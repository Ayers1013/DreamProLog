{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5ee588dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-12-27 00:55:14.487052: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running the DreamProlog algorithm.\n",
      "There was a problem with the provided arguments. The program will run in the default setting:\n",
      "--configs prolog --logdir logdir\n",
      "Namespace(act='elu', action_gnn_hidden_act=64, action_gnn_hidden_val=200, action_gnn_layers=6, action_gnn_next_shape=(32, 64, 32), action_gnn_start_shape=(4, 1, 4), action_repeat=1, actor_disc=5, actor_dist='normal', actor_entropy='1e-4', actor_grad_clip=100, actor_init_std=1.0, actor_layers=4, actor_lr=0.001, actor_min_std=0.1, actor_outscale=0.0, actor_state_entropy=0.0, actor_temp=0.1, atari_grayscale=False, behavior_stop_grad=True, clip_rewards='identity', collect_dyn_sample=True, dataset_size=100000, debug=False, disag_layers=1, disag_log=True, disag_models=3, disag_offset=0, disag_target='embed', disag_units=200, discount=0.95, discount_lambda=0.8, discount_layers=2, discount_scale=1.0, dyn_cell='gru', dyn_deter=512, dyn_discrete=32, dyn_hidden=512, dyn_input_layers=5, dyn_mean_act='none', dyn_min_std=0.1, dyn_output_layers=5, dyn_shared=False, dyn_std_act='sigmoid2', dyn_stoch=192, envs=1, eval_every=500, eval_noise=0.0, eval_state_mean=False, evaldir=None, expl_amount=0.0, expl_behavior='greedy', expl_extr_scale=0.0, expl_gifs=False, expl_intr_scale=1.0, expl_until=10000000.0, free_heads=('image', 'reward', 'discount'), future_entropy=False, gnn_hidden_act=128, gnn_hidden_val=384, gnn_layers=14, gnn_next_shape=(32, 64, 32), gnn_start_shape=(4, 1, 4), gpu_growth=True, grad_clip=200, grad_heads=('image', 'reward', 'discount', 'action_mask'), imag_gradient='reinforce', imag_gradient_mix='0.1', imag_horizon=3, imag_sample=True, kl_balance='0.8', kl_free='0.5', kl_scale='1.0', log_every=10, model_lr=0.0009, offline_evaldir='', offline_traindir='', opt='adam', opt_eps=0.0008, oversample_ends=False, precision=32, pred_discount=True, prefill=40000, pretrain=5, reset_every=0, reward_layers=2, reward_scale=1.0, seed=0, share_gnn=True, slow_actor_target=False, slow_target_fraction=1, slow_target_update=100, slow_value_target=False, steps=1000000, task='prolog_void', time_limit=1000, train_every=25, train_steps=10, traindir=None, units=192, value_decay=0.0, value_grad_clip=100, value_head='normal', value_layers=3, value_lr=0.001, weight_decay=0.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "usage: ipykernel_launcher.py [-h] --configs CONFIGS [CONFIGS ...] --logdir\n",
      "                             LOGDIR\n",
      "ipykernel_launcher.py: error: the following arguments are required: --configs, --logdir\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logdir logdir\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-12-27 00:55:15.942327: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set\n",
      "2021-12-27 00:55:15.943052: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcuda.so.1\n",
      "2021-12-27 00:55:17.237212: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: \n",
      "pciBusID: 0000:05:00.0 name: TITAN V computeCapability: 7.0\n",
      "coreClock: 1.455GHz coreCount: 80 deviceMemorySize: 11.78GiB deviceMemoryBandwidth: 607.97GiB/s\n",
      "2021-12-27 00:55:17.237887: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 1 with properties: \n",
      "pciBusID: 0000:09:00.0 name: TITAN V computeCapability: 7.0\n",
      "coreClock: 1.455GHz coreCount: 80 deviceMemorySize: 11.78GiB deviceMemoryBandwidth: 607.97GiB/s\n",
      "2021-12-27 00:55:17.237906: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1\n",
      "2021-12-27 00:55:17.239219: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10\n",
      "2021-12-27 00:55:17.239248: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.10\n",
      "2021-12-27 00:55:17.240426: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10\n",
      "2021-12-27 00:55:17.240617: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10\n",
      "2021-12-27 00:55:17.241912: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10\n",
      "2021-12-27 00:55:17.242632: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.10\n",
      "2021-12-27 00:55:17.245443: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7\n",
      "2021-12-27 00:55:17.247860: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0, 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Suite: prolog\n",
      "Found 131 problem files.\n",
      "Query:\n",
      "    init_python(\"leancop/theorems/m2n140/t30_wellord1.p\",[conj, nodef, eager_reduction(1)],GnnInput, SimpleFeatures, TextFeatures, TextActions, ActionsMask, Result) \n",
      "\n",
      "Suite: prolog\n",
      "Found 131 problem files.\n",
      "Query:\n",
      "    init_python(\"leancop/theorems/m2n140/t40_tex_2.p\",[conj, nodef, eager_reduction(1)],GnnInput, SimpleFeatures, TextFeatures, TextActions, ActionsMask, Result) \n",
      "\n",
      "Prefill dataset (0 steps).\n",
      "Loaded problem: m2n140__t5_tmap_1\n",
      "Found 131 problem files.\n",
      "Query:\n",
      "    init_python(\"leancop/theorems/m2n140/t39_partfun1.p\",[conj, nodef, eager_reduction(1)],GnnInput, SimpleFeatures, TextFeatures, TextActions, ActionsMask, Result) \n",
      "\n",
      "Eval episode has 25 steps and return -0.500.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kristsz/DreamProLog/envs/wrappers.py:57: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  value = np.array(value)\n"
     ]
    }
   ],
   "source": [
    "from main import init_config\n",
    "from controller import Controller\n",
    "from dataset.process import TokenParser\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "ctrl = Controller(*init_config())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0eab208f",
   "metadata": {},
   "outputs": [],
   "source": [
    "meta = ctrl.datasetManager._train_eps._meta\n",
    "ds = []\n",
    "for v in meta.values():\n",
    "    ds.extend([str(s)[1:] for s in v['action_space_text']])\n",
    "    \n",
    "parser = TokenParser()\n",
    "\n",
    "def pad(narr):\n",
    "    size = narr.size\n",
    "    return np.pad(narr, [0, 128-size])\n",
    "\n",
    "parsed_ds = []\n",
    "for dp in ds:\n",
    "    parsed_ds.append(pad(np.array(parser.parse(dp), dtype = np.int32)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "30896e5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-12-27 00:55:29.134409: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2021-12-27 00:55:29.353617: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: \n",
      "pciBusID: 0000:05:00.0 name: TITAN V computeCapability: 7.0\n",
      "coreClock: 1.455GHz coreCount: 80 deviceMemorySize: 11.78GiB deviceMemoryBandwidth: 607.97GiB/s\n",
      "2021-12-27 00:55:29.354239: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 1 with properties: \n",
      "pciBusID: 0000:09:00.0 name: TITAN V computeCapability: 7.0\n",
      "coreClock: 1.455GHz coreCount: 80 deviceMemorySize: 11.78GiB deviceMemoryBandwidth: 607.97GiB/s\n",
      "2021-12-27 00:55:29.354263: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1\n",
      "2021-12-27 00:55:29.354285: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10\n",
      "2021-12-27 00:55:29.354295: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.10\n",
      "2021-12-27 00:55:29.354306: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10\n",
      "2021-12-27 00:55:29.354316: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10\n",
      "2021-12-27 00:55:29.354326: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10\n",
      "2021-12-27 00:55:29.354337: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.10\n",
      "2021-12-27 00:55:29.354347: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7\n",
      "2021-12-27 00:55:29.356618: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0, 1\n",
      "2021-12-27 00:55:29.356644: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1\n",
      "2021-12-27 00:55:30.021274: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1261] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
      "2021-12-27 00:55:30.021304: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1267]      0 1 \n",
      "2021-12-27 00:55:30.021310: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1280] 0:   N Y \n",
      "2021-12-27 00:55:30.021313: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1280] 1:   Y N \n",
      "2021-12-27 00:55:30.023848: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1406] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10910 MB memory) -> physical GPU (device: 0, name: TITAN V, pci bus id: 0000:05:00.0, compute capability: 7.0)\n",
      "2021-12-27 00:55:30.025325: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1406] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:1 with 10913 MB memory) -> physical GPU (device: 1, name: TITAN V, pci bus id: 0000:09:00.0, compute capability: 7.0)\n",
      "2021-12-27 00:55:30.025623: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "BATCH_SIZE = 32\n",
    "def generator():\n",
    "    for i in range(1000):\n",
    "        x = tf.constant([parsed_ds[np.random.randint(len(parsed_ds))] for i in range(BATCH_SIZE)])\n",
    "        yield x, x\n",
    "sgn = tf.TensorSpec((BATCH_SIZE, 128), dtype=tf.int32)\n",
    "tf_ds = tf.data.Dataset.from_generator(generator, output_signature = (sgn, sgn))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fd23e2fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU available:  [PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU'), PhysicalDevice(name='/physical_device:GPU:1', device_type='GPU')]\n"
     ]
    }
   ],
   "source": [
    "from unorganized.parts2 import Net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "646ac130",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Loss(tf.keras.losses.Loss):\n",
    "    def __init__(self, omega=0.01):\n",
    "        super().__init__()\n",
    "        self.omega = omega\n",
    "        \n",
    "    def call(self, y_true, y_pred):\n",
    "        y = tf.nn.softmax(y_pred, axis=-1)\n",
    "        y_probs = tf.gather(y, y_true, axis=-1, batch_dims=2)\n",
    "        y_log_probs = tf.math.log(y_probs+0.001)\n",
    "        #loss = self.omega*y_log_probs + (1-self.omega)*tf.math.cumsum(y_log_probs, axis=-1)\n",
    "        #loss = y_log_probs*tf.math.cumprod(0.97*tf.ones((32,128)), axis=-1)\n",
    "        mask = 1-tf.cast(tf.math.equal(y_true, 0), tf.float32)\n",
    "        #mask = tf.math.cumprod(mask, axis=-1)\n",
    "        loss = (mask+self.omega)*y_log_probs\n",
    "        loss = -tf.math.reduce_sum(loss)/(128*32)\n",
    "        return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6f9556c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Net(4, 8, 128, 64, 4, 128)#Net(128, 4, 256)\n",
    "#d_model = 256\n",
    "#enc_embed = tf.keras.layers.Embedding(300, d_model)\n",
    "#encoder = Encoder(4, d_model, 4, 512, 0.04)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b6cda476",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-12-27 00:55:30.340656: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:116] None of the MLIR optimization passes are enabled (registered 2)\n",
      "2021-12-27 00:55:30.357404: I tensorflow/core/platform/profile_utils/cpu_utils.cc:112] CPU Frequency: 3598190000 Hz\n",
      "2021-12-27 00:55:30.383214: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10\n",
      "2021-12-27 00:55:30.542655: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7\n"
     ]
    }
   ],
   "source": [
    "x, x = next(iter(tf_ds))\n",
    "model(x, False)\n",
    "y_true = x\n",
    "mask = 1-tf.cast(tf.math.equal(y_true, 0), tf.float32)\n",
    "mask = tf.math.cumprod(mask, axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "af8f2751",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=tf.keras.optimizers.Adam(), loss=Loss(), metrics=[])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2ea1cba5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/6\n",
      "1000/1000 [==============================] - 24s 18ms/step - loss: 0.7817\n",
      "Epoch 2/6\n",
      "1000/1000 [==============================] - 18s 18ms/step - loss: 0.6761\n",
      "Epoch 3/6\n",
      "1000/1000 [==============================] - 20s 20ms/step - loss: 0.6668\n",
      "Epoch 4/6\n",
      "1000/1000 [==============================] - 18s 18ms/step - loss: 0.6669\n",
      "Epoch 5/6\n",
      "1000/1000 [==============================] - 18s 18ms/step - loss: 0.6680\n",
      "Epoch 6/6\n",
      "1000/1000 [==============================] - 18s 18ms/step - loss: 0.6689\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f98980f5c50>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(tf_ds, epochs = 6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ed7a942c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[  3  21   5  10   7  22  23  24   5  38  23  19   7  38  23   6   7   2\n",
      "    1   2   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0]\n",
      " [ 21   5  12  13   2   3  21   5  16  18   2   9   5  12  16   2   9   5\n",
      "   13  18   2   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0]\n",
      " [ 14   5  57   5  19   5  12  13  16  13   2   3   9   5  12  55  23  13\n",
      "    2  14   5  19   5  12  13  12   2   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0]\n",
      " [ 28  23  12   2   3 145   5  12  13   2   3  14   5   6   5  13  12  13\n",
      "    2   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0]], shape=(4, 128), dtype=int32)\n",
      "\n",
      "tf.Tensor(\n",
      "[[  3   5  12  13   2   3   9   5  16   2   2   2   5   2  12   2   2   2\n",
      "    5  16   2   2   2   2   5   2   2   2   2  23   2   2   5  23   2   2\n",
      "  122   2   2   2   2   2   2  12   5   2   2  38  23  20  12  23  16   2\n",
      "   47  20  12  18   5   2   2  47   5  18   5  16  18  16  12  13  13   2\n",
      "    2   0   0   0   0   0   0 125   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0]\n",
      " [  3   5  12  13   2   3   9   5  16   2   2   2   5   2  12   2   2   2\n",
      "    5  16   2   2   2   2   5   2   2   2   2  23   2   2   5  23   2   2\n",
      "  122   2   2   2   2   2   2  12   5   2   2  38  23  20  12  23  16   2\n",
      "   47  20  12  18   5   2   2  47   5  18   5  16  18  16  12  13  13   2\n",
      "    2   0   0   0   0   0   0 125   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0]\n",
      " [  3   5  12  13   2   3   9   5  16   2   2   2   5   2  12   2   2   2\n",
      "    5  16   2   2   2   2   5   2   2   2   2  23   2   2   5  23   2   2\n",
      "  122   2   2   2   2   2   2  12   5   2   2  38  23  20  12  23  16   2\n",
      "   47  20  12  18   5   2   2  47   5  18   5  16  18  16  12  13  13   2\n",
      "    2   0   0   0   0   0   0 125   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0]\n",
      " [  3   5  12  13   2   3   9   5  16   2   2   2   5   2  12   2   2   2\n",
      "    5  16   2   2   2   2   5   2   2   2   2  23   2   2   5  23   2   2\n",
      "  122   2   2   2   2   2   2  12   5   2   2  38  23  20  12  23  16   2\n",
      "   47  20  12  18   5   2   2  47   5  18   5  16  18  16  12  13  13   2\n",
      "    2   0   0   0   0   0   0 125   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0]], shape=(4, 128), dtype=int64)\n",
      "\n",
      "tf.Tensor(\n",
      "[[38  2 21  1  4  0 13  0  5  1 11  0  2  1  9  0  2 19  0 11  0  0  0  0\n",
      "   1  1  1  1  1  1  2  2  2  2  2  2  2  3  3  2  3  4  3  4  4  4  4  5\n",
      "   4  4  5  5  6  6  6  6  7  7  8  8  8  8  9  8  9 10 10 10 11 11 11 13\n",
      "  18 24 24 27 33 32 33 27 33 32 37 37 40 35 34 38 38 43 46 56 57 60 57 55\n",
      "  56 62 58 68 64 65 65 60 58 56 66 55 61 58 53 54 66 75 71 67 71 69 69 74\n",
      "  85 92 99 99 99 99 99 99]\n",
      " [ 8 40 57 35 34 27  3 28 17  8 23  9 21 12  7 27 13 17  7  4 27  0  0  0\n",
      "   1  1  1  1  1  1  2  2  2  2  2  2  2  3  3  2  3  4  3  4  4  4  4  5\n",
      "   4  4  5  5  6  6  6  6  7  7  8  8  8  8  9  8  9 10 10 10 11 11 11 13\n",
      "  18 24 24 27 33 32 33 27 33 32 37 37 40 35 34 38 38 43 46 56 57 60 57 55\n",
      "  56 62 58 68 64 65 65 60 58 56 66 55 61 58 53 54 66 75 71 67 71 69 69 74\n",
      "  85 92 99 99 99 99 99 99]\n",
      " [ 3 40  0  2  0  3  6 14 17 11 23  0  2 10 17  0 11  8 13  0  9  1 10  7\n",
      "   8  6 12  1  1  1  2  2  2  2  2  2  2  3  3  2  3  4  3  4  4  4  4  5\n",
      "   4  4  5  5  6  6  6  6  7  7  8  8  8  8  9  8  9 10 10 10 11 11 11 13\n",
      "  18 24 24 27 33 32 33 27 33 32 37 37 40 35 34 38 38 43 46 56 57 60 57 55\n",
      "  56 62 58 68 64 65 65 60 58 56 66 55 61 58 53 54 66 75 71 67 71 69 69 74\n",
      "  85 92 99 99 99 99 99 99]\n",
      " [ 2 16 57 14  6  0  9  5 15 18  3  2 21  0 10 10 10  8 13  0  0  0  0  0\n",
      "   1  1  1  1  1  1  2  2  2  2  2  2  2  3  3  2  3  4  3  4  4  4  4  5\n",
      "   4  4  5  5  6  6  6  6  7  7  8  8  8  8  9  8  9 10 10 10 11 11 11 13\n",
      "  18 24 24 27 33 32 33 27 33 32 37 37 40 35 34 38 38 43 46 56 57 60 57 55\n",
      "  56 62 58 68 64 65 65 60 58 56 66 55 61 58 53 54 66 75 71 67 71 69 69 74\n",
      "  85 92 99 99 99 99 99 99]], shape=(4, 128), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "x, y_true = next(iter(tf_ds))\n",
    "y_pred = model(x, False)\n",
    "y_pred = tf.nn.softmax(y_pred, axis=-1)\n",
    "y_probs = tf.gather(y_pred, y_true, axis=-1, batch_dims=2)\n",
    "y_pred = tf.math.argmax(y_pred, axis=-1)\n",
    "print(x[:4], y_pred[:4], tf.cast(100*y_probs[:4], dtype=tf.int32), sep='\\n\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "da59122a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Variable 'Variable:0' shape=(1, 8, 64) dtype=float32, numpy=\n",
       "array([[[ 0.97824246,  0.5974416 ,  0.00375594,  0.23254953,\n",
       "          0.22993088,  0.5955447 ,  0.17607917,  0.9732856 ,\n",
       "          0.9335298 ,  0.40274316,  0.03229064,  0.3560708 ,\n",
       "          0.6219572 ,  0.5183356 ,  1.0049845 ,  0.03811038,\n",
       "          0.28507778,  0.42520964,  0.39790943,  0.8667803 ,\n",
       "          0.6957693 ,  0.84650147,  0.11995757,  0.93961203,\n",
       "          0.24121642,  0.37429434,  0.4334079 ,  0.7966627 ,\n",
       "          0.0120051 ,  0.3501379 ,  0.04965518,  0.07324756,\n",
       "          0.03087216,  0.40470082,  0.726252  ,  0.00433213,\n",
       "          0.4536972 ,  0.85086304,  0.8707042 ,  0.15310346,\n",
       "          0.23801196,  0.12061308,  0.25752205,  0.6786174 ,\n",
       "          0.06412861,  0.71585965,  0.40815648,  0.42879924,\n",
       "          0.7573862 ,  0.7762137 ,  0.92630833,  0.10193264,\n",
       "          0.61462843,  0.3048497 ,  0.16122748,  0.6568268 ,\n",
       "          0.4650954 ,  0.34682822,  0.08825079,  0.93316704,\n",
       "          0.69303644,  0.44166785,  0.69549245,  0.6605126 ],\n",
       "        [ 0.8281372 ,  0.8874785 ,  0.11829961,  0.08023531,\n",
       "          0.4274655 ,  0.23374201,  0.16811702,  0.25084162,\n",
       "          0.47006977,  0.55254334,  0.95135516,  0.05746121,\n",
       "          0.35070947,  0.41751084,  0.21553318,  0.8692415 ,\n",
       "          0.8127577 ,  0.47000614,  0.9859046 ,  0.1624024 ,\n",
       "          0.81365055,  0.5025315 ,  0.6992852 ,  0.62195754,\n",
       "          0.849092  ,  0.40866834,  0.3716105 ,  0.01629933,\n",
       "          0.15427919,  0.18975514,  0.6317164 ,  0.4391429 ,\n",
       "          0.33329234,  0.85894126,  0.3248741 ,  0.65531707,\n",
       "          0.2555616 ,  0.3623853 ,  0.6560366 ,  0.8673966 ,\n",
       "          0.6025716 ,  0.2949161 ,  0.7085286 ,  0.5695833 ,\n",
       "          0.9483534 ,  0.19318391,  0.267844  ,  0.35900548,\n",
       "          0.9906833 ,  0.8706429 ,  0.24792449,  0.6059903 ,\n",
       "          0.21535732,  0.25053877, -0.00851414,  0.5355722 ,\n",
       "          0.755764  ,  0.06184495,  0.09728385,  0.84927833,\n",
       "          0.66278917,  0.61623645,  0.7311301 ,  0.3130638 ],\n",
       "        [ 0.5810451 ,  0.9767463 ,  0.01416342,  0.2817337 ,\n",
       "          0.41124898,  0.19546059,  0.18835795,  0.00999037,\n",
       "          0.7681113 ,  0.5957971 ,  0.25203672,  0.39043766,\n",
       "          0.01744007,  0.6803088 ,  0.06231946,  0.12748851,\n",
       "          0.07935833,  0.38679123,  0.38391972,  0.8602645 ,\n",
       "          0.82900846,  0.7076884 ,  0.82471156,  0.98181355,\n",
       "          0.6812958 ,  0.508417  ,  0.6886546 ,  0.17019218,\n",
       "          0.06383195,  0.94153965,  0.44493297,  0.1567566 ,\n",
       "          0.6082507 ,  0.89285636,  0.40341505,  0.5032867 ,\n",
       "          0.27418074,  0.65663904,  0.82386965,  0.22630465,\n",
       "          0.93163824,  0.72037613,  0.81358844,  0.86336976,\n",
       "          0.77777845,  0.1287708 ,  0.16810383,  0.8330797 ,\n",
       "          0.35481468,  0.66245395,  0.31287277,  0.24906835,\n",
       "          0.46507722,  0.71614254,  0.8240508 ,  0.5756153 ,\n",
       "          0.26971182,  0.60046744,  0.09534622,  0.31955028,\n",
       "          0.8105481 ,  0.8745944 ,  0.85870147,  0.7159155 ],\n",
       "        [ 0.5847105 ,  0.38217312,  0.3437684 ,  0.12301464,\n",
       "          0.13869138,  0.15763025,  0.3523697 ,  0.72589797,\n",
       "          0.618445  ,  0.14296292,  0.00147914,  0.7178158 ,\n",
       "          0.11810065,  0.3368505 ,  0.8115145 ,  0.13424185,\n",
       "          0.38129464,  0.8121778 ,  0.70185304,  0.19731903,\n",
       "          0.21559763,  0.09723122,  0.20929551,  0.09640621,\n",
       "          0.1967975 ,  0.0734721 ,  0.45521745,  0.04009094,\n",
       "          0.5690061 ,  0.31111395,  0.80649334,  0.064853  ,\n",
       "          0.0091613 ,  0.5461623 ,  0.83266073,  0.25553584,\n",
       "          0.44444296,  0.05985489,  0.2528961 ,  0.0822283 ,\n",
       "          0.6483788 ,  0.27455655,  0.02174682,  0.982061  ,\n",
       "          0.64104235,  0.35824773,  0.15164904,  0.13214764,\n",
       "          0.0472228 ,  0.6005471 ,  0.5021968 ,  0.05964812,\n",
       "          0.3538114 ,  0.78033864,  0.6927824 ,  0.9353366 ,\n",
       "          0.9854648 ,  0.30236933,  0.09606879,  0.2822195 ,\n",
       "          0.35372242,  0.64878047,  0.5218575 ,  0.8433587 ],\n",
       "        [ 0.04330634,  0.85164994,  0.6592402 ,  0.30464745,\n",
       "          0.50851345,  0.6512426 ,  0.19115093,  0.4207788 ,\n",
       "          0.63336307,  0.06942788,  0.5534036 ,  0.00150564,\n",
       "          0.31399372,  0.641598  ,  0.6113748 ,  0.11730114,\n",
       "          0.86148316,  0.2155337 ,  0.7132311 ,  0.06327683,\n",
       "          0.561038  ,  0.85338384,  0.73734033,  0.9211239 ,\n",
       "          0.76073956,  0.254753  ,  0.51882046,  0.92697835,\n",
       "          0.4922957 ,  0.50929487,  0.98501664,  0.30543134,\n",
       "          0.96245605,  0.05809683,  0.5734985 ,  0.78379124,\n",
       "          0.09547626,  0.29845223,  0.09108062,  0.543522  ,\n",
       "          0.67866594,  0.61413914,  0.7490615 ,  0.67743295,\n",
       "          0.63756204,  0.6257022 ,  0.24798653,  0.067578  ,\n",
       "          0.21136808,  0.03969147,  0.01421232,  0.98349315,\n",
       "          0.932258  ,  0.7399628 ,  0.07227788,  0.51896995,\n",
       "          0.77607936,  0.98202145,  0.8446403 ,  0.6565324 ,\n",
       "          0.15428302,  0.50233334,  0.2465607 ,  0.16817096],\n",
       "        [ 0.9636986 ,  0.59572077,  0.70727813,  0.17480619,\n",
       "          0.4610126 ,  0.25203675,  0.55786765,  0.31648168,\n",
       "          0.49405152,  0.52228075,  0.21978107,  0.24455345,\n",
       "          0.970547  ,  0.35645354,  0.4203873 ,  0.9717107 ,\n",
       "          0.7755067 ,  0.372805  ,  0.6451782 ,  0.62754154,\n",
       "          0.5322748 ,  0.35764363,  0.7471448 ,  0.31652012,\n",
       "          0.968178  ,  0.42210662,  0.8132814 ,  0.60801464,\n",
       "          0.62286246,  0.31114006,  0.6231446 ,  0.961546  ,\n",
       "          0.03238477,  0.97948736,  0.15796243,  0.65111583,\n",
       "          0.15055679,  0.71159345,  0.65409744,  0.7055023 ,\n",
       "          0.41099554,  0.17034672,  0.14614934,  0.19436367,\n",
       "          0.62219447,  0.69383466,  0.42748883,  0.3055191 ,\n",
       "          0.1558022 ,  0.21194401,  0.42559925,  0.5592469 ,\n",
       "          0.3452418 ,  0.14720382,  0.63733864,  0.53035325,\n",
       "          0.08530228,  0.29530597,  0.331903  ,  0.8218423 ,\n",
       "          0.9685283 ,  0.1716163 ,  0.83117616,  0.20484684],\n",
       "        [ 0.4816254 ,  0.8175809 ,  0.09092811,  0.25930163,\n",
       "          0.75981414,  0.08758111,  0.09290592,  0.09665404,\n",
       "          0.4822679 ,  0.80233365,  0.7009257 ,  0.57318145,\n",
       "          0.50138843,  0.1178119 ,  0.75484234,  0.5736582 ,\n",
       "          0.9664787 ,  0.01519688,  0.4094414 ,  0.08304475,\n",
       "          0.25920147,  0.06230672,  0.07475383,  0.36684868,\n",
       "          0.8976382 ,  0.31059116,  0.6146023 ,  0.3379181 ,\n",
       "          0.36615518,  0.8845062 ,  0.922152  ,  0.08306389,\n",
       "          0.6807039 ,  0.13146943,  0.92268866,  0.5793245 ,\n",
       "          0.8869386 ,  0.20343065,  0.00608589,  0.28219712,\n",
       "          0.24775475,  0.23940423,  0.9935852 ,  0.41501272,\n",
       "          0.5772268 ,  0.18399557,  0.25797325,  0.77864087,\n",
       "          0.8447339 ,  0.8829197 ,  0.3235644 ,  0.7025581 ,\n",
       "          0.83459467,  0.23469168,  0.5418813 ,  0.37799218,\n",
       "          0.41383484,  0.57877094,  0.6870747 ,  0.65649766,\n",
       "          0.94202834,  0.9271302 ,  0.721393  ,  0.90111446],\n",
       "        [ 0.402577  ,  0.37729377,  0.69322205,  0.41931343,\n",
       "          0.8160068 ,  0.05943399,  0.49493098,  0.67675155,\n",
       "          0.7377573 ,  0.352244  ,  0.33543336,  0.74658483,\n",
       "          0.5775448 ,  0.6894367 ,  0.490692  ,  0.18008731,\n",
       "          0.24722795,  0.40089816,  0.72732145,  0.6067268 ,\n",
       "          0.16643263,  0.6038145 ,  0.5204367 ,  0.3635949 ,\n",
       "          0.47575656,  0.7354527 ,  0.88766485,  0.34535563,\n",
       "          0.61988914,  0.9503081 ,  0.68879014,  0.71524316,\n",
       "          0.7946243 ,  0.48361462,  0.6937841 ,  0.4047492 ,\n",
       "          0.8305514 ,  0.26578668,  0.764223  ,  0.5265038 ,\n",
       "          0.712759  ,  0.98148155,  0.6681022 ,  0.6173479 ,\n",
       "          0.87097543,  0.5142971 ,  0.9117764 ,  0.381274  ,\n",
       "          0.2634328 ,  0.9210584 ,  0.8028938 ,  0.88487566,\n",
       "          0.92697704,  0.2787055 ,  0.43540192,  0.92872995,\n",
       "          0.46788785,  0.97294146,  0.2581754 ,  0.8541845 ,\n",
       "          0.87220997,  0.04026144,  0.19716313,  0.8484343 ]]],\n",
       "      dtype=float32)>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.encoder.variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4d28b215",
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = tf.cast(tf.math.equal(x[:1], 0), tf.float32)[:, tf.newaxis, :, tf.newaxis]\n",
    "        \n",
    "v, q = model.enc_embed(x)[:1], model.encoder.variable#tf.tile(model.encoder.variable, (32, 1, 1))\n",
    "v = [v]\n",
    "q = [q]\n",
    "attention = []\n",
    "for l in model.encoder.layers:\n",
    "    _v, _q, _att = l(v[-1], q[-1], mask, False)\n",
    "    v.append(_v)\n",
    "    q.append(_q)\n",
    "    attention.append(_att)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b633f062",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Tensor: shape=(1, 128, 64), dtype=float32, numpy=\n",
       " array([[[-0.01382007, -0.04508341,  0.02874011, ..., -0.02775118,\n",
       "          -0.02536368,  0.00064962],\n",
       "         [ 0.01436266,  0.02622153,  0.01461639, ..., -0.01393499,\n",
       "          -0.03265372,  0.00102618],\n",
       "         [ 0.00857547,  0.0001025 ,  0.02118409, ..., -0.01031844,\n",
       "          -0.02387962,  0.05068742],\n",
       "         ...,\n",
       "         [-0.03988689,  0.01468533,  0.04644993, ...,  0.05614553,\n",
       "           0.02990331,  0.01761182],\n",
       "         [-0.03988689,  0.01468533,  0.04644993, ...,  0.05614553,\n",
       "           0.02990331,  0.01761182],\n",
       "         [-0.03988689,  0.01468533,  0.04644993, ...,  0.05614553,\n",
       "           0.02990331,  0.01761182]]], dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 128, 64), dtype=float32, numpy=\n",
       " array([[[-0.20192027,  1.3405633 , -0.8428617 , ..., -0.2973917 ,\n",
       "           1.1533742 , -1.2528737 ],\n",
       "         [-0.20114128,  1.3411578 , -0.8436888 , ..., -0.29684174,\n",
       "           1.153654  , -1.2516905 ],\n",
       "         [-0.19997585,  1.3403556 , -0.8431535 , ..., -0.29589388,\n",
       "           1.1551809 , -1.2531028 ],\n",
       "         ...,\n",
       "         [-0.20070393,  1.341973  , -0.8428246 , ..., -0.29959446,\n",
       "           1.1531758 , -1.2530502 ],\n",
       "         [-0.20070393,  1.341973  , -0.8428246 , ..., -0.29959446,\n",
       "           1.1531758 , -1.2530502 ],\n",
       "         [-0.20070393,  1.341973  , -0.8428246 , ..., -0.29959446,\n",
       "           1.1531758 , -1.2530502 ]]], dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 128, 64), dtype=float32, numpy=\n",
       " array([[[ 1.445249  ,  0.59312445, -0.9332212 , ...,  0.1571224 ,\n",
       "           0.61259985,  0.5575406 ],\n",
       "         [ 1.4452488 ,  0.5931244 , -0.9332212 , ...,  0.15712237,\n",
       "           0.61259985,  0.5575406 ],\n",
       "         [ 1.445249  ,  0.5931244 , -0.93322134, ...,  0.15712243,\n",
       "           0.61259997,  0.55754066],\n",
       "         ...,\n",
       "         [ 1.4452488 ,  0.59312445, -0.9332211 , ...,  0.15712237,\n",
       "           0.61259997,  0.5575406 ],\n",
       "         [ 1.4452488 ,  0.59312445, -0.9332211 , ...,  0.15712237,\n",
       "           0.61259997,  0.5575406 ],\n",
       "         [ 1.4452488 ,  0.59312445, -0.9332211 , ...,  0.15712237,\n",
       "           0.61259997,  0.5575406 ]]], dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 128, 64), dtype=float32, numpy=\n",
       " array([[[-0.99730355,  1.3838431 ,  2.1812918 , ...,  0.363907  ,\n",
       "           0.72222906, -1.7517744 ],\n",
       "         [-0.99730355,  1.3838431 ,  2.1812916 , ...,  0.36390704,\n",
       "           0.7222291 , -1.7517745 ],\n",
       "         [-0.9973035 ,  1.3838431 ,  2.1812918 , ...,  0.3639071 ,\n",
       "           0.7222291 , -1.7517745 ],\n",
       "         ...,\n",
       "         [-0.9973035 ,  1.3838431 ,  2.1812916 , ...,  0.36390704,\n",
       "           0.722229  , -1.7517744 ],\n",
       "         [-0.9973035 ,  1.3838431 ,  2.1812916 , ...,  0.36390704,\n",
       "           0.722229  , -1.7517744 ],\n",
       "         [-0.9973035 ,  1.3838431 ,  2.1812916 , ...,  0.36390704,\n",
       "           0.722229  , -1.7517744 ]]], dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 128, 64), dtype=float32, numpy=\n",
       " array([[[-1.5386612 ,  0.73619866,  0.85359323, ..., -0.43693942,\n",
       "          -2.504601  , -1.565139  ],\n",
       "         [-1.5386612 ,  0.7361988 ,  0.8535933 , ..., -0.4369394 ,\n",
       "          -2.504601  , -1.5651392 ],\n",
       "         [-1.5386612 ,  0.7361988 ,  0.8535932 , ..., -0.4369394 ,\n",
       "          -2.504601  , -1.565139  ],\n",
       "         ...,\n",
       "         [-1.538661  ,  0.7361987 ,  0.8535931 , ..., -0.43693945,\n",
       "          -2.5046008 , -1.5651392 ],\n",
       "         [-1.538661  ,  0.7361987 ,  0.8535931 , ..., -0.43693945,\n",
       "          -2.5046008 , -1.5651392 ],\n",
       "         [-1.538661  ,  0.7361987 ,  0.8535931 , ..., -0.43693945,\n",
       "          -2.5046008 , -1.5651392 ]]], dtype=float32)>]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fc0e4c48",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor: shape=(1, 4, 128, 8), dtype=float32, numpy=\n",
       " array([[[[0.12545249, 0.12511896, 0.12447762, ..., 0.12503707,\n",
       "           0.12401682, 0.12555017],\n",
       "          [0.12500124, 0.12403779, 0.124701  , ..., 0.12725063,\n",
       "           0.12449756, 0.1272593 ],\n",
       "          [0.1250275 , 0.12406384, 0.12502721, ..., 0.12618999,\n",
       "           0.12559298, 0.12666376],\n",
       "          ...,\n",
       "          [0.125     , 0.125     , 0.125     , ..., 0.125     ,\n",
       "           0.125     , 0.125     ],\n",
       "          [0.125     , 0.125     , 0.125     , ..., 0.125     ,\n",
       "           0.125     , 0.125     ],\n",
       "          [0.125     , 0.125     , 0.125     , ..., 0.125     ,\n",
       "           0.125     , 0.125     ]],\n",
       " \n",
       "         [[0.12381552, 0.1259679 , 0.1259109 , ..., 0.12662154,\n",
       "           0.12292788, 0.12490745],\n",
       "          [0.12466825, 0.12476002, 0.12428483, ..., 0.12738751,\n",
       "           0.12321696, 0.12461508],\n",
       "          [0.12265145, 0.12534714, 0.12570193, ..., 0.12721707,\n",
       "           0.12363745, 0.12557124],\n",
       "          ...,\n",
       "          [0.125     , 0.125     , 0.125     , ..., 0.125     ,\n",
       "           0.125     , 0.125     ],\n",
       "          [0.125     , 0.125     , 0.125     , ..., 0.125     ,\n",
       "           0.125     , 0.125     ],\n",
       "          [0.125     , 0.125     , 0.125     , ..., 0.125     ,\n",
       "           0.125     , 0.125     ]],\n",
       " \n",
       "         [[0.12495664, 0.12480421, 0.12429771, ..., 0.12624368,\n",
       "           0.12404333, 0.1257907 ],\n",
       "          [0.12520522, 0.12500942, 0.1242968 , ..., 0.12550476,\n",
       "           0.12391047, 0.12523669],\n",
       "          [0.12431334, 0.12405989, 0.12443452, ..., 0.12545349,\n",
       "           0.12393364, 0.12574126],\n",
       "          ...,\n",
       "          [0.125     , 0.125     , 0.125     , ..., 0.125     ,\n",
       "           0.125     , 0.125     ],\n",
       "          [0.125     , 0.125     , 0.125     , ..., 0.125     ,\n",
       "           0.125     , 0.125     ],\n",
       "          [0.125     , 0.125     , 0.125     , ..., 0.125     ,\n",
       "           0.125     , 0.125     ]],\n",
       " \n",
       "         [[0.12432232, 0.1254811 , 0.12477573, ..., 0.12574832,\n",
       "           0.12549998, 0.12442632],\n",
       "          [0.12330741, 0.12681744, 0.12565547, ..., 0.12315898,\n",
       "           0.12766661, 0.12238298],\n",
       "          [0.12243684, 0.127147  , 0.12759522, ..., 0.1262289 ,\n",
       "           0.1245874 , 0.12351111],\n",
       "          ...,\n",
       "          [0.125     , 0.125     , 0.125     , ..., 0.125     ,\n",
       "           0.125     , 0.125     ],\n",
       "          [0.125     , 0.125     , 0.125     , ..., 0.125     ,\n",
       "           0.125     , 0.125     ],\n",
       "          [0.125     , 0.125     , 0.125     , ..., 0.125     ,\n",
       "           0.125     , 0.125     ]]]], dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 4, 8, 128), dtype=float32, numpy=\n",
       " array([[[[0.0078124 , 0.00781265, 0.00781446, ..., 0.00781206,\n",
       "           0.00781206, 0.00781206],\n",
       "          [0.00780933, 0.00781085, 0.00781081, ..., 0.00781216,\n",
       "           0.00781216, 0.00781216],\n",
       "          [0.00780906, 0.00780648, 0.00780903, ..., 0.00781263,\n",
       "           0.00781263, 0.00781263],\n",
       "          ...,\n",
       "          [0.00780855, 0.00781074, 0.00781132, ..., 0.00781215,\n",
       "           0.00781215, 0.00781215],\n",
       "          [0.00781475, 0.00781564, 0.00781129, ..., 0.00781216,\n",
       "           0.00781216, 0.00781216],\n",
       "          [0.00781234, 0.00781314, 0.00781198, ..., 0.00781205,\n",
       "           0.00781205, 0.00781205]],\n",
       " \n",
       "         [[0.00781023, 0.00781353, 0.0078137 , ..., 0.00781228,\n",
       "           0.00781228, 0.00781228],\n",
       "          [0.00781164, 0.00781411, 0.00781071, ..., 0.00781247,\n",
       "           0.00781247, 0.00781247],\n",
       "          [0.00780991, 0.00781486, 0.00781166, ..., 0.0078124 ,\n",
       "           0.0078124 , 0.0078124 ],\n",
       "          ...,\n",
       "          [0.00781143, 0.00781509, 0.00781132, ..., 0.00781222,\n",
       "           0.00781222, 0.00781222],\n",
       "          [0.00781197, 0.00781443, 0.00781274, ..., 0.00781227,\n",
       "           0.00781227, 0.00781227],\n",
       "          [0.00781093, 0.00781492, 0.00781473, ..., 0.0078122 ,\n",
       "           0.0078122 , 0.0078122 ]],\n",
       " \n",
       "         [[0.00781626, 0.00781045, 0.00781218, ..., 0.00781278,\n",
       "           0.00781278, 0.00781278],\n",
       "          [0.00781242, 0.00780701, 0.00780917, ..., 0.0078129 ,\n",
       "           0.0078129 , 0.0078129 ],\n",
       "          [0.00781428, 0.00780676, 0.00780528, ..., 0.00781307,\n",
       "           0.00781307, 0.00781307],\n",
       "          ...,\n",
       "          [0.00781593, 0.00780788, 0.00780747, ..., 0.00781284,\n",
       "           0.00781284, 0.00781284],\n",
       "          [0.00781313, 0.00780623, 0.00780587, ..., 0.00781326,\n",
       "           0.00781326, 0.00781326],\n",
       "          [0.00781857, 0.00780806, 0.0078092 , ..., 0.00781301,\n",
       "           0.00781301, 0.00781301]],\n",
       " \n",
       "         [[0.00781665, 0.00781685, 0.00781822, ..., 0.0078119 ,\n",
       "           0.0078119 , 0.0078119 ],\n",
       "          [0.00781442, 0.00781781, 0.00782361, ..., 0.00781141,\n",
       "           0.00781141, 0.00781141],\n",
       "          [0.00781983, 0.00782143, 0.00782476, ..., 0.00781118,\n",
       "           0.00781118, 0.00781118],\n",
       "          ...,\n",
       "          [0.00781454, 0.0078185 , 0.00782078, ..., 0.00781158,\n",
       "           0.00781158, 0.00781158],\n",
       "          [0.0078131 , 0.00781397, 0.00781673, ..., 0.0078121 ,\n",
       "           0.0078121 , 0.0078121 ],\n",
       "          [0.00781701, 0.00781713, 0.00781886, ..., 0.00781188,\n",
       "           0.00781188, 0.00781188]]]], dtype=float32)>)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attention[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4bd29ad1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Variable 'Variable:0' shape=(1, 8, 64) dtype=float32, numpy=\n",
       " array([[[ 0.97824246,  0.5974416 ,  0.00375594,  0.23254953,\n",
       "           0.22993088,  0.5955447 ,  0.17607917,  0.9732856 ,\n",
       "           0.9335298 ,  0.40274316,  0.03229064,  0.3560708 ,\n",
       "           0.6219572 ,  0.5183356 ,  1.0049845 ,  0.03811038,\n",
       "           0.28507778,  0.42520964,  0.39790943,  0.8667803 ,\n",
       "           0.6957693 ,  0.84650147,  0.11995757,  0.93961203,\n",
       "           0.24121642,  0.37429434,  0.4334079 ,  0.7966627 ,\n",
       "           0.0120051 ,  0.3501379 ,  0.04965518,  0.07324756,\n",
       "           0.03087216,  0.40470082,  0.726252  ,  0.00433213,\n",
       "           0.4536972 ,  0.85086304,  0.8707042 ,  0.15310346,\n",
       "           0.23801196,  0.12061308,  0.25752205,  0.6786174 ,\n",
       "           0.06412861,  0.71585965,  0.40815648,  0.42879924,\n",
       "           0.7573862 ,  0.7762137 ,  0.92630833,  0.10193264,\n",
       "           0.61462843,  0.3048497 ,  0.16122748,  0.6568268 ,\n",
       "           0.4650954 ,  0.34682822,  0.08825079,  0.93316704,\n",
       "           0.69303644,  0.44166785,  0.69549245,  0.6605126 ],\n",
       "         [ 0.8281372 ,  0.8874785 ,  0.11829961,  0.08023531,\n",
       "           0.4274655 ,  0.23374201,  0.16811702,  0.25084162,\n",
       "           0.47006977,  0.55254334,  0.95135516,  0.05746121,\n",
       "           0.35070947,  0.41751084,  0.21553318,  0.8692415 ,\n",
       "           0.8127577 ,  0.47000614,  0.9859046 ,  0.1624024 ,\n",
       "           0.81365055,  0.5025315 ,  0.6992852 ,  0.62195754,\n",
       "           0.849092  ,  0.40866834,  0.3716105 ,  0.01629933,\n",
       "           0.15427919,  0.18975514,  0.6317164 ,  0.4391429 ,\n",
       "           0.33329234,  0.85894126,  0.3248741 ,  0.65531707,\n",
       "           0.2555616 ,  0.3623853 ,  0.6560366 ,  0.8673966 ,\n",
       "           0.6025716 ,  0.2949161 ,  0.7085286 ,  0.5695833 ,\n",
       "           0.9483534 ,  0.19318391,  0.267844  ,  0.35900548,\n",
       "           0.9906833 ,  0.8706429 ,  0.24792449,  0.6059903 ,\n",
       "           0.21535732,  0.25053877, -0.00851414,  0.5355722 ,\n",
       "           0.755764  ,  0.06184495,  0.09728385,  0.84927833,\n",
       "           0.66278917,  0.61623645,  0.7311301 ,  0.3130638 ],\n",
       "         [ 0.5810451 ,  0.9767463 ,  0.01416342,  0.2817337 ,\n",
       "           0.41124898,  0.19546059,  0.18835795,  0.00999037,\n",
       "           0.7681113 ,  0.5957971 ,  0.25203672,  0.39043766,\n",
       "           0.01744007,  0.6803088 ,  0.06231946,  0.12748851,\n",
       "           0.07935833,  0.38679123,  0.38391972,  0.8602645 ,\n",
       "           0.82900846,  0.7076884 ,  0.82471156,  0.98181355,\n",
       "           0.6812958 ,  0.508417  ,  0.6886546 ,  0.17019218,\n",
       "           0.06383195,  0.94153965,  0.44493297,  0.1567566 ,\n",
       "           0.6082507 ,  0.89285636,  0.40341505,  0.5032867 ,\n",
       "           0.27418074,  0.65663904,  0.82386965,  0.22630465,\n",
       "           0.93163824,  0.72037613,  0.81358844,  0.86336976,\n",
       "           0.77777845,  0.1287708 ,  0.16810383,  0.8330797 ,\n",
       "           0.35481468,  0.66245395,  0.31287277,  0.24906835,\n",
       "           0.46507722,  0.71614254,  0.8240508 ,  0.5756153 ,\n",
       "           0.26971182,  0.60046744,  0.09534622,  0.31955028,\n",
       "           0.8105481 ,  0.8745944 ,  0.85870147,  0.7159155 ],\n",
       "         [ 0.5847105 ,  0.38217312,  0.3437684 ,  0.12301464,\n",
       "           0.13869138,  0.15763025,  0.3523697 ,  0.72589797,\n",
       "           0.618445  ,  0.14296292,  0.00147914,  0.7178158 ,\n",
       "           0.11810065,  0.3368505 ,  0.8115145 ,  0.13424185,\n",
       "           0.38129464,  0.8121778 ,  0.70185304,  0.19731903,\n",
       "           0.21559763,  0.09723122,  0.20929551,  0.09640621,\n",
       "           0.1967975 ,  0.0734721 ,  0.45521745,  0.04009094,\n",
       "           0.5690061 ,  0.31111395,  0.80649334,  0.064853  ,\n",
       "           0.0091613 ,  0.5461623 ,  0.83266073,  0.25553584,\n",
       "           0.44444296,  0.05985489,  0.2528961 ,  0.0822283 ,\n",
       "           0.6483788 ,  0.27455655,  0.02174682,  0.982061  ,\n",
       "           0.64104235,  0.35824773,  0.15164904,  0.13214764,\n",
       "           0.0472228 ,  0.6005471 ,  0.5021968 ,  0.05964812,\n",
       "           0.3538114 ,  0.78033864,  0.6927824 ,  0.9353366 ,\n",
       "           0.9854648 ,  0.30236933,  0.09606879,  0.2822195 ,\n",
       "           0.35372242,  0.64878047,  0.5218575 ,  0.8433587 ],\n",
       "         [ 0.04330634,  0.85164994,  0.6592402 ,  0.30464745,\n",
       "           0.50851345,  0.6512426 ,  0.19115093,  0.4207788 ,\n",
       "           0.63336307,  0.06942788,  0.5534036 ,  0.00150564,\n",
       "           0.31399372,  0.641598  ,  0.6113748 ,  0.11730114,\n",
       "           0.86148316,  0.2155337 ,  0.7132311 ,  0.06327683,\n",
       "           0.561038  ,  0.85338384,  0.73734033,  0.9211239 ,\n",
       "           0.76073956,  0.254753  ,  0.51882046,  0.92697835,\n",
       "           0.4922957 ,  0.50929487,  0.98501664,  0.30543134,\n",
       "           0.96245605,  0.05809683,  0.5734985 ,  0.78379124,\n",
       "           0.09547626,  0.29845223,  0.09108062,  0.543522  ,\n",
       "           0.67866594,  0.61413914,  0.7490615 ,  0.67743295,\n",
       "           0.63756204,  0.6257022 ,  0.24798653,  0.067578  ,\n",
       "           0.21136808,  0.03969147,  0.01421232,  0.98349315,\n",
       "           0.932258  ,  0.7399628 ,  0.07227788,  0.51896995,\n",
       "           0.77607936,  0.98202145,  0.8446403 ,  0.6565324 ,\n",
       "           0.15428302,  0.50233334,  0.2465607 ,  0.16817096],\n",
       "         [ 0.9636986 ,  0.59572077,  0.70727813,  0.17480619,\n",
       "           0.4610126 ,  0.25203675,  0.55786765,  0.31648168,\n",
       "           0.49405152,  0.52228075,  0.21978107,  0.24455345,\n",
       "           0.970547  ,  0.35645354,  0.4203873 ,  0.9717107 ,\n",
       "           0.7755067 ,  0.372805  ,  0.6451782 ,  0.62754154,\n",
       "           0.5322748 ,  0.35764363,  0.7471448 ,  0.31652012,\n",
       "           0.968178  ,  0.42210662,  0.8132814 ,  0.60801464,\n",
       "           0.62286246,  0.31114006,  0.6231446 ,  0.961546  ,\n",
       "           0.03238477,  0.97948736,  0.15796243,  0.65111583,\n",
       "           0.15055679,  0.71159345,  0.65409744,  0.7055023 ,\n",
       "           0.41099554,  0.17034672,  0.14614934,  0.19436367,\n",
       "           0.62219447,  0.69383466,  0.42748883,  0.3055191 ,\n",
       "           0.1558022 ,  0.21194401,  0.42559925,  0.5592469 ,\n",
       "           0.3452418 ,  0.14720382,  0.63733864,  0.53035325,\n",
       "           0.08530228,  0.29530597,  0.331903  ,  0.8218423 ,\n",
       "           0.9685283 ,  0.1716163 ,  0.83117616,  0.20484684],\n",
       "         [ 0.4816254 ,  0.8175809 ,  0.09092811,  0.25930163,\n",
       "           0.75981414,  0.08758111,  0.09290592,  0.09665404,\n",
       "           0.4822679 ,  0.80233365,  0.7009257 ,  0.57318145,\n",
       "           0.50138843,  0.1178119 ,  0.75484234,  0.5736582 ,\n",
       "           0.9664787 ,  0.01519688,  0.4094414 ,  0.08304475,\n",
       "           0.25920147,  0.06230672,  0.07475383,  0.36684868,\n",
       "           0.8976382 ,  0.31059116,  0.6146023 ,  0.3379181 ,\n",
       "           0.36615518,  0.8845062 ,  0.922152  ,  0.08306389,\n",
       "           0.6807039 ,  0.13146943,  0.92268866,  0.5793245 ,\n",
       "           0.8869386 ,  0.20343065,  0.00608589,  0.28219712,\n",
       "           0.24775475,  0.23940423,  0.9935852 ,  0.41501272,\n",
       "           0.5772268 ,  0.18399557,  0.25797325,  0.77864087,\n",
       "           0.8447339 ,  0.8829197 ,  0.3235644 ,  0.7025581 ,\n",
       "           0.83459467,  0.23469168,  0.5418813 ,  0.37799218,\n",
       "           0.41383484,  0.57877094,  0.6870747 ,  0.65649766,\n",
       "           0.94202834,  0.9271302 ,  0.721393  ,  0.90111446],\n",
       "         [ 0.402577  ,  0.37729377,  0.69322205,  0.41931343,\n",
       "           0.8160068 ,  0.05943399,  0.49493098,  0.67675155,\n",
       "           0.7377573 ,  0.352244  ,  0.33543336,  0.74658483,\n",
       "           0.5775448 ,  0.6894367 ,  0.490692  ,  0.18008731,\n",
       "           0.24722795,  0.40089816,  0.72732145,  0.6067268 ,\n",
       "           0.16643263,  0.6038145 ,  0.5204367 ,  0.3635949 ,\n",
       "           0.47575656,  0.7354527 ,  0.88766485,  0.34535563,\n",
       "           0.61988914,  0.9503081 ,  0.68879014,  0.71524316,\n",
       "           0.7946243 ,  0.48361462,  0.6937841 ,  0.4047492 ,\n",
       "           0.8305514 ,  0.26578668,  0.764223  ,  0.5265038 ,\n",
       "           0.712759  ,  0.98148155,  0.6681022 ,  0.6173479 ,\n",
       "           0.87097543,  0.5142971 ,  0.9117764 ,  0.381274  ,\n",
       "           0.2634328 ,  0.9210584 ,  0.8028938 ,  0.88487566,\n",
       "           0.92697704,  0.2787055 ,  0.43540192,  0.92872995,\n",
       "           0.46788785,  0.97294146,  0.2581754 ,  0.8541845 ,\n",
       "           0.87220997,  0.04026144,  0.19716313,  0.8484343 ]]],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 8, 64), dtype=float32, numpy=\n",
       " array([[[-1.2134249 ,  0.06157426, -0.62771225, -1.3665692 ,\n",
       "           1.2061712 ,  0.77129936,  0.76716405,  0.82724005,\n",
       "          -0.9052732 ,  1.0538965 , -0.731596  ,  0.3306431 ,\n",
       "          -0.5452227 , -0.05172697, -1.1178502 ,  0.7234627 ,\n",
       "           0.8729181 , -0.29091102,  0.73724383,  0.9352786 ,\n",
       "          -0.3159214 ,  1.1520624 , -0.85455173, -1.3069304 ,\n",
       "          -0.07917387, -0.21496461,  0.6408595 , -2.1983287 ,\n",
       "           1.0402429 ,  0.47474545, -0.13323182,  0.20395817,\n",
       "          -1.8211664 , -0.17911993, -1.4157684 , -1.825274  ,\n",
       "           0.75036275, -0.07306023, -0.06332931,  1.216023  ,\n",
       "           0.30771512, -0.8821611 ,  1.3970892 , -0.3567608 ,\n",
       "          -1.9311773 ,  0.484571  , -1.8805667 ,  0.80365163,\n",
       "           1.6719632 ,  0.8967481 , -0.2627821 , -1.1465083 ,\n",
       "           0.13696462, -0.22968641, -0.9682226 ,  0.80398285,\n",
       "           0.15912981,  1.8837067 ,  0.45766848, -1.5915565 ,\n",
       "           2.3416276 ,  0.39271796,  0.27114558,  0.86019075],\n",
       "         [-1.213424  ,  0.06157426, -0.62771267, -1.366569  ,\n",
       "           1.2061708 ,  0.7713    ,  0.76716346,  0.8272399 ,\n",
       "          -0.90527415,  1.0538969 , -0.73159593,  0.33064258,\n",
       "          -0.5452229 , -0.05172715, -1.1178496 ,  0.7234626 ,\n",
       "           0.87291855, -0.29091176,  0.7372434 ,  0.93527865,\n",
       "          -0.3159224 ,  1.1520624 , -0.8545516 , -1.3069304 ,\n",
       "          -0.07917411, -0.21496473,  0.64085907, -2.1983287 ,\n",
       "           1.0402428 ,  0.47474596, -0.13323256,  0.20395796,\n",
       "          -1.8211668 , -0.17911945, -1.4157684 , -1.8252739 ,\n",
       "           0.7503634 , -0.07306001, -0.06332958,  1.2160231 ,\n",
       "           0.30771497, -0.88216054,  1.3970891 , -0.35676038,\n",
       "          -1.931177  ,  0.48457143, -1.8805664 ,  0.8036523 ,\n",
       "           1.6719627 ,  0.89674824, -0.26278165, -1.1465086 ,\n",
       "           0.13696432, -0.22968608, -0.96822184,  0.8039827 ,\n",
       "           0.15913008,  1.8837067 ,  0.4576685 , -1.5915567 ,\n",
       "           2.341627  ,  0.39271817,  0.27114618,  0.86019105],\n",
       "         [-1.2134237 ,  0.06157456, -0.6277122 , -1.3665696 ,\n",
       "           1.2061704 ,  0.7713003 ,  0.767164  ,  0.8272399 ,\n",
       "          -0.9052733 ,  1.0538965 , -0.7315953 ,  0.3306425 ,\n",
       "          -0.5452232 , -0.05172687, -1.1178496 ,  0.72346324,\n",
       "           0.87291867, -0.2909115 ,  0.7372438 ,  0.93527824,\n",
       "          -0.31592217,  1.1520623 , -0.8545521 , -1.3069302 ,\n",
       "          -0.07917468, -0.21496463,  0.6408593 , -2.1983283 ,\n",
       "           1.0402424 ,  0.4747459 , -0.13323212,  0.20395851,\n",
       "          -1.8211671 , -0.17911911, -1.4157684 , -1.8252745 ,\n",
       "           0.75036347, -0.0730598 , -0.06332989,  1.2160225 ,\n",
       "           0.30771556, -0.882161  ,  1.3970889 , -0.35675982,\n",
       "          -1.9311775 ,  0.4845709 , -1.8805661 ,  0.8036517 ,\n",
       "           1.6719631 ,  0.89674747, -0.26278108, -1.1465094 ,\n",
       "           0.13696405, -0.22968663, -0.9682221 ,  0.80398196,\n",
       "           0.15913032,  1.8837066 ,  0.4576686 , -1.591557  ,\n",
       "           2.3416276 ,  0.39271718,  0.2711458 ,  0.86019105],\n",
       "         [-1.2134246 ,  0.06157453, -0.6277121 , -1.3665694 ,\n",
       "           1.2061707 ,  0.7713008 ,  0.767164  ,  0.82724   ,\n",
       "          -0.90527344,  1.0538963 , -0.73159593,  0.33064315,\n",
       "          -0.545223  , -0.05172668, -1.1178496 ,  0.72346294,\n",
       "           0.872919  , -0.29091156,  0.7372436 ,  0.9352785 ,\n",
       "          -0.3159218 ,  1.1520625 , -0.8545523 , -1.3069302 ,\n",
       "          -0.07917405, -0.21496516,  0.6408593 , -2.1983285 ,\n",
       "           1.0402422 ,  0.47474542, -0.13323292,  0.2039582 ,\n",
       "          -1.8211675 , -0.17911938, -1.4157677 , -1.8252738 ,\n",
       "           0.7503628 , -0.07305898, -0.06332973,  1.2160227 ,\n",
       "           0.307715  , -0.88216037,  1.3970886 , -0.35676047,\n",
       "          -1.9311773 ,  0.48457113, -1.8805664 ,  0.80365205,\n",
       "           1.6719631 ,  0.8967476 , -0.26278186, -1.146509  ,\n",
       "           0.1369645 , -0.22968662, -0.9682213 ,  0.80398184,\n",
       "           0.15913053,  1.8837066 ,  0.45766863, -1.591557  ,\n",
       "           2.341627  ,  0.3927181 ,  0.27114522,  0.8601913 ],\n",
       "         [-1.2134243 ,  0.06157476, -0.6277122 , -1.3665693 ,\n",
       "           1.2061706 ,  0.7713001 ,  0.7671637 ,  0.8272398 ,\n",
       "          -0.90527356,  1.0538967 , -0.7315956 ,  0.33064312,\n",
       "          -0.54522264, -0.05172659, -1.1178493 ,  0.7234628 ,\n",
       "           0.8729185 , -0.2909113 ,  0.7372438 ,  0.93527883,\n",
       "          -0.3159221 ,  1.1520625 , -0.85455203, -1.3069302 ,\n",
       "          -0.07917423, -0.21496521,  0.6408595 , -2.1983285 ,\n",
       "           1.0402423 ,  0.47474575, -0.13323227,  0.20395817,\n",
       "          -1.8211668 , -0.17911957, -1.4157679 , -1.8252739 ,\n",
       "           0.75036335, -0.07305977, -0.06332963,  1.2160224 ,\n",
       "           0.30771497, -0.88216084,  1.3970886 , -0.3567603 ,\n",
       "          -1.9311774 ,  0.48457062, -1.8805662 ,  0.8036523 ,\n",
       "           1.6719635 ,  0.89674675, -0.26278144, -1.1465087 ,\n",
       "           0.1369645 , -0.22968684, -0.96822166,  0.80398154,\n",
       "           0.15913074,  1.8837068 ,  0.45766807, -1.5915567 ,\n",
       "           2.3416266 ,  0.39271778,  0.27114624,  0.86019117],\n",
       "         [-1.2134241 ,  0.06157435, -0.6277125 , -1.3665696 ,\n",
       "           1.2061704 ,  0.77129984,  0.76716423,  0.82724005,\n",
       "          -0.9052739 ,  1.0538965 , -0.73159534,  0.33064294,\n",
       "          -0.545223  , -0.05172676, -1.1178493 ,  0.7234629 ,\n",
       "           0.8729185 , -0.29091105,  0.737244  ,  0.9352787 ,\n",
       "          -0.31592223,  1.1520625 , -0.85455215, -1.3069309 ,\n",
       "          -0.07917405, -0.21496473,  0.6408596 , -2.1983283 ,\n",
       "           1.0402418 ,  0.47474548, -0.13323182,  0.2039584 ,\n",
       "          -1.821167  , -0.17911936, -1.4157683 , -1.8252746 ,\n",
       "           0.75036293, -0.07305956, -0.06332979,  1.2160221 ,\n",
       "           0.3077156 , -0.88216096,  1.3970886 , -0.3567601 ,\n",
       "          -1.931177  ,  0.4845713 , -1.8805664 ,  0.80365187,\n",
       "           1.6719633 ,  0.896747  , -0.26278174, -1.1465088 ,\n",
       "           0.13696447, -0.22968696, -0.9682215 ,  0.8039825 ,\n",
       "           0.15913011,  1.8837073 ,  0.45766845, -1.5915568 ,\n",
       "           2.3416271 ,  0.3927177 ,  0.2711456 ,  0.8601914 ],\n",
       "         [-1.2134246 ,  0.06157447, -0.6277113 , -1.3665695 ,\n",
       "           1.2061709 ,  0.7713002 ,  0.76716405,  0.8272398 ,\n",
       "          -0.90527344,  1.0538965 , -0.7315955 ,  0.33064353,\n",
       "          -0.54522294, -0.05172682, -1.1178496 ,  0.7234629 ,\n",
       "           0.8729187 , -0.29091138,  0.7372437 ,  0.9352787 ,\n",
       "          -0.3159218 ,  1.1520628 , -0.85455185, -1.3069298 ,\n",
       "          -0.0791742 , -0.21496499,  0.64085937, -2.1983287 ,\n",
       "           1.0402421 ,  0.4747458 , -0.13323224,  0.20395838,\n",
       "          -1.8211673 , -0.17911907, -1.415768  , -1.8252739 ,\n",
       "           0.7503631 , -0.07305942, -0.06333005,  1.216023  ,\n",
       "           0.30771562, -0.88216084,  1.3970885 , -0.3567603 ,\n",
       "          -1.9311776 ,  0.4845707 , -1.8805666 ,  0.803652  ,\n",
       "           1.6719629 ,  0.89674735, -0.2627817 , -1.1465093 ,\n",
       "           0.13696444, -0.2296868 , -0.96822137,  0.80398214,\n",
       "           0.15913056,  1.8837063 ,  0.45766813, -1.5915568 ,\n",
       "           2.3416274 ,  0.3927176 ,  0.27114516,  0.86019105],\n",
       "         [-1.2134242 ,  0.06157389, -0.627712  , -1.3665695 ,\n",
       "           1.2061707 ,  0.7712999 ,  0.76716435,  0.8272408 ,\n",
       "          -0.90527374,  1.0538963 , -0.7315956 ,  0.3306427 ,\n",
       "          -0.5452228 , -0.05172734, -1.1178501 ,  0.72346294,\n",
       "           0.8729181 , -0.29091138,  0.7372437 ,  0.93527794,\n",
       "          -0.31592265,  1.1520628 , -0.8545522 , -1.3069302 ,\n",
       "          -0.07917506, -0.21496426,  0.6408594 , -2.1983278 ,\n",
       "           1.0402427 ,  0.47474632, -0.13323188,  0.2039584 ,\n",
       "          -1.821167  , -0.1791193 , -1.4157684 , -1.825274  ,\n",
       "           0.7503634 , -0.07305999, -0.06332965,  1.2160227 ,\n",
       "           0.3077154 , -0.88216203,  1.397089  , -0.35676035,\n",
       "          -1.9311773 ,  0.48457104, -1.8805662 ,  0.8036518 ,\n",
       "           1.6719633 ,  0.89674777, -0.2627812 , -1.1465087 ,\n",
       "           0.13696393, -0.22968702, -0.96822214,  0.8039828 ,\n",
       "           0.1591308 ,  1.8837072 ,  0.4576685 , -1.5915568 ,\n",
       "           2.3416274 ,  0.39271775,  0.27114555,  0.8601912 ]]],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 8, 64), dtype=float32, numpy=\n",
       " array([[[ 5.87150037e-01,  3.20269912e-01, -7.36464977e-01,\n",
       "          -7.12320268e-01, -1.64037132e+00,  2.21256167e-01,\n",
       "          -7.33170092e-01,  7.83796728e-01,  2.19813779e-01,\n",
       "          -1.49245858e+00,  1.36541319e+00,  1.98285893e-01,\n",
       "          -1.22125995e+00,  4.78693962e-01, -3.99931133e-01,\n",
       "          -1.43319935e-01, -9.31762636e-01,  1.35808277e+00,\n",
       "           7.38546789e-01,  5.70746660e-01,  1.14594769e+00,\n",
       "           2.58558057e-02,  2.05096149e+00,  1.84628832e+00,\n",
       "           3.58296663e-01, -4.33872461e-01,  9.04859960e-01,\n",
       "           1.71591207e-01, -4.76371288e-01, -1.76031458e+00,\n",
       "          -5.23945510e-01,  5.13254106e-01,  6.48716450e-01,\n",
       "           4.29474622e-01,  6.08770132e-01, -1.19883096e+00,\n",
       "          -5.19784451e-01, -1.34826982e+00,  6.81488216e-01,\n",
       "           7.49926925e-01, -1.60801840e+00,  1.05724525e+00,\n",
       "          -1.16050631e-01, -5.93489826e-01,  5.66411018e-01,\n",
       "          -2.41720140e-01,  7.01651037e-01, -9.67360675e-01,\n",
       "          -5.40849209e-01, -1.31385475e-01,  1.68597847e-01,\n",
       "           3.09773296e-01, -2.45776439e+00, -2.72954434e-01,\n",
       "          -2.01727295e+00,  1.65393323e-01,  3.36538285e-01,\n",
       "           1.14049077e+00,  1.87944695e-01, -1.59076869e+00,\n",
       "          -8.78529102e-02, -3.26507958e-03, -5.19550204e-01,\n",
       "           3.73204160e+00],\n",
       "         [ 5.87150097e-01,  3.20269942e-01, -7.36465096e-01,\n",
       "          -7.12320447e-01, -1.64037132e+00,  2.21256182e-01,\n",
       "          -7.33170092e-01,  7.83796668e-01,  2.19813719e-01,\n",
       "          -1.49245858e+00,  1.36541319e+00,  1.98285922e-01,\n",
       "          -1.22125995e+00,  4.78693932e-01, -3.99931133e-01,\n",
       "          -1.43319950e-01, -9.31762636e-01,  1.35808289e+00,\n",
       "           7.38546789e-01,  5.70746720e-01,  1.14594769e+00,\n",
       "           2.58558951e-02,  2.05096149e+00,  1.84628832e+00,\n",
       "           3.58296603e-01, -4.33872402e-01,  9.04859960e-01,\n",
       "           1.71591252e-01, -4.76371288e-01, -1.76031458e+00,\n",
       "          -5.23945510e-01,  5.13254046e-01,  6.48716450e-01,\n",
       "           4.29474652e-01,  6.08770192e-01, -1.19883096e+00,\n",
       "          -5.19784510e-01, -1.34826982e+00,  6.81488216e-01,\n",
       "           7.49926925e-01, -1.60801840e+00,  1.05724525e+00,\n",
       "          -1.16050638e-01, -5.93489885e-01,  5.66411018e-01,\n",
       "          -2.41720170e-01,  7.01651216e-01, -9.67360616e-01,\n",
       "          -5.40849268e-01, -1.31385520e-01,  1.68597877e-01,\n",
       "           3.09773266e-01, -2.45776439e+00, -2.72954434e-01,\n",
       "          -2.01727295e+00,  1.65393323e-01,  3.36538315e-01,\n",
       "           1.14049089e+00,  1.87944695e-01, -1.59076869e+00,\n",
       "          -8.78528878e-02, -3.26509355e-03, -5.19550264e-01,\n",
       "           3.73204160e+00],\n",
       "         [ 5.87150097e-01,  3.20269912e-01, -7.36464977e-01,\n",
       "          -7.12320387e-01, -1.64037132e+00,  2.21256152e-01,\n",
       "          -7.33170092e-01,  7.83796728e-01,  2.19813764e-01,\n",
       "          -1.49245858e+00,  1.36541319e+00,  1.98285893e-01,\n",
       "          -1.22125995e+00,  4.78694022e-01, -3.99931133e-01,\n",
       "          -1.43319935e-01, -9.31762636e-01,  1.35808277e+00,\n",
       "           7.38546789e-01,  5.70746660e-01,  1.14594769e+00,\n",
       "           2.58558653e-02,  2.05096149e+00,  1.84628832e+00,\n",
       "           3.58296603e-01, -4.33872402e-01,  9.04859960e-01,\n",
       "           1.71591237e-01, -4.76371288e-01, -1.76031458e+00,\n",
       "          -5.23945510e-01,  5.13254046e-01,  6.48716450e-01,\n",
       "           4.29474652e-01,  6.08770132e-01, -1.19883096e+00,\n",
       "          -5.19784510e-01, -1.34826982e+00,  6.81488216e-01,\n",
       "           7.49926925e-01, -1.60801840e+00,  1.05724525e+00,\n",
       "          -1.16050616e-01, -5.93489826e-01,  5.66411018e-01,\n",
       "          -2.41720155e-01,  7.01651216e-01, -9.67360616e-01,\n",
       "          -5.40849209e-01, -1.31385520e-01,  1.68597907e-01,\n",
       "           3.09773266e-01, -2.45776439e+00, -2.72954434e-01,\n",
       "          -2.01727295e+00,  1.65393323e-01,  3.36538285e-01,\n",
       "           1.14049077e+00,  1.87944695e-01, -1.59076881e+00,\n",
       "          -8.78528953e-02, -3.26507958e-03, -5.19550264e-01,\n",
       "           3.73204160e+00],\n",
       "         [ 5.87150097e-01,  3.20269942e-01, -7.36464918e-01,\n",
       "          -7.12320447e-01, -1.64037132e+00,  2.21256137e-01,\n",
       "          -7.33170092e-01,  7.83796668e-01,  2.19813734e-01,\n",
       "          -1.49245858e+00,  1.36541319e+00,  1.98285878e-01,\n",
       "          -1.22125995e+00,  4.78693932e-01, -3.99931133e-01,\n",
       "          -1.43319935e-01, -9.31762636e-01,  1.35808277e+00,\n",
       "           7.38546789e-01,  5.70746720e-01,  1.14594769e+00,\n",
       "           2.58557796e-02,  2.05096149e+00,  1.84628868e+00,\n",
       "           3.58296603e-01, -4.33872402e-01,  9.04859960e-01,\n",
       "           1.71591178e-01, -4.76371288e-01, -1.76031458e+00,\n",
       "          -5.23945510e-01,  5.13254046e-01,  6.48716450e-01,\n",
       "           4.29474652e-01,  6.08770192e-01, -1.19883108e+00,\n",
       "          -5.19784510e-01, -1.34826982e+00,  6.81488216e-01,\n",
       "           7.49926925e-01, -1.60801840e+00,  1.05724525e+00,\n",
       "          -1.16050661e-01, -5.93489826e-01,  5.66411018e-01,\n",
       "          -2.41720170e-01,  7.01651216e-01, -9.67360675e-01,\n",
       "          -5.40849268e-01, -1.31385490e-01,  1.68597877e-01,\n",
       "           3.09773237e-01, -2.45776439e+00, -2.72954464e-01,\n",
       "          -2.01727295e+00,  1.65393308e-01,  3.36538315e-01,\n",
       "           1.14049077e+00,  1.87944725e-01, -1.59076869e+00,\n",
       "          -8.78528953e-02, -3.26504139e-03, -5.19550323e-01,\n",
       "           3.73204160e+00],\n",
       "         [ 5.87149978e-01,  3.20269942e-01, -7.36465156e-01,\n",
       "          -7.12320268e-01, -1.64037156e+00,  2.21256152e-01,\n",
       "          -7.33170092e-01,  7.83796668e-01,  2.19813690e-01,\n",
       "          -1.49245858e+00,  1.36541343e+00,  1.98285863e-01,\n",
       "          -1.22125995e+00,  4.78693873e-01, -3.99931073e-01,\n",
       "          -1.43319905e-01, -9.31762636e-01,  1.35808277e+00,\n",
       "           7.38546789e-01,  5.70746720e-01,  1.14594769e+00,\n",
       "           2.58557983e-02,  2.05096149e+00,  1.84628868e+00,\n",
       "           3.58296603e-01, -4.33872491e-01,  9.04860020e-01,\n",
       "           1.71591133e-01, -4.76371288e-01, -1.76031458e+00,\n",
       "          -5.23945570e-01,  5.13254046e-01,  6.48716450e-01,\n",
       "           4.29474711e-01,  6.08770192e-01, -1.19883108e+00,\n",
       "          -5.19784510e-01, -1.34826982e+00,  6.81488216e-01,\n",
       "           7.49926865e-01, -1.60801840e+00,  1.05724525e+00,\n",
       "          -1.16050586e-01, -5.93489766e-01,  5.66411078e-01,\n",
       "          -2.41720185e-01,  7.01651216e-01, -9.67360735e-01,\n",
       "          -5.40849209e-01, -1.31385446e-01,  1.68597877e-01,\n",
       "           3.09773296e-01, -2.45776439e+00, -2.72954434e-01,\n",
       "          -2.01727271e+00,  1.65393308e-01,  3.36538345e-01,\n",
       "           1.14049077e+00,  1.87944770e-01, -1.59076881e+00,\n",
       "          -8.78529698e-02, -3.26504139e-03, -5.19550264e-01,\n",
       "           3.73204136e+00],\n",
       "         [ 5.87150097e-01,  3.20269912e-01, -7.36465096e-01,\n",
       "          -7.12320447e-01, -1.64037156e+00,  2.21256167e-01,\n",
       "          -7.33170211e-01,  7.83796668e-01,  2.19813704e-01,\n",
       "          -1.49245858e+00,  1.36541331e+00,  1.98285878e-01,\n",
       "          -1.22125995e+00,  4.78693932e-01, -3.99931133e-01,\n",
       "          -1.43319950e-01, -9.31762636e-01,  1.35808289e+00,\n",
       "           7.38546729e-01,  5.70746660e-01,  1.14594769e+00,\n",
       "           2.58558318e-02,  2.05096149e+00,  1.84628868e+00,\n",
       "           3.58296603e-01, -4.33872402e-01,  9.04859960e-01,\n",
       "           1.71591237e-01, -4.76371229e-01, -1.76031458e+00,\n",
       "          -5.23945510e-01,  5.13254046e-01,  6.48716450e-01,\n",
       "           4.29474682e-01,  6.08770251e-01, -1.19883096e+00,\n",
       "          -5.19784510e-01, -1.34826982e+00,  6.81488156e-01,\n",
       "           7.49926925e-01, -1.60801840e+00,  1.05724514e+00,\n",
       "          -1.16050631e-01, -5.93489766e-01,  5.66411018e-01,\n",
       "          -2.41720170e-01,  7.01651216e-01, -9.67360616e-01,\n",
       "          -5.40849268e-01, -1.31385535e-01,  1.68597907e-01,\n",
       "           3.09773237e-01, -2.45776439e+00, -2.72954434e-01,\n",
       "          -2.01727295e+00,  1.65393353e-01,  3.36538255e-01,\n",
       "           1.14049077e+00,  1.87944710e-01, -1.59076869e+00,\n",
       "          -8.78529251e-02, -3.26505536e-03, -5.19550323e-01,\n",
       "           3.73204160e+00],\n",
       "         [ 5.87150097e-01,  3.20269942e-01, -7.36465096e-01,\n",
       "          -7.12320268e-01, -1.64037132e+00,  2.21256137e-01,\n",
       "          -7.33170211e-01,  7.83796668e-01,  2.19813704e-01,\n",
       "          -1.49245858e+00,  1.36541319e+00,  1.98285863e-01,\n",
       "          -1.22125995e+00,  4.78693932e-01, -3.99931133e-01,\n",
       "          -1.43319964e-01, -9.31762636e-01,  1.35808289e+00,\n",
       "           7.38546789e-01,  5.70746720e-01,  1.14594769e+00,\n",
       "           2.58558914e-02,  2.05096149e+00,  1.84628832e+00,\n",
       "           3.58296603e-01, -4.33872402e-01,  9.04859960e-01,\n",
       "           1.71591237e-01, -4.76371288e-01, -1.76031458e+00,\n",
       "          -5.23945510e-01,  5.13254046e-01,  6.48716450e-01,\n",
       "           4.29474682e-01,  6.08770192e-01, -1.19883096e+00,\n",
       "          -5.19784510e-01, -1.34826982e+00,  6.81488276e-01,\n",
       "           7.49926925e-01, -1.60801840e+00,  1.05724525e+00,\n",
       "          -1.16050623e-01, -5.93489885e-01,  5.66411018e-01,\n",
       "          -2.41720200e-01,  7.01651096e-01, -9.67360616e-01,\n",
       "          -5.40849268e-01, -1.31385490e-01,  1.68597907e-01,\n",
       "           3.09773237e-01, -2.45776439e+00, -2.72954464e-01,\n",
       "          -2.01727295e+00,  1.65393308e-01,  3.36538315e-01,\n",
       "           1.14049089e+00,  1.87944695e-01, -1.59076869e+00,\n",
       "          -8.78529102e-02, -3.26509820e-03, -5.19550264e-01,\n",
       "           3.73204160e+00],\n",
       "         [ 5.87150097e-01,  3.20269883e-01, -7.36464977e-01,\n",
       "          -7.12320387e-01, -1.64037132e+00,  2.21256122e-01,\n",
       "          -7.33170092e-01,  7.83796787e-01,  2.19813764e-01,\n",
       "          -1.49245858e+00,  1.36541319e+00,  1.98285863e-01,\n",
       "          -1.22125995e+00,  4.78693992e-01, -3.99931133e-01,\n",
       "          -1.43319905e-01, -9.31762636e-01,  1.35808277e+00,\n",
       "           7.38546789e-01,  5.70746660e-01,  1.14594769e+00,\n",
       "           2.58558057e-02,  2.05096149e+00,  1.84628856e+00,\n",
       "           3.58296603e-01, -4.33872432e-01,  9.04859900e-01,\n",
       "           1.71591267e-01, -4.76371229e-01, -1.76031458e+00,\n",
       "          -5.23945451e-01,  5.13254046e-01,  6.48716390e-01,\n",
       "           4.29474652e-01,  6.08770251e-01, -1.19883096e+00,\n",
       "          -5.19784510e-01, -1.34826958e+00,  6.81488216e-01,\n",
       "           7.49926925e-01, -1.60801840e+00,  1.05724525e+00,\n",
       "          -1.16050631e-01, -5.93489826e-01,  5.66411018e-01,\n",
       "          -2.41720155e-01,  7.01651216e-01, -9.67360616e-01,\n",
       "          -5.40849209e-01, -1.31385550e-01,  1.68597847e-01,\n",
       "           3.09773296e-01, -2.45776439e+00, -2.72954375e-01,\n",
       "          -2.01727295e+00,  1.65393338e-01,  3.36538345e-01,\n",
       "           1.14049077e+00,  1.87944695e-01, -1.59076881e+00,\n",
       "          -8.78529400e-02, -3.26508889e-03, -5.19550264e-01,\n",
       "           3.73204160e+00]]], dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 8, 64), dtype=float32, numpy=\n",
       " array([[[-7.1088653 ,  0.76393574, -0.30715883, -0.7356172 ,\n",
       "           0.21878907,  0.32941166, -0.02708121,  0.72544914,\n",
       "          -0.6217228 ,  0.04176078,  0.5925138 , -0.3262681 ,\n",
       "           0.17033607,  0.07972481, -0.28071064, -0.8247616 ,\n",
       "          -0.15846069,  0.49883586, -0.12510958,  0.7163497 ,\n",
       "           0.870947  , -0.36155158, -2.7424269 , -0.74735713,\n",
       "           0.96899676, -0.46424967,  0.11526711, -0.10920988,\n",
       "           0.16571338,  0.23029208, -0.54434174, -0.7601449 ,\n",
       "           0.3402252 , -0.06564911,  0.48512834,  0.56373996,\n",
       "           0.18742122,  0.86063063, -0.00925638,  0.46289048,\n",
       "           0.73888046, -0.24965648, -0.7570384 ,  1.0645396 ,\n",
       "          -0.36935955, -0.16193408,  0.23952979, -0.08829568,\n",
       "           0.4239631 , -0.13698103,  0.44388688, -0.84631723,\n",
       "           1.0112395 , -0.29473925, -0.38983035,  0.6886825 ,\n",
       "           0.6346003 ,  1.4367839 ,  0.02871594, -0.08520981,\n",
       "           0.06101068,  1.4554969 ,  0.15073505,  0.23988774],\n",
       "         [-7.1088653 ,  0.7639356 , -0.30715877, -0.7356171 ,\n",
       "           0.21878913,  0.32941154, -0.02708117,  0.72544914,\n",
       "          -0.6217229 ,  0.04176076,  0.5925139 , -0.3262681 ,\n",
       "           0.17033604,  0.07972481, -0.28071064, -0.8247616 ,\n",
       "          -0.15846072,  0.49883592, -0.12510955,  0.7163497 ,\n",
       "           0.87094694, -0.36155155, -2.7424269 , -0.74735713,\n",
       "           0.9689968 , -0.46424964,  0.1152672 , -0.10920992,\n",
       "           0.16571349,  0.23029204, -0.5443418 , -0.7601449 ,\n",
       "           0.34022516, -0.0656492 ,  0.48512828,  0.56374   ,\n",
       "           0.18742129,  0.8606307 , -0.00925638,  0.46289042,\n",
       "           0.7388806 , -0.24965654, -0.7570383 ,  1.0645396 ,\n",
       "          -0.36935955, -0.16193406,  0.23952976, -0.08829558,\n",
       "           0.42396304, -0.13698108,  0.44388688, -0.8463171 ,\n",
       "           1.0112395 , -0.2947393 , -0.38983035,  0.6886825 ,\n",
       "           0.6346003 ,  1.4367839 ,  0.02871598, -0.08520981,\n",
       "           0.06101067,  1.4554969 ,  0.15073502,  0.23988774],\n",
       "         [-7.1088653 ,  0.7639357 , -0.30715883, -0.7356172 ,\n",
       "           0.21878907,  0.32941163, -0.02708114,  0.7254492 ,\n",
       "          -0.62172294,  0.04176077,  0.59251386, -0.3262681 ,\n",
       "           0.17033604,  0.0797248 , -0.2807106 , -0.8247616 ,\n",
       "          -0.15846074,  0.4988358 , -0.12510954,  0.7163497 ,\n",
       "           0.8709469 , -0.36155155, -2.742427  , -0.74735713,\n",
       "           0.96899676, -0.46424958,  0.1152671 , -0.1092099 ,\n",
       "           0.16571343,  0.23029199, -0.54434186, -0.7601449 ,\n",
       "           0.34022513, -0.06564914,  0.48512822,  0.56373996,\n",
       "           0.1874213 ,  0.86063063, -0.0092564 ,  0.46289045,\n",
       "           0.73888046, -0.24965654, -0.75703835,  1.0645396 ,\n",
       "          -0.36935955, -0.16193415,  0.23952973, -0.08829565,\n",
       "           0.423963  , -0.13698104,  0.44388688, -0.8463171 ,\n",
       "           1.0112395 , -0.29473928, -0.38983038,  0.6886825 ,\n",
       "           0.63460034,  1.436784  ,  0.028716  , -0.08520978,\n",
       "           0.06101069,  1.4554968 ,  0.15073507,  0.23988768],\n",
       "         [-7.1088653 ,  0.7639356 , -0.3071587 , -0.73561716,\n",
       "           0.2187891 ,  0.32941163, -0.02708117,  0.72544914,\n",
       "          -0.6217229 ,  0.04176084,  0.5925138 , -0.32626805,\n",
       "           0.17033604,  0.07972477, -0.28071052, -0.8247616 ,\n",
       "          -0.15846072,  0.49883574, -0.12510952,  0.71634966,\n",
       "           0.8709468 , -0.3615515 , -2.7424269 , -0.74735713,\n",
       "           0.96899676, -0.46424958,  0.1152671 , -0.10920998,\n",
       "           0.16571338,  0.23029202, -0.5443418 , -0.7601449 ,\n",
       "           0.3402251 , -0.06564915,  0.48512822,  0.56374   ,\n",
       "           0.18742134,  0.86063063, -0.00925641,  0.46289048,\n",
       "           0.73888046, -0.24965654, -0.7570383 ,  1.0645396 ,\n",
       "          -0.3693595 , -0.16193406,  0.23952973, -0.08829555,\n",
       "           0.42396307, -0.1369811 ,  0.44388688, -0.846317  ,\n",
       "           1.0112394 , -0.29473925, -0.38983035,  0.68868256,\n",
       "           0.63460034,  1.4367839 ,  0.02871593, -0.08520981,\n",
       "           0.0610106 ,  1.4554968 ,  0.15073505,  0.23988768],\n",
       "         [-7.1088653 ,  0.76393574, -0.3071587 , -0.73561716,\n",
       "           0.21878904,  0.3294117 , -0.0270811 ,  0.7254492 ,\n",
       "          -0.62172294,  0.04176086,  0.59251374, -0.32626805,\n",
       "           0.1703361 ,  0.07972474, -0.28071052, -0.82476145,\n",
       "          -0.15846069,  0.49883568, -0.12510955,  0.7163497 ,\n",
       "           0.8709468 , -0.36155155, -2.7424269 , -0.74735713,\n",
       "           0.96899664, -0.46424967,  0.11526719, -0.10920995,\n",
       "           0.16571338,  0.23029198, -0.5443418 , -0.7601449 ,\n",
       "           0.34022516, -0.06564917,  0.48512828,  0.56373996,\n",
       "           0.18742128,  0.86063063, -0.00925636,  0.46289048,\n",
       "           0.7388804 , -0.24965648, -0.7570383 ,  1.0645396 ,\n",
       "          -0.3693595 , -0.16193406,  0.23952976, -0.08829565,\n",
       "           0.42396304, -0.1369811 ,  0.44388682, -0.846317  ,\n",
       "           1.0112394 , -0.29473922, -0.38983035,  0.68868256,\n",
       "           0.6346004 ,  1.4367839 ,  0.02871596, -0.08520976,\n",
       "           0.06101063,  1.4554968 ,  0.15073508,  0.23988765],\n",
       "         [-7.1088653 ,  0.7639357 , -0.3071588 , -0.73561716,\n",
       "           0.21878904,  0.32941163, -0.02708118,  0.7254491 ,\n",
       "          -0.62172276,  0.04176078,  0.5925137 , -0.32626814,\n",
       "           0.17033605,  0.0797248 , -0.28071067, -0.82476157,\n",
       "          -0.15846068,  0.4988358 , -0.12510957,  0.71634966,\n",
       "           0.870947  , -0.36155158, -2.7424269 , -0.7473571 ,\n",
       "           0.9689966 , -0.46424964,  0.11526713, -0.10920992,\n",
       "           0.16571333,  0.23029208, -0.54434174, -0.7601448 ,\n",
       "           0.34022516, -0.06564913,  0.48512828,  0.56373996,\n",
       "           0.18742122,  0.8606306 , -0.00925636,  0.46289042,\n",
       "           0.7388804 , -0.24965642, -0.7570383 ,  1.0645396 ,\n",
       "          -0.36935952, -0.16193408,  0.23952979, -0.08829573,\n",
       "           0.423963  , -0.13698103,  0.44388682, -0.8463172 ,\n",
       "           1.0112394 , -0.29473925, -0.38983038,  0.6886825 ,\n",
       "           0.6346002 ,  1.4367839 ,  0.02871596, -0.08520981,\n",
       "           0.06101062,  1.4554968 ,  0.15073504,  0.23988774],\n",
       "         [-7.1088653 ,  0.76393574, -0.30715883, -0.73561716,\n",
       "           0.2187891 ,  0.32941166, -0.02708113,  0.7254492 ,\n",
       "          -0.62172294,  0.04176078,  0.5925139 , -0.326268  ,\n",
       "           0.17033602,  0.07972473, -0.28071064, -0.8247616 ,\n",
       "          -0.15846072,  0.49883592, -0.12510955,  0.71634966,\n",
       "           0.8709469 , -0.36155155, -2.7424269 , -0.74735713,\n",
       "           0.96899676, -0.46424958,  0.11526717, -0.10920985,\n",
       "           0.16571344,  0.23029196, -0.5443418 , -0.7601449 ,\n",
       "           0.34022516, -0.06564913,  0.48512822,  0.5637399 ,\n",
       "           0.18742129,  0.86063063, -0.00925641,  0.46289042,\n",
       "           0.7388804 , -0.24965657, -0.7570383 ,  1.0645396 ,\n",
       "          -0.3693595 , -0.16193411,  0.23952973, -0.08829563,\n",
       "           0.42396304, -0.13698097,  0.44388688, -0.8463171 ,\n",
       "           1.0112395 , -0.29473925, -0.3898304 ,  0.6886825 ,\n",
       "           0.63460034,  1.436784  ,  0.02871601, -0.08520979,\n",
       "           0.06101068,  1.4554968 ,  0.15073508,  0.23988762],\n",
       "         [-7.1088653 ,  0.76393557, -0.30715874, -0.73561716,\n",
       "           0.21878913,  0.3294115 , -0.02708121,  0.7254492 ,\n",
       "          -0.62172294,  0.04176073,  0.59251386, -0.32626814,\n",
       "           0.17033604,  0.07972478, -0.28071067, -0.8247616 ,\n",
       "          -0.15846072,  0.4988358 , -0.12510958,  0.7163497 ,\n",
       "           0.8709469 , -0.36155158, -2.742427  , -0.74735725,\n",
       "           0.96899676, -0.46424967,  0.11526711, -0.10920994,\n",
       "           0.16571346,  0.23029199, -0.5443419 , -0.7601449 ,\n",
       "           0.34022513, -0.06564923,  0.48512822,  0.56373996,\n",
       "           0.18742128,  0.86063063, -0.00925644,  0.46289045,\n",
       "           0.7388805 , -0.24965651, -0.75703835,  1.0645396 ,\n",
       "          -0.36935952, -0.16193414,  0.23952976, -0.08829561,\n",
       "           0.423963  , -0.13698106,  0.44388682, -0.8463171 ,\n",
       "           1.0112395 , -0.29473934, -0.38983038,  0.6886825 ,\n",
       "           0.6346003 ,  1.436784  ,  0.02871596, -0.08520984,\n",
       "           0.06101062,  1.4554968 ,  0.15073496,  0.23988771]]],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 8, 64), dtype=float32, numpy=\n",
       " array([[[ 1.27739286e+00,  1.03316940e-01,  2.70817317e-02,\n",
       "           3.33512276e-02,  5.69610000e-01,  1.18749849e-01,\n",
       "           1.21005523e+00,  7.89851993e-02,  1.71022266e-01,\n",
       "          -1.66140878e+00,  2.99577564e-01,  3.52768153e-02,\n",
       "           4.44957651e-02,  9.76787448e-01,  2.01330520e-02,\n",
       "          -8.26560184e-02, -1.97298661e-01, -1.51756555e-01,\n",
       "           1.59416080e-01,  1.98887810e-02, -2.95425896e-02,\n",
       "          -4.24772501e-01, -1.14513695e+00,  5.55832028e-01,\n",
       "          -7.94034600e-01, -8.02546926e-03, -3.51113454e-03,\n",
       "          -1.02864671e+00,  6.38300925e-02, -5.15456676e-01,\n",
       "          -3.29961777e-02,  1.78818759e-02, -4.40455191e-02,\n",
       "           2.23881491e-02, -3.46019380e-02, -4.33677509e-02,\n",
       "          -3.59327346e-02, -5.17526865e-02,  2.80012965e-01,\n",
       "           4.70851548e-03, -7.16616750e-01,  6.81887791e-02,\n",
       "          -2.20032558e-02,  1.26845017e-02, -2.49884985e-02,\n",
       "           6.30226545e-03,  3.52391392e-01, -9.08268690e-02,\n",
       "          -5.90582341e-02,  3.15135419e-02,  4.79192548e-02,\n",
       "           7.56414235e-02,  2.48038128e-01, -3.60464528e-02,\n",
       "          -1.00915693e-02, -1.73711218e-04,  3.84298921e+00,\n",
       "           4.55546938e-03, -2.88714588e-01, -2.17789765e-02,\n",
       "          -6.32438809e-02, -1.82793625e-02, -2.66459846e+00,\n",
       "           3.45391743e-02],\n",
       "         [ 1.27739286e+00,  1.03316911e-01,  2.70817764e-02,\n",
       "           3.33513319e-02,  5.69609880e-01,  1.18749864e-01,\n",
       "           1.21005523e+00,  7.89852142e-02,  1.71022251e-01,\n",
       "          -1.66140878e+00,  2.99577653e-01,  3.52768824e-02,\n",
       "           4.44958173e-02,  9.76787567e-01,  2.01330930e-02,\n",
       "          -8.26559439e-02, -1.97298750e-01, -1.51756495e-01,\n",
       "           1.59416035e-01,  1.98887810e-02, -2.95427367e-02,\n",
       "          -4.24772561e-01, -1.14513695e+00,  5.55832088e-01,\n",
       "          -7.94034779e-01, -8.02549534e-03, -3.51112336e-03,\n",
       "          -1.02864683e+00,  6.38300478e-02, -5.15456796e-01,\n",
       "          -3.29962820e-02,  1.78817511e-02, -4.40456234e-02,\n",
       "           2.23880708e-02, -3.46020348e-02, -4.33678031e-02,\n",
       "          -3.59327570e-02, -5.17527163e-02,  2.80012876e-01,\n",
       "           4.70840000e-03, -7.16616750e-01,  6.81888685e-02,\n",
       "          -2.20032688e-02,  1.26845166e-02, -2.49884687e-02,\n",
       "           6.30235113e-03,  3.52391422e-01, -9.08268243e-02,\n",
       "          -5.90581298e-02,  3.15136313e-02,  4.79191951e-02,\n",
       "           7.56413490e-02,  2.48038158e-01, -3.60465124e-02,\n",
       "          -1.00914463e-02, -1.73743814e-04,  3.84298921e+00,\n",
       "           4.55538463e-03, -2.88714647e-01, -2.17790101e-02,\n",
       "          -6.32438958e-02, -1.82792358e-02, -2.66459846e+00,\n",
       "           3.45393047e-02],\n",
       "         [ 1.27739298e+00,  1.03316925e-01,  2.70817541e-02,\n",
       "           3.33512127e-02,  5.69610000e-01,  1.18749864e-01,\n",
       "           1.21005523e+00,  7.89852291e-02,  1.71022281e-01,\n",
       "          -1.66140902e+00,  2.99577534e-01,  3.52768116e-02,\n",
       "           4.44958098e-02,  9.76787329e-01,  2.01330651e-02,\n",
       "          -8.26560035e-02, -1.97298676e-01, -1.51756555e-01,\n",
       "           1.59416094e-01,  1.98887810e-02, -2.95425821e-02,\n",
       "          -4.24772501e-01, -1.14513695e+00,  5.55832028e-01,\n",
       "          -7.94034779e-01, -8.02549906e-03, -3.51108797e-03,\n",
       "          -1.02864671e+00,  6.38301075e-02, -5.15456676e-01,\n",
       "          -3.29961181e-02,  1.78819094e-02, -4.40455042e-02,\n",
       "           2.23881379e-02, -3.46019529e-02, -4.33677360e-02,\n",
       "          -3.59326899e-02, -5.17526604e-02,  2.80012965e-01,\n",
       "           4.70855553e-03, -7.16616869e-01,  6.81887716e-02,\n",
       "          -2.20032334e-02,  1.26845390e-02, -2.49884687e-02,\n",
       "           6.30227663e-03,  3.52391392e-01, -9.08268392e-02,\n",
       "          -5.90582043e-02,  3.15135270e-02,  4.79192697e-02,\n",
       "           7.56414533e-02,  2.48038098e-01, -3.60464230e-02,\n",
       "          -1.00915842e-02, -1.73715875e-04,  3.84298921e+00,\n",
       "           4.55552246e-03, -2.88714617e-01, -2.17789244e-02,\n",
       "          -6.32438883e-02, -1.82793569e-02, -2.66459870e+00,\n",
       "           3.45392004e-02],\n",
       "         [ 1.27739286e+00,  1.03316881e-01,  2.70817429e-02,\n",
       "           3.33511680e-02,  5.69609940e-01,  1.18749835e-01,\n",
       "           1.21005523e+00,  7.89851248e-02,  1.71022281e-01,\n",
       "          -1.66140902e+00,  2.99577624e-01,  3.52768227e-02,\n",
       "           4.44958098e-02,  9.76787448e-01,  2.01330706e-02,\n",
       "          -8.26559886e-02, -1.97298750e-01, -1.51756495e-01,\n",
       "           1.59416139e-01,  1.98888257e-02, -2.95426063e-02,\n",
       "          -4.24772501e-01, -1.14513695e+00,  5.55832028e-01,\n",
       "          -7.94034779e-01, -8.02548602e-03, -3.51109356e-03,\n",
       "          -1.02864671e+00,  6.38301224e-02, -5.15456617e-01,\n",
       "          -3.29962671e-02,  1.78819057e-02, -4.40455414e-02,\n",
       "           2.23880988e-02, -3.46019752e-02, -4.33678031e-02,\n",
       "          -3.59326825e-02, -5.17526679e-02,  2.80012965e-01,\n",
       "           4.70855646e-03, -7.16616809e-01,  6.81887940e-02,\n",
       "          -2.20032278e-02,  1.26845129e-02, -2.49883942e-02,\n",
       "           6.30228780e-03,  3.52391362e-01, -9.08268690e-02,\n",
       "          -5.90582415e-02,  3.15134972e-02,  4.79192846e-02,\n",
       "           7.56413862e-02,  2.48038068e-01, -3.60464640e-02,\n",
       "          -1.00915730e-02, -1.73759647e-04,  3.84298921e+00,\n",
       "           4.55554482e-03, -2.88714588e-01, -2.17789914e-02,\n",
       "          -6.32439405e-02, -1.82793792e-02, -2.66459823e+00,\n",
       "           3.45392041e-02],\n",
       "         [ 1.27739275e+00,  1.03316836e-01,  2.70817503e-02,\n",
       "           3.33511382e-02,  5.69609940e-01,  1.18749835e-01,\n",
       "           1.21005535e+00,  7.89851546e-02,  1.71022296e-01,\n",
       "          -1.66140902e+00,  2.99577653e-01,  3.52768339e-02,\n",
       "           4.44958471e-02,  9.76787448e-01,  2.01330818e-02,\n",
       "          -8.26560035e-02, -1.97298735e-01, -1.51756525e-01,\n",
       "           1.59416154e-01,  1.98888481e-02, -2.95426659e-02,\n",
       "          -4.24772441e-01, -1.14513695e+00,  5.55832028e-01,\n",
       "          -7.94034779e-01, -8.02548602e-03, -3.51107586e-03,\n",
       "          -1.02864671e+00,  6.38301224e-02, -5.15456617e-01,\n",
       "          -3.29962745e-02,  1.78819168e-02, -4.40455340e-02,\n",
       "           2.23880447e-02, -3.46020050e-02, -4.33678105e-02,\n",
       "          -3.59327048e-02, -5.17527051e-02,  2.80012935e-01,\n",
       "           4.70856298e-03, -7.16616809e-01,  6.81888089e-02,\n",
       "          -2.20031943e-02,  1.26845129e-02, -2.49884240e-02,\n",
       "           6.30226173e-03,  3.52391362e-01, -9.08268988e-02,\n",
       "          -5.90582192e-02,  3.15134674e-02,  4.79192846e-02,\n",
       "           7.56413713e-02,  2.48038128e-01, -3.60464454e-02,\n",
       "          -1.00915506e-02, -1.73820183e-04,  3.84298921e+00,\n",
       "           4.55553923e-03, -2.88714617e-01, -2.17789579e-02,\n",
       "          -6.32439256e-02, -1.82793681e-02, -2.66459823e+00,\n",
       "           3.45392302e-02],\n",
       "         [ 1.27739275e+00,  1.03316911e-01,  2.70817764e-02,\n",
       "           3.33513021e-02,  5.69609880e-01,  1.18749835e-01,\n",
       "           1.21005523e+00,  7.89851993e-02,  1.71022236e-01,\n",
       "          -1.66140902e+00,  2.99577653e-01,  3.52768786e-02,\n",
       "           4.44958769e-02,  9.76787448e-01,  2.01331005e-02,\n",
       "          -8.26559439e-02, -1.97298750e-01, -1.51756525e-01,\n",
       "           1.59416050e-01,  1.98887698e-02, -2.95427591e-02,\n",
       "          -4.24772561e-01, -1.14513695e+00,  5.55832028e-01,\n",
       "          -7.94034779e-01, -8.02550465e-03, -3.51112057e-03,\n",
       "          -1.02864671e+00,  6.38300329e-02, -5.15456796e-01,\n",
       "          -3.29962671e-02,  1.78817660e-02, -4.40456234e-02,\n",
       "           2.23880261e-02, -3.46020348e-02, -4.33678553e-02,\n",
       "          -3.59327421e-02, -5.17527349e-02,  2.80012906e-01,\n",
       "           4.70837671e-03, -7.16616690e-01,  6.81888461e-02,\n",
       "          -2.20032744e-02,  1.26845278e-02, -2.49884836e-02,\n",
       "           6.30236976e-03,  3.52391362e-01, -9.08268392e-02,\n",
       "          -5.90581670e-02,  3.15136164e-02,  4.79192100e-02,\n",
       "           7.56413639e-02,  2.48038188e-01, -3.60464975e-02,\n",
       "          -1.00914799e-02, -1.73763372e-04,  3.84298944e+00,\n",
       "           4.55540791e-03, -2.88714677e-01, -2.17790045e-02,\n",
       "          -6.32439554e-02, -1.82792433e-02, -2.66459823e+00,\n",
       "           3.45392972e-02],\n",
       "         [ 1.27739286e+00,  1.03317000e-01,  2.70817652e-02,\n",
       "           3.33513096e-02,  5.69609821e-01,  1.18749909e-01,\n",
       "           1.21005523e+00,  7.89851844e-02,  1.71022356e-01,\n",
       "          -1.66140902e+00,  2.99577773e-01,  3.52769308e-02,\n",
       "           4.44959290e-02,  9.76787567e-01,  2.01330911e-02,\n",
       "          -8.26559439e-02, -1.97298735e-01, -1.51756525e-01,\n",
       "           1.59416094e-01,  1.98887587e-02, -2.95427404e-02,\n",
       "          -4.24772501e-01, -1.14513695e+00,  5.55832028e-01,\n",
       "          -7.94034898e-01, -8.02545622e-03, -3.51105817e-03,\n",
       "          -1.02864671e+00,  6.38301075e-02, -5.15456796e-01,\n",
       "          -3.29962298e-02,  1.78818144e-02, -4.40455638e-02,\n",
       "           2.23880559e-02, -3.46020721e-02, -4.33678105e-02,\n",
       "          -3.59327719e-02, -5.17526790e-02,  2.80012906e-01,\n",
       "           4.70835716e-03, -7.16616869e-01,  6.81888908e-02,\n",
       "          -2.20032819e-02,  1.26845054e-02, -2.49883831e-02,\n",
       "           6.30241074e-03,  3.52391422e-01, -9.08268243e-02,\n",
       "          -5.90580851e-02,  3.15136015e-02,  4.79191132e-02,\n",
       "           7.56413639e-02,  2.48038158e-01, -3.60464342e-02,\n",
       "          -1.00913979e-02, -1.73714943e-04,  3.84298921e+00,\n",
       "           4.55546472e-03, -2.88714617e-01, -2.17789244e-02,\n",
       "          -6.32438436e-02, -1.82792637e-02, -2.66459846e+00,\n",
       "           3.45394015e-02],\n",
       "         [ 1.27739286e+00,  1.03316940e-01,  2.70817354e-02,\n",
       "           3.33512276e-02,  5.69609940e-01,  1.18749879e-01,\n",
       "           1.21005523e+00,  7.89852142e-02,  1.71022296e-01,\n",
       "          -1.66140902e+00,  2.99577564e-01,  3.52768041e-02,\n",
       "           4.44958545e-02,  9.76787448e-01,  2.01330576e-02,\n",
       "          -8.26560333e-02, -1.97298676e-01, -1.51756585e-01,\n",
       "           1.59416094e-01,  1.98888108e-02, -2.95425877e-02,\n",
       "          -4.24772561e-01, -1.14513695e+00,  5.55832028e-01,\n",
       "          -7.94034660e-01, -8.02547298e-03, -3.51116341e-03,\n",
       "          -1.02864671e+00,  6.38301373e-02, -5.15456617e-01,\n",
       "          -3.29961479e-02,  1.78819150e-02, -4.40455116e-02,\n",
       "           2.23881453e-02, -3.46019603e-02, -4.33677435e-02,\n",
       "          -3.59327421e-02, -5.17526567e-02,  2.80012935e-01,\n",
       "           4.70852852e-03, -7.16616750e-01,  6.81887791e-02,\n",
       "          -2.20032502e-02,  1.26844719e-02, -2.49884911e-02,\n",
       "           6.30228035e-03,  3.52391392e-01, -9.08268541e-02,\n",
       "          -5.90582415e-02,  3.15135419e-02,  4.79192398e-02,\n",
       "           7.56414533e-02,  2.48038158e-01, -3.60464230e-02,\n",
       "          -1.00915618e-02, -1.73732638e-04,  3.84298921e+00,\n",
       "           4.55549452e-03, -2.88714617e-01, -2.17789635e-02,\n",
       "          -6.32439107e-02, -1.82793811e-02, -2.66459846e+00,\n",
       "           3.45392115e-02]]], dtype=float32)>]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6773a0fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(32, 4, 128, 128), dtype=float32, numpy=\n",
       "array([[[[1., 1., 1., ..., 1., 1., 1.],\n",
       "         [1., 1., 1., ..., 1., 1., 1.],\n",
       "         [1., 1., 1., ..., 1., 1., 1.],\n",
       "         ...,\n",
       "         [1., 1., 1., ..., 1., 1., 1.],\n",
       "         [1., 1., 1., ..., 1., 1., 1.],\n",
       "         [1., 1., 1., ..., 1., 1., 1.]],\n",
       "\n",
       "        [[1., 1., 1., ..., 1., 1., 1.],\n",
       "         [1., 1., 1., ..., 1., 1., 1.],\n",
       "         [1., 1., 1., ..., 1., 1., 1.],\n",
       "         ...,\n",
       "         [1., 1., 1., ..., 1., 1., 1.],\n",
       "         [1., 1., 1., ..., 1., 1., 1.],\n",
       "         [1., 1., 1., ..., 1., 1., 1.]],\n",
       "\n",
       "        [[1., 1., 1., ..., 1., 1., 1.],\n",
       "         [1., 1., 1., ..., 1., 1., 1.],\n",
       "         [1., 1., 1., ..., 1., 1., 1.],\n",
       "         ...,\n",
       "         [1., 1., 1., ..., 1., 1., 1.],\n",
       "         [1., 1., 1., ..., 1., 1., 1.],\n",
       "         [1., 1., 1., ..., 1., 1., 1.]],\n",
       "\n",
       "        [[1., 1., 1., ..., 1., 1., 1.],\n",
       "         [1., 1., 1., ..., 1., 1., 1.],\n",
       "         [1., 1., 1., ..., 1., 1., 1.],\n",
       "         ...,\n",
       "         [1., 1., 1., ..., 1., 1., 1.],\n",
       "         [1., 1., 1., ..., 1., 1., 1.],\n",
       "         [1., 1., 1., ..., 1., 1., 1.]]],\n",
       "\n",
       "\n",
       "       [[[1., 1., 1., ..., 1., 1., 1.],\n",
       "         [1., 1., 1., ..., 1., 1., 1.],\n",
       "         [1., 1., 1., ..., 1., 1., 1.],\n",
       "         ...,\n",
       "         [1., 1., 1., ..., 1., 1., 1.],\n",
       "         [1., 1., 1., ..., 1., 1., 1.],\n",
       "         [1., 1., 1., ..., 1., 1., 1.]],\n",
       "\n",
       "        [[1., 1., 1., ..., 1., 1., 1.],\n",
       "         [1., 1., 1., ..., 1., 1., 1.],\n",
       "         [1., 1., 1., ..., 1., 1., 1.],\n",
       "         ...,\n",
       "         [1., 1., 1., ..., 1., 1., 1.],\n",
       "         [1., 1., 1., ..., 1., 1., 1.],\n",
       "         [1., 1., 1., ..., 1., 1., 1.]],\n",
       "\n",
       "        [[1., 1., 1., ..., 1., 1., 1.],\n",
       "         [1., 1., 1., ..., 1., 1., 1.],\n",
       "         [1., 1., 1., ..., 1., 1., 1.],\n",
       "         ...,\n",
       "         [1., 1., 1., ..., 1., 1., 1.],\n",
       "         [1., 1., 1., ..., 1., 1., 1.],\n",
       "         [1., 1., 1., ..., 1., 1., 1.]],\n",
       "\n",
       "        [[1., 1., 1., ..., 1., 1., 1.],\n",
       "         [1., 1., 1., ..., 1., 1., 1.],\n",
       "         [1., 1., 1., ..., 1., 1., 1.],\n",
       "         ...,\n",
       "         [1., 1., 1., ..., 1., 1., 1.],\n",
       "         [1., 1., 1., ..., 1., 1., 1.],\n",
       "         [1., 1., 1., ..., 1., 1., 1.]]],\n",
       "\n",
       "\n",
       "       [[[1., 1., 1., ..., 1., 1., 1.],\n",
       "         [1., 1., 1., ..., 1., 1., 1.],\n",
       "         [1., 1., 1., ..., 1., 1., 1.],\n",
       "         ...,\n",
       "         [1., 1., 1., ..., 1., 1., 1.],\n",
       "         [1., 1., 1., ..., 1., 1., 1.],\n",
       "         [1., 1., 1., ..., 1., 1., 1.]],\n",
       "\n",
       "        [[1., 1., 1., ..., 1., 1., 1.],\n",
       "         [1., 1., 1., ..., 1., 1., 1.],\n",
       "         [1., 1., 1., ..., 1., 1., 1.],\n",
       "         ...,\n",
       "         [1., 1., 1., ..., 1., 1., 1.],\n",
       "         [1., 1., 1., ..., 1., 1., 1.],\n",
       "         [1., 1., 1., ..., 1., 1., 1.]],\n",
       "\n",
       "        [[1., 1., 1., ..., 1., 1., 1.],\n",
       "         [1., 1., 1., ..., 1., 1., 1.],\n",
       "         [1., 1., 1., ..., 1., 1., 1.],\n",
       "         ...,\n",
       "         [1., 1., 1., ..., 1., 1., 1.],\n",
       "         [1., 1., 1., ..., 1., 1., 1.],\n",
       "         [1., 1., 1., ..., 1., 1., 1.]],\n",
       "\n",
       "        [[1., 1., 1., ..., 1., 1., 1.],\n",
       "         [1., 1., 1., ..., 1., 1., 1.],\n",
       "         [1., 1., 1., ..., 1., 1., 1.],\n",
       "         ...,\n",
       "         [1., 1., 1., ..., 1., 1., 1.],\n",
       "         [1., 1., 1., ..., 1., 1., 1.],\n",
       "         [1., 1., 1., ..., 1., 1., 1.]]],\n",
       "\n",
       "\n",
       "       ...,\n",
       "\n",
       "\n",
       "       [[[1., 1., 1., ..., 1., 1., 1.],\n",
       "         [1., 1., 1., ..., 1., 1., 1.],\n",
       "         [1., 1., 1., ..., 1., 1., 1.],\n",
       "         ...,\n",
       "         [1., 1., 1., ..., 1., 1., 1.],\n",
       "         [1., 1., 1., ..., 1., 1., 1.],\n",
       "         [1., 1., 1., ..., 1., 1., 1.]],\n",
       "\n",
       "        [[1., 1., 1., ..., 1., 1., 1.],\n",
       "         [1., 1., 1., ..., 1., 1., 1.],\n",
       "         [1., 1., 1., ..., 1., 1., 1.],\n",
       "         ...,\n",
       "         [1., 1., 1., ..., 1., 1., 1.],\n",
       "         [1., 1., 1., ..., 1., 1., 1.],\n",
       "         [1., 1., 1., ..., 1., 1., 1.]],\n",
       "\n",
       "        [[1., 1., 1., ..., 1., 1., 1.],\n",
       "         [1., 1., 1., ..., 1., 1., 1.],\n",
       "         [1., 1., 1., ..., 1., 1., 1.],\n",
       "         ...,\n",
       "         [1., 1., 1., ..., 1., 1., 1.],\n",
       "         [1., 1., 1., ..., 1., 1., 1.],\n",
       "         [1., 1., 1., ..., 1., 1., 1.]],\n",
       "\n",
       "        [[1., 1., 1., ..., 1., 1., 1.],\n",
       "         [1., 1., 1., ..., 1., 1., 1.],\n",
       "         [1., 1., 1., ..., 1., 1., 1.],\n",
       "         ...,\n",
       "         [1., 1., 1., ..., 1., 1., 1.],\n",
       "         [1., 1., 1., ..., 1., 1., 1.],\n",
       "         [1., 1., 1., ..., 1., 1., 1.]]],\n",
       "\n",
       "\n",
       "       [[[1., 1., 1., ..., 1., 1., 1.],\n",
       "         [1., 1., 1., ..., 1., 1., 1.],\n",
       "         [1., 1., 1., ..., 1., 1., 1.],\n",
       "         ...,\n",
       "         [1., 1., 1., ..., 1., 1., 1.],\n",
       "         [1., 1., 1., ..., 1., 1., 1.],\n",
       "         [1., 1., 1., ..., 1., 1., 1.]],\n",
       "\n",
       "        [[1., 1., 1., ..., 1., 1., 1.],\n",
       "         [1., 1., 1., ..., 1., 1., 1.],\n",
       "         [1., 1., 1., ..., 1., 1., 1.],\n",
       "         ...,\n",
       "         [1., 1., 1., ..., 1., 1., 1.],\n",
       "         [1., 1., 1., ..., 1., 1., 1.],\n",
       "         [1., 1., 1., ..., 1., 1., 1.]],\n",
       "\n",
       "        [[1., 1., 1., ..., 1., 1., 1.],\n",
       "         [1., 1., 1., ..., 1., 1., 1.],\n",
       "         [1., 1., 1., ..., 1., 1., 1.],\n",
       "         ...,\n",
       "         [1., 1., 1., ..., 1., 1., 1.],\n",
       "         [1., 1., 1., ..., 1., 1., 1.],\n",
       "         [1., 1., 1., ..., 1., 1., 1.]],\n",
       "\n",
       "        [[1., 1., 1., ..., 1., 1., 1.],\n",
       "         [1., 1., 1., ..., 1., 1., 1.],\n",
       "         [1., 1., 1., ..., 1., 1., 1.],\n",
       "         ...,\n",
       "         [1., 1., 1., ..., 1., 1., 1.],\n",
       "         [1., 1., 1., ..., 1., 1., 1.],\n",
       "         [1., 1., 1., ..., 1., 1., 1.]]],\n",
       "\n",
       "\n",
       "       [[[1., 1., 1., ..., 1., 1., 1.],\n",
       "         [1., 1., 1., ..., 1., 1., 1.],\n",
       "         [1., 1., 1., ..., 1., 1., 1.],\n",
       "         ...,\n",
       "         [1., 1., 1., ..., 1., 1., 1.],\n",
       "         [1., 1., 1., ..., 1., 1., 1.],\n",
       "         [1., 1., 1., ..., 1., 1., 1.]],\n",
       "\n",
       "        [[1., 1., 1., ..., 1., 1., 1.],\n",
       "         [1., 1., 1., ..., 1., 1., 1.],\n",
       "         [1., 1., 1., ..., 1., 1., 1.],\n",
       "         ...,\n",
       "         [1., 1., 1., ..., 1., 1., 1.],\n",
       "         [1., 1., 1., ..., 1., 1., 1.],\n",
       "         [1., 1., 1., ..., 1., 1., 1.]],\n",
       "\n",
       "        [[1., 1., 1., ..., 1., 1., 1.],\n",
       "         [1., 1., 1., ..., 1., 1., 1.],\n",
       "         [1., 1., 1., ..., 1., 1., 1.],\n",
       "         ...,\n",
       "         [1., 1., 1., ..., 1., 1., 1.],\n",
       "         [1., 1., 1., ..., 1., 1., 1.],\n",
       "         [1., 1., 1., ..., 1., 1., 1.]],\n",
       "\n",
       "        [[1., 1., 1., ..., 1., 1., 1.],\n",
       "         [1., 1., 1., ..., 1., 1., 1.],\n",
       "         [1., 1., 1., ..., 1., 1., 1.],\n",
       "         ...,\n",
       "         [1., 1., 1., ..., 1., 1., 1.],\n",
       "         [1., 1., 1., ..., 1., 1., 1.],\n",
       "         [1., 1., 1., ..., 1., 1., 1.]]]], dtype=float32)>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.ones((32, 4, 128, 128))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbc2ca83",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
