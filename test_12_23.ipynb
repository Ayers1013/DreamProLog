{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5ee588dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-12-30 22:48:49.289621: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running the DreamProlog algorithm.\n",
      "There was a problem with the provided arguments. The program will run in the default setting:\n",
      "--configs prolog --logdir logdir\n",
      "Namespace(act='elu', action_gnn_hidden_act=64, action_gnn_hidden_val=200, action_gnn_layers=6, action_gnn_next_shape=(32, 64, 32), action_gnn_start_shape=(4, 1, 4), action_repeat=1, actor_disc=5, actor_dist='normal', actor_entropy='1e-4', actor_grad_clip=100, actor_init_std=1.0, actor_layers=4, actor_lr=0.001, actor_min_std=0.1, actor_outscale=0.0, actor_state_entropy=0.0, actor_temp=0.1, atari_grayscale=False, behavior_stop_grad=True, clip_rewards='identity', collect_dyn_sample=True, dataset_size=100000, debug=False, disag_layers=1, disag_log=True, disag_models=3, disag_offset=0, disag_target='embed', disag_units=200, discount=0.95, discount_lambda=0.8, discount_layers=2, discount_scale=1.0, dyn_cell='gru', dyn_deter=512, dyn_discrete=32, dyn_hidden=512, dyn_input_layers=5, dyn_mean_act='none', dyn_min_std=0.1, dyn_output_layers=5, dyn_shared=False, dyn_std_act='sigmoid2', dyn_stoch=192, envs=1, eval_every=500, eval_noise=0.0, eval_state_mean=False, evaldir=None, expl_amount=0.0, expl_behavior='greedy', expl_extr_scale=0.0, expl_gifs=False, expl_intr_scale=1.0, expl_until=10000000.0, free_heads=('image', 'reward', 'discount'), future_entropy=False, gnn_hidden_act=128, gnn_hidden_val=384, gnn_layers=14, gnn_next_shape=(32, 64, 32), gnn_start_shape=(4, 1, 4), gpu_growth=True, grad_clip=200, grad_heads=('image', 'reward', 'discount', 'action_mask'), imag_gradient='reinforce', imag_gradient_mix='0.1', imag_horizon=3, imag_sample=True, kl_balance='0.8', kl_free='0.5', kl_scale='1.0', log_every=10, model_lr=0.0009, offline_evaldir='', offline_traindir='', opt='adam', opt_eps=0.0008, oversample_ends=False, precision=32, pred_discount=True, prefill=40000, pretrain=5, reset_every=0, reward_layers=2, reward_scale=1.0, seed=0, share_gnn=True, slow_actor_target=False, slow_target_fraction=1, slow_target_update=100, slow_value_target=False, steps=1000000, task='prolog_void', time_limit=1000, train_every=25, train_steps=10, traindir=None, units=192, value_decay=0.0, value_grad_clip=100, value_head='normal', value_layers=3, value_lr=0.001, weight_decay=0.0)\n",
      "Logdir logdir\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "usage: ipykernel_launcher.py [-h] --configs CONFIGS [CONFIGS ...] --logdir\n",
      "                             LOGDIR\n",
      "ipykernel_launcher.py: error: the following arguments are required: --configs, --logdir\n",
      "2021-12-30 22:48:50.743013: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set\n",
      "2021-12-30 22:48:50.743667: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcuda.so.1\n",
      "2021-12-30 22:48:50.779060: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: \n",
      "pciBusID: 0000:05:00.0 name: TITAN V computeCapability: 7.0\n",
      "coreClock: 1.455GHz coreCount: 80 deviceMemorySize: 11.78GiB deviceMemoryBandwidth: 607.97GiB/s\n",
      "2021-12-30 22:48:50.779718: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 1 with properties: \n",
      "pciBusID: 0000:09:00.0 name: TITAN V computeCapability: 7.0\n",
      "coreClock: 1.455GHz coreCount: 80 deviceMemorySize: 11.78GiB deviceMemoryBandwidth: 607.97GiB/s\n",
      "2021-12-30 22:48:50.779737: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1\n",
      "2021-12-30 22:48:50.781075: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10\n",
      "2021-12-30 22:48:50.781103: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.10\n",
      "2021-12-30 22:48:50.782348: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10\n",
      "2021-12-30 22:48:50.782555: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10\n",
      "2021-12-30 22:48:50.783935: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10\n",
      "2021-12-30 22:48:50.784696: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.10\n",
      "2021-12-30 22:48:50.787678: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7\n",
      "2021-12-30 22:48:50.790273: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0, 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Suite: prolog\n",
      "Found 131 problem files.\n",
      "Query:\n",
      "    init_python(\"leancop/theorems/m2n140/t6_orders_2.p\",[conj, nodef, eager_reduction(1)],GnnInput, SimpleFeatures, TextFeatures, TextActions, ActionsMask, Result) \n",
      "\n",
      "Suite: prolog\n",
      "Found 131 problem files.\n",
      "Query:\n",
      "    init_python(\"leancop/theorems/m2n140/t41_zfmisc_1.p\",[conj, nodef, eager_reduction(1)],GnnInput, SimpleFeatures, TextFeatures, TextActions, ActionsMask, Result) \n",
      "\n",
      "Prefill dataset (0 steps).\n",
      "Loaded problem: m2n140__t16_tops_1\n",
      "Eval episode has 11 steps and return -0.200.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kristsz/DreamProLog/envs/wrappers.py:57: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  value = np.array(value)\n"
     ]
    }
   ],
   "source": [
    "from main import init_config\n",
    "from controller import Controller\n",
    "from dataset.process import TokenParser\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "ctrl = Controller(*init_config())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0eab208f",
   "metadata": {},
   "outputs": [],
   "source": [
    "meta = ctrl.datasetManager._train_eps._meta\n",
    "ds = []\n",
    "for v in meta.values():\n",
    "    ds.extend([str(s)[1:] for s in v['action_space_text']])\n",
    "    \n",
    "parser = TokenParser()\n",
    "\n",
    "def pad(narr):\n",
    "    size = narr.size\n",
    "    return np.pad(narr, [0, 128-size])\n",
    "\n",
    "parsed_ds = []\n",
    "for dp in ds:\n",
    "    parsed_ds.append(pad(np.array(parser.parse(dp), dtype = np.int32)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "30896e5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-12-30 22:49:01.384666: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2021-12-30 22:49:01.599230: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: \n",
      "pciBusID: 0000:05:00.0 name: TITAN V computeCapability: 7.0\n",
      "coreClock: 1.455GHz coreCount: 80 deviceMemorySize: 11.78GiB deviceMemoryBandwidth: 607.97GiB/s\n",
      "2021-12-30 22:49:01.599829: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 1 with properties: \n",
      "pciBusID: 0000:09:00.0 name: TITAN V computeCapability: 7.0\n",
      "coreClock: 1.455GHz coreCount: 80 deviceMemorySize: 11.78GiB deviceMemoryBandwidth: 607.97GiB/s\n",
      "2021-12-30 22:49:01.599851: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1\n",
      "2021-12-30 22:49:01.599873: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10\n",
      "2021-12-30 22:49:01.599884: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.10\n",
      "2021-12-30 22:49:01.599894: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10\n",
      "2021-12-30 22:49:01.599905: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10\n",
      "2021-12-30 22:49:01.599915: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10\n",
      "2021-12-30 22:49:01.599925: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.10\n",
      "2021-12-30 22:49:01.599936: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7\n",
      "2021-12-30 22:49:01.602221: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0, 1\n",
      "2021-12-30 22:49:01.602249: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1\n",
      "2021-12-30 22:49:02.283984: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1261] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
      "2021-12-30 22:49:02.284014: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1267]      0 1 \n",
      "2021-12-30 22:49:02.284019: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1280] 0:   N Y \n",
      "2021-12-30 22:49:02.284023: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1280] 1:   Y N \n",
      "2021-12-30 22:49:02.286459: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1406] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10019 MB memory) -> physical GPU (device: 0, name: TITAN V, pci bus id: 0000:05:00.0, compute capability: 7.0)\n",
      "2021-12-30 22:49:02.287882: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1406] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:1 with 10487 MB memory) -> physical GPU (device: 1, name: TITAN V, pci bus id: 0000:09:00.0, compute capability: 7.0)\n",
      "2021-12-30 22:49:02.288124: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "BATCH_SIZE = 32\n",
    "def generator():\n",
    "    for i in range(1000):\n",
    "        x = tf.constant([parsed_ds[np.random.randint(len(parsed_ds))] for i in range(BATCH_SIZE)])\n",
    "        yield x, x\n",
    "sgn = tf.TensorSpec((BATCH_SIZE, 128), dtype=tf.int32)\n",
    "tf_ds = tf.data.Dataset.from_generator(generator, output_signature = (sgn, sgn))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fd23e2fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU available:  [PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU'), PhysicalDevice(name='/physical_device:GPU:1', device_type='GPU')]\n"
     ]
    }
   ],
   "source": [
    "from unorganized.parts2 import Net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "646ac130",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Loss(tf.keras.losses.Loss):\n",
    "    def __init__(self, omega=0.0):\n",
    "        super().__init__()\n",
    "        self.omega = omega\n",
    "        \n",
    "    def call(self, y_true, y_pred):\n",
    "        y = tf.nn.softmax(y_pred, axis=-1)\n",
    "        y_probs = tf.gather(y, y_true, axis=-1, batch_dims=2)\n",
    "        y_log_probs = tf.math.log(y_probs+0.001)\n",
    "        #loss = self.omega*y_log_probs + (1-self.omega)*tf.math.cumsum(y_log_probs, axis=-1)\n",
    "        #loss = y_log_probs*tf.math.cumprod(0.97*tf.ones((32,128)), axis=-1)\n",
    "        mask = 1-tf.cast(tf.math.equal(y_true, 0), tf.float32)\n",
    "        #mask = tf.math.cumprod(mask, axis=-1)\n",
    "        loss = (mask+self.omega)*y_log_probs\n",
    "        loss = -tf.math.reduce_sum(loss)/(128*32)\n",
    "        return loss\n",
    "    \n",
    "class Loss(tf.keras.losses.Loss):\n",
    "    def __init__(self, omega=0.0):\n",
    "        super().__init__()\n",
    "        self.omega = omega\n",
    "        self.loss_objective = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True, reduction='none')\n",
    "        \n",
    "    def call(self, y_true, y_pred):\n",
    "        loss = self.loss_objective(y_true, y_pred)\n",
    "        mask = 1-tf.cast(tf.math.equal(y_true, 0), tf.float32)\n",
    "        \n",
    "        loss *= mask\n",
    "        return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6f9556c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Net(1)#Net(1, 8, 128, 64, 4, 128)#Net(128, 4, 256)\n",
    "#d_model = 256\n",
    "#enc_embed = tf.keras.layers.Embedding(300, d_model)\n",
    "#encoder = Encoder(4, d_model, 4, 512, 0.04)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b6cda476",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-12-30 22:49:02.391966: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:116] None of the MLIR optimization passes are enabled (registered 2)\n",
      "2021-12-30 22:49:02.409409: I tensorflow/core/platform/profile_utils/cpu_utils.cc:112] CPU Frequency: 3598190000 Hz\n",
      "2021-12-30 22:49:02.433723: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10\n",
      "2021-12-30 22:49:02.607983: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7\n"
     ]
    }
   ],
   "source": [
    "x, x = next(iter(tf_ds))\n",
    "model(x, False)\n",
    "y_true = x\n",
    "mask = 1-tf.cast(tf.math.equal(y_true, 0), tf.float32)\n",
    "mask = tf.math.cumprod(mask, axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "af8f2751",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=tf.keras.optimizers.Adam(), loss=Loss(), metrics=[])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2ea1cba5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "1000/1000 [==============================] - 11s 9ms/step - loss: 0.7101\n",
      "Epoch 2/50\n",
      "1000/1000 [==============================] - 9s 9ms/step - loss: 0.5241\n",
      "Epoch 3/50\n",
      "1000/1000 [==============================] - 9s 9ms/step - loss: 0.4740\n",
      "Epoch 4/50\n",
      "1000/1000 [==============================] - 9s 9ms/step - loss: 0.4376\n",
      "Epoch 5/50\n",
      "1000/1000 [==============================] - 9s 9ms/step - loss: 0.4214\n",
      "Epoch 6/50\n",
      "1000/1000 [==============================] - 9s 9ms/step - loss: 0.4070\n",
      "Epoch 7/50\n",
      "1000/1000 [==============================] - 9s 9ms/step - loss: 0.4019\n",
      "Epoch 8/50\n",
      "1000/1000 [==============================] - 9s 9ms/step - loss: 0.3982\n",
      "Epoch 9/50\n",
      "1000/1000 [==============================] - 9s 9ms/step - loss: 0.3871\n",
      "Epoch 10/50\n",
      "1000/1000 [==============================] - 9s 9ms/step - loss: 0.3815\n",
      "Epoch 11/50\n",
      "1000/1000 [==============================] - 9s 9ms/step - loss: 0.3767\n",
      "Epoch 12/50\n",
      "1000/1000 [==============================] - 9s 9ms/step - loss: 0.3750\n",
      "Epoch 13/50\n",
      "1000/1000 [==============================] - 9s 9ms/step - loss: 0.3714\n",
      "Epoch 14/50\n",
      "1000/1000 [==============================] - 9s 9ms/step - loss: 0.3682\n",
      "Epoch 15/50\n",
      "1000/1000 [==============================] - 9s 9ms/step - loss: 0.3595\n",
      "Epoch 16/50\n",
      "1000/1000 [==============================] - 9s 9ms/step - loss: 0.3642\n",
      "Epoch 17/50\n",
      "1000/1000 [==============================] - 9s 9ms/step - loss: 0.3638\n",
      "Epoch 18/50\n",
      "1000/1000 [==============================] - 9s 9ms/step - loss: 0.3591\n",
      "Epoch 19/50\n",
      "1000/1000 [==============================] - 9s 9ms/step - loss: 0.3608\n",
      "Epoch 20/50\n",
      "1000/1000 [==============================] - 9s 9ms/step - loss: 0.3549\n",
      "Epoch 21/50\n",
      "1000/1000 [==============================] - 9s 9ms/step - loss: 0.3556\n",
      "Epoch 22/50\n",
      "1000/1000 [==============================] - 9s 9ms/step - loss: 0.3525\n",
      "Epoch 23/50\n",
      "1000/1000 [==============================] - 9s 9ms/step - loss: 0.3464\n",
      "Epoch 24/50\n",
      "1000/1000 [==============================] - 9s 9ms/step - loss: 0.3443\n",
      "Epoch 25/50\n",
      "1000/1000 [==============================] - 9s 9ms/step - loss: 0.3437\n",
      "Epoch 26/50\n",
      "1000/1000 [==============================] - 9s 9ms/step - loss: 0.3474\n",
      "Epoch 27/50\n",
      "1000/1000 [==============================] - 9s 9ms/step - loss: 0.3396\n",
      "Epoch 28/50\n",
      "1000/1000 [==============================] - 9s 9ms/step - loss: 0.3491\n",
      "Epoch 29/50\n",
      "1000/1000 [==============================] - 9s 9ms/step - loss: 0.3385\n",
      "Epoch 30/50\n",
      "1000/1000 [==============================] - 9s 9ms/step - loss: 0.3424\n",
      "Epoch 31/50\n",
      "1000/1000 [==============================] - 9s 9ms/step - loss: 0.3371\n",
      "Epoch 32/50\n",
      "1000/1000 [==============================] - 9s 9ms/step - loss: 0.3412\n",
      "Epoch 33/50\n",
      "1000/1000 [==============================] - 9s 9ms/step - loss: 0.3405\n",
      "Epoch 34/50\n",
      "1000/1000 [==============================] - 9s 9ms/step - loss: 0.3364\n",
      "Epoch 35/50\n",
      "1000/1000 [==============================] - 9s 9ms/step - loss: 0.3365\n",
      "Epoch 36/50\n",
      "1000/1000 [==============================] - 9s 9ms/step - loss: 0.3349\n",
      "Epoch 37/50\n",
      "1000/1000 [==============================] - 9s 9ms/step - loss: 0.3368\n",
      "Epoch 38/50\n",
      "1000/1000 [==============================] - 9s 9ms/step - loss: 0.3293\n",
      "Epoch 39/50\n",
      "1000/1000 [==============================] - 9s 9ms/step - loss: 0.3332\n",
      "Epoch 40/50\n",
      "1000/1000 [==============================] - 9s 9ms/step - loss: 0.3294\n",
      "Epoch 41/50\n",
      "1000/1000 [==============================] - 9s 9ms/step - loss: 0.3343\n",
      "Epoch 42/50\n",
      "1000/1000 [==============================] - 9s 9ms/step - loss: 0.3267\n",
      "Epoch 43/50\n",
      "1000/1000 [==============================] - 9s 9ms/step - loss: 0.3290\n",
      "Epoch 44/50\n",
      "1000/1000 [==============================] - 9s 9ms/step - loss: 0.3314\n",
      "Epoch 45/50\n",
      "1000/1000 [==============================] - 9s 9ms/step - loss: 0.3275\n",
      "Epoch 46/50\n",
      "1000/1000 [==============================] - 9s 9ms/step - loss: 0.3292\n",
      "Epoch 47/50\n",
      "1000/1000 [==============================] - 9s 9ms/step - loss: 0.3234\n",
      "Epoch 48/50\n",
      "1000/1000 [==============================] - 9s 9ms/step - loss: 0.3302\n",
      "Epoch 49/50\n",
      "1000/1000 [==============================] - 9s 9ms/step - loss: 0.3256\n",
      "Epoch 50/50\n",
      "1000/1000 [==============================] - 9s 9ms/step - loss: 0.3269\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f1226fe3e50>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(tf_ds, epochs = 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ed7a942c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[ 21   5  12  22  23  24   5  13  16   2   9   5  16  40   2 109  20  12\n",
      "   13  16   2   3   9   5  12  40   2   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0]\n",
      " [ 21   5  12  22  23  24   5  13  16   2   3  27  23 125  20  13  16  12\n",
      "    2  27  23  12   2 109  20  12  13  16   2   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0]\n",
      " [  9   5  12  13   2   3   9   5  22  23  12  22  23  13   2   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0]\n",
      " [ 87   5  12  13   2  28  23  12   2   3  89   5  12  13   2   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0]], shape=(4, 128), dtype=int32)\n",
      "\n",
      "tf.Tensor(\n",
      "[[  3   5  12  13  40   2  21   5  16   2   3  24   5  16  16   2  16   5\n",
      "   16  16   2   2   2   5  12  40   2   5  12  16   2  40  40   2   2   2\n",
      "    9  40  40   2  12  24  40  40  40   9  40  16   5  40  40   3   2  40\n",
      "   12  40   2   9   2   2  16  20   5  74   2  16  20  16  16  13  16   2\n",
      "    2  12  16  16  16  40   5  12   2  13  23   2   5  23  16  12  16  13\n",
      "   16  16   2  16  20  13  40 108  23  16   2  20   5   5  13  40   2  20\n",
      "   20  13  16   2   2   3  23  20  16  16  16  13   2   2   5   5  40  40\n",
      "    5  40]\n",
      " [ 21 109  12 125   3  24   5 125  16   2   3  12  16 125  20  27  16  12\n",
      "    2  27   2   5  12  12   2  21  16  12   2  23  24   5  27  13   2   2\n",
      "   27  13  12   2 109  12  24   2  27  27  20  27  23  13  27  24   2  12\n",
      "   12  13   2   2   2   2   2  20   2  12  16  16  20  12  16  13   2   2\n",
      "   20  12   2  16   2   2  20 125   2  13   2   2  12  23  16  12   2  13\n",
      "    2  16   2  16  20  13   2  13  12  13   2   2   2  13  13   2   2  21\n",
      "   13  13  16  20   2  27  16  20  13  16   2  13  12   2  27  27   2  12\n",
      "   12   2]\n",
      " [  3   5   5  13   2   3   9  23  13   2   9  22  12  13   2  22  22  13\n",
      "    2   2  22   5   2  13  12  22   5   5   5  12  12  22  12   2   9  22\n",
      "   22  12   2  22  12   5   9   5  13  12   2   2  23  13  22   5  22   2\n",
      "   12  13   2   2   2   2  12  21   5  13  13   2  23  12  23  13  12  22\n",
      "    2  23  12  12  13   2  23  12   2  38  23   2  13  74  23  12  12  13\n",
      "    2  12  13  12  23  13   2   2  23  12  22  13   2  23  23  22  23  23\n",
      "   13  23  23   2   2   3  23  23  13  23   2   2   5   2   2   2   2   2\n",
      "    5  13]\n",
      " [ 89  89  12  13   2  28  23  13   2   2  89   5  12  13   2  89   5  12\n",
      "   12   2   2  13   5   5  12   2  28   5   2  12  12   2   3   2   5  12\n",
      "    5   5  12   2   2   5   5  12  12  12   2   5   5  12   3  12  12  12\n",
      "   12  13   2   2   5  12  12   2   5  12  13   2   2   2  13  13   2  12\n",
      "    5   2  12  12  13   2   5  12   2   2   2   2   2   5   5   2   2   2\n",
      "    2   5  13  12  13  13  12  13  13  12  13   2   5  12  13   2   2  12\n",
      "   13  12  23  12   2  12   3  89   2  13   2   2   5   2   2   5   2  13\n",
      "   12  12]], shape=(4, 128), dtype=int64)\n",
      "\n",
      "tf.Tensor(\n",
      "[[17 31 58 11 13  7 15 13 36 24  3  8 21  5  7 18  2 11  8 25 26  2  6 41\n",
      "  36 34 48  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "   0  0  0  0  0  0  0  0]\n",
      " [41 15 73 16  8 17 41 15 39 18 16 14  4 35 36 10 33 50 55 21 10 18  7  7\n",
      "   6  4 10  7 31  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "   0  0  0  0  0  0  0  0]\n",
      " [47 76 48 70 78 78 51 24 12 10 23 47 19 93 97  0  0  0  0  0  0  0  0  0\n",
      "   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "   0  0  0  0  0  0  0  0]\n",
      " [16 20 90 42 43 53 35 35 49 38 77 59 78 48 87  0  0  0  0  0  0  0  0  0\n",
      "   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "   0  0  0  0  0  0  0  0]], shape=(4, 128), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "x, y_true = next(iter(tf_ds))\n",
    "y_pred = model(x, False)\n",
    "y_pred = tf.nn.softmax(y_pred, axis=-1)\n",
    "y_probs = tf.gather(y_pred, y_true, axis=-1, batch_dims=2)\n",
    "y_pred = tf.math.argmax(y_pred, axis=-1)\n",
    "print(x[:4], y_pred[:4], tf.cast(100*y_probs[:4], dtype=tf.int32), sep='\\n\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "da59122a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Variable 'Variable:0' shape=(1, 8, 128) dtype=float32, numpy=\n",
       "array([[[ 0.70087147,  0.1958967 , -0.35145903, ...,  0.48064098,\n",
       "          0.4918324 ,  0.03355688],\n",
       "        [ 0.20909105,  0.69546527, -0.23883833, ...,  0.5814026 ,\n",
       "          0.25828016,  0.5053409 ],\n",
       "        [-0.21123317,  0.7534062 ,  0.7333148 , ..., -0.10376038,\n",
       "          0.6470314 , -0.12154149],\n",
       "        ...,\n",
       "        [ 0.46920526, -0.04690957,  0.6305629 , ...,  0.34775922,\n",
       "          0.04588863, -0.03653677],\n",
       "        [ 0.03515827, -0.09518815,  0.4213055 , ...,  0.26995596,\n",
       "          0.2315686 , -0.09755877],\n",
       "        [ 0.15336037,  0.21321705,  0.70800805, ...,  0.54270494,\n",
       "         -0.08866469,  0.643626  ]]], dtype=float32)>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.encoder.variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4d28b215",
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = tf.cast(tf.math.equal(x[:1], 0), tf.float32)[:, tf.newaxis, :, tf.newaxis]\n",
    "        \n",
    "v, q = model.enc_embed(x)[:1], model.encoder.variable#tf.tile(model.encoder.variable, (32, 1, 1))\n",
    "v = [v]\n",
    "q = [q]\n",
    "attention = []\n",
    "for l in model.encoder.layers:\n",
    "    _v, _q, _att = l(v[-1], q[-1], mask, False)\n",
    "    v.append(_v)\n",
    "    q.append(_q)\n",
    "    attention.append(_att)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b633f062",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Tensor: shape=(1, 128, 128), dtype=float32, numpy=\n",
       " array([[[ 0.04792119,  0.04437996, -0.00787528, ..., -0.07554483,\n",
       "           0.31612352, -0.24282289],\n",
       "         [-0.23656398,  0.00266965, -0.15428829, ..., -0.26722905,\n",
       "           0.05645089,  0.11960076],\n",
       "         [ 0.19339246, -0.05289397,  0.11940589, ...,  0.32167187,\n",
       "          -0.48939654,  0.04903906],\n",
       "         ...,\n",
       "         [-0.49084064,  0.65793324, -0.6095724 , ..., -0.9494842 ,\n",
       "           0.08307586,  0.10185409],\n",
       "         [-0.49084064,  0.65793324, -0.6095724 , ..., -0.9494842 ,\n",
       "           0.08307586,  0.10185409],\n",
       "         [-0.49084064,  0.65793324, -0.6095724 , ..., -0.9494842 ,\n",
       "           0.08307586,  0.10185409]]], dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 128, 128), dtype=float32, numpy=\n",
       " array([[[ 0.11194344, -0.0637473 , -0.8052465 , ..., -0.12497996,\n",
       "           0.51567215,  0.29573622],\n",
       "         [ 0.3811726 , -0.05803382,  0.00395416, ...,  0.14346313,\n",
       "          -0.2781397 ,  0.24369061],\n",
       "         [ 0.4371124 , -0.23597085,  0.06091493, ..., -0.7970505 ,\n",
       "           0.12803395,  0.22459096],\n",
       "         ...,\n",
       "         [ 0.21625543, -0.04932679, -0.01801831, ..., -0.16413158,\n",
       "          -0.17873853, -0.05707125],\n",
       "         [ 0.21625543, -0.04932679, -0.01801831, ..., -0.16413158,\n",
       "          -0.17873853, -0.05707125],\n",
       "         [ 0.21625543, -0.04932679, -0.01801831, ..., -0.16413158,\n",
       "          -0.17873853, -0.05707125]]], dtype=float32)>]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fc0e4c48",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor: shape=(1, 4, 128, 8), dtype=float32, numpy=\n",
       " array([[[[2.51413316e-01, 1.04385642e-02, 7.05200341e-03, ...,\n",
       "           1.28090337e-01, 5.06249487e-01, 8.14314261e-02],\n",
       "          [6.94326081e-06, 2.74363818e-04, 1.09457616e-02, ...,\n",
       "           3.74753581e-05, 4.39365249e-05, 1.62385895e-05],\n",
       "          [5.51492907e-03, 1.52532076e-02, 9.39111948e-01, ...,\n",
       "           3.09610344e-03, 2.06962833e-03, 7.02536013e-03],\n",
       "          ...,\n",
       "          [1.60381082e-28, 1.60381082e-28, 1.60381082e-28, ...,\n",
       "           1.60381082e-28, 1.60381082e-28, 1.60381082e-28],\n",
       "          [1.60381082e-28, 1.60381082e-28, 1.60381082e-28, ...,\n",
       "           1.60381082e-28, 1.60381082e-28, 1.60381082e-28],\n",
       "          [1.60381082e-28, 1.60381082e-28, 1.60381082e-28, ...,\n",
       "           1.60381082e-28, 1.60381082e-28, 1.60381082e-28]],\n",
       " \n",
       "         [[9.34151001e-03, 1.08260974e-01, 1.45780921e-01, ...,\n",
       "           7.30265602e-02, 3.63879353e-02, 1.66411586e-02],\n",
       "          [1.56238035e-04, 1.19090881e-02, 8.00474510e-02, ...,\n",
       "           9.05647129e-02, 2.25540902e-02, 6.57404133e-04],\n",
       "          [2.90228762e-02, 1.80134103e-01, 5.03862202e-02, ...,\n",
       "           5.07431962e-02, 4.56772774e-01, 7.25646242e-02],\n",
       "          ...,\n",
       "          [1.25000000e-01, 1.25000000e-01, 1.25000000e-01, ...,\n",
       "           1.25000000e-01, 1.25000000e-01, 1.25000000e-01],\n",
       "          [1.25000000e-01, 1.25000000e-01, 1.25000000e-01, ...,\n",
       "           1.25000000e-01, 1.25000000e-01, 1.25000000e-01],\n",
       "          [1.25000000e-01, 1.25000000e-01, 1.25000000e-01, ...,\n",
       "           1.25000000e-01, 1.25000000e-01, 1.25000000e-01]],\n",
       " \n",
       "         [[4.59518604e-04, 9.55441594e-01, 3.77695449e-03, ...,\n",
       "           1.80219344e-04, 1.66448916e-03, 1.06974680e-04],\n",
       "          [6.62170234e-04, 3.35548634e-06, 9.98352408e-01, ...,\n",
       "           4.99022121e-07, 1.63330029e-07, 9.75698465e-04],\n",
       "          [4.64712532e-04, 9.66393948e-01, 2.21128762e-03, ...,\n",
       "           1.05677544e-04, 1.30534789e-03, 6.16901525e-05],\n",
       "          ...,\n",
       "          [1.60381082e-28, 1.60381082e-28, 1.00000000e+00, ...,\n",
       "           1.60381082e-28, 1.60381082e-28, 1.60381082e-28],\n",
       "          [1.60381082e-28, 1.60381082e-28, 1.00000000e+00, ...,\n",
       "           1.60381082e-28, 1.60381082e-28, 1.60381082e-28],\n",
       "          [1.60381082e-28, 1.60381082e-28, 1.00000000e+00, ...,\n",
       "           1.60381082e-28, 1.60381082e-28, 1.60381082e-28]],\n",
       " \n",
       "         [[1.27101317e-04, 4.92751738e-03, 1.20027187e-04, ...,\n",
       "           1.03126392e-02, 8.93229677e-04, 1.70900807e-04],\n",
       "          [4.73443613e-08, 9.67098731e-06, 2.01020484e-07, ...,\n",
       "           6.84920466e-04, 1.99701003e-06, 1.19516216e-07],\n",
       "          [5.14976382e-02, 4.36848328e-02, 1.03235774e-01, ...,\n",
       "           4.81114864e-01, 1.68264955e-01, 4.84004579e-02],\n",
       "          ...,\n",
       "          [1.60381082e-28, 1.60381082e-28, 1.60381082e-28, ...,\n",
       "           1.60381082e-28, 1.60381082e-28, 1.60381082e-28],\n",
       "          [1.60381082e-28, 1.60381082e-28, 1.60381082e-28, ...,\n",
       "           1.60381082e-28, 1.60381082e-28, 1.60381082e-28],\n",
       "          [1.60381082e-28, 1.60381082e-28, 1.60381082e-28, ...,\n",
       "           1.60381082e-28, 1.60381082e-28, 1.60381082e-28]]]],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 4, 8, 128), dtype=float32, numpy=\n",
       " array([[[[2.2383923e-04, 6.9403788e-04, 2.5519729e-02, ...,\n",
       "           1.8443252e-04, 1.8443252e-04, 1.8443252e-04],\n",
       "          [4.3763305e-04, 3.7234446e-03, 1.1760461e-02, ...,\n",
       "           5.1419582e-04, 5.1419582e-04, 5.1419582e-04],\n",
       "          [1.0111360e-03, 1.1985233e-04, 5.3179887e-04, ...,\n",
       "           1.1597580e-03, 1.1597580e-03, 1.1597580e-03],\n",
       "          ...,\n",
       "          [2.6289728e-03, 1.0480352e-05, 5.3208903e-04, ...,\n",
       "           2.8438468e-05, 2.8438468e-05, 2.8438468e-05],\n",
       "          [5.9302740e-02, 8.6532079e-04, 5.6858668e-03, ...,\n",
       "           1.4298976e-03, 1.4298976e-03, 1.4298976e-03],\n",
       "          [2.4694635e-04, 2.8390543e-06, 1.3620518e-03, ...,\n",
       "           8.2979692e-05, 8.2979692e-05, 8.2979692e-05]],\n",
       " \n",
       "         [[1.3951339e-01, 9.9252993e-03, 6.2586652e-04, ...,\n",
       "           2.7198703e-03, 2.7198703e-03, 2.7198703e-03],\n",
       "          [2.4948588e-02, 3.4126027e-03, 8.3463098e-04, ...,\n",
       "           5.0232192e-03, 5.0232192e-03, 5.0232192e-03],\n",
       "          [1.9026758e-01, 2.5987374e-06, 1.0623556e-06, ...,\n",
       "           3.1986528e-07, 3.1986528e-07, 3.1986528e-07],\n",
       "          ...,\n",
       "          [9.5593100e-03, 1.5269694e-07, 1.3858054e-06, ...,\n",
       "           8.9203681e-08, 8.9203681e-08, 8.9203681e-08],\n",
       "          [6.6427290e-02, 1.6699877e-04, 3.9626706e-05, ...,\n",
       "           4.6815483e-05, 4.6815483e-05, 4.6815483e-05],\n",
       "          [9.5606573e-02, 2.4901499e-04, 3.2294509e-05, ...,\n",
       "           3.0803967e-05, 3.0803967e-05, 3.0803967e-05]],\n",
       " \n",
       "         [[2.4699614e-11, 7.5840820e-11, 1.3594434e-04, ...,\n",
       "           4.5747253e-08, 4.5747253e-08, 4.5747253e-08],\n",
       "          [5.5229457e-09, 1.3277737e-06, 6.2653947e-07, ...,\n",
       "           5.1343515e-05, 5.1343515e-05, 5.1343515e-05],\n",
       "          [2.2918700e-16, 8.9045092e-15, 5.4490819e-13, ...,\n",
       "           7.2329356e-12, 7.2329356e-12, 7.2329356e-12],\n",
       "          ...,\n",
       "          [6.8472539e-10, 9.0569877e-08, 7.0004075e-06, ...,\n",
       "           9.1225365e-07, 9.1225365e-07, 9.1225365e-07],\n",
       "          [7.6530937e-10, 1.6166201e-08, 1.4328788e-06, ...,\n",
       "           3.8999099e-07, 3.8999099e-07, 3.8999099e-07],\n",
       "          [6.6277655e-17, 3.5827413e-18, 1.3170353e-13, ...,\n",
       "           3.6148246e-14, 3.6148246e-14, 3.6148246e-14]],\n",
       " \n",
       "         [[4.6754838e-03, 1.4505278e-04, 7.9352424e-02, ...,\n",
       "           4.5436977e-05, 4.5436977e-05, 4.5436977e-05],\n",
       "          [8.8731162e-03, 3.0874656e-04, 1.1130693e-01, ...,\n",
       "           8.0442900e-05, 8.0442900e-05, 8.0442900e-05],\n",
       "          [5.6237630e-03, 7.5148753e-05, 1.0341695e-03, ...,\n",
       "           3.8706939e-06, 3.8706939e-06, 3.8706939e-06],\n",
       "          ...,\n",
       "          [5.8936463e-03, 6.5490917e-06, 2.9169419e-03, ...,\n",
       "           5.5380116e-07, 5.5380116e-07, 5.5380116e-07],\n",
       "          [7.0797736e-03, 4.2292723e-03, 3.2591596e-03, ...,\n",
       "           1.2627977e-03, 1.2627977e-03, 1.2627977e-03],\n",
       "          [2.3749936e-02, 1.4636449e-03, 7.3992419e-03, ...,\n",
       "           3.8750636e-04, 3.8750636e-04, 3.8750636e-04]]]], dtype=float32)>)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attention[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4bd29ad1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Variable 'Variable:0' shape=(1, 8, 128) dtype=float32, numpy=\n",
       " array([[[ 0.70087147,  0.1958967 , -0.35145903, ...,  0.48064098,\n",
       "           0.4918324 ,  0.03355688],\n",
       "         [ 0.20909105,  0.69546527, -0.23883833, ...,  0.5814026 ,\n",
       "           0.25828016,  0.5053409 ],\n",
       "         [-0.21123317,  0.7534062 ,  0.7333148 , ..., -0.10376038,\n",
       "           0.6470314 , -0.12154149],\n",
       "         ...,\n",
       "         [ 0.46920526, -0.04690957,  0.6305629 , ...,  0.34775922,\n",
       "           0.04588863, -0.03653677],\n",
       "         [ 0.03515827, -0.09518815,  0.4213055 , ...,  0.26995596,\n",
       "           0.2315686 , -0.09755877],\n",
       "         [ 0.15336037,  0.21321705,  0.70800805, ...,  0.54270494,\n",
       "          -0.08866469,  0.643626  ]]], dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 8, 128), dtype=float32, numpy=\n",
       " array([[[-8.9805186e-02, -1.5886374e-01,  9.1277137e-02, ...,\n",
       "           3.6378831e-01,  2.5522321e-02,  3.0075678e-01],\n",
       "         [-8.1214778e-02, -1.6048390e-01,  9.6112058e-02, ...,\n",
       "           3.1804240e-01,  2.0409845e-02,  2.2095262e-01],\n",
       "         [ 2.7948666e-02, -2.2614016e-01,  1.9418390e-01, ...,\n",
       "           1.1585881e-01,  1.6429509e-01,  2.7754471e-01],\n",
       "         ...,\n",
       "         [-1.5526921e-02, -3.8556319e-01,  3.0619612e-01, ...,\n",
       "           2.5994003e-02,  2.3547560e-05, -1.8568847e-01],\n",
       "         [-1.2658633e-01, -1.7539145e-01,  4.5724206e-02, ...,\n",
       "          -2.9824369e-02, -2.6436973e-01,  2.9063129e-01],\n",
       "         [-5.0465479e-02, -3.6430672e-01,  2.2890048e-01, ...,\n",
       "           5.8947504e-03, -2.8431438e-02,  7.4393384e-02]]], dtype=float32)>]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6773a0fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(32, 4, 128, 128), dtype=float32, numpy=\n",
       "array([[[[1., 1., 1., ..., 1., 1., 1.],\n",
       "         [1., 1., 1., ..., 1., 1., 1.],\n",
       "         [1., 1., 1., ..., 1., 1., 1.],\n",
       "         ...,\n",
       "         [1., 1., 1., ..., 1., 1., 1.],\n",
       "         [1., 1., 1., ..., 1., 1., 1.],\n",
       "         [1., 1., 1., ..., 1., 1., 1.]],\n",
       "\n",
       "        [[1., 1., 1., ..., 1., 1., 1.],\n",
       "         [1., 1., 1., ..., 1., 1., 1.],\n",
       "         [1., 1., 1., ..., 1., 1., 1.],\n",
       "         ...,\n",
       "         [1., 1., 1., ..., 1., 1., 1.],\n",
       "         [1., 1., 1., ..., 1., 1., 1.],\n",
       "         [1., 1., 1., ..., 1., 1., 1.]],\n",
       "\n",
       "        [[1., 1., 1., ..., 1., 1., 1.],\n",
       "         [1., 1., 1., ..., 1., 1., 1.],\n",
       "         [1., 1., 1., ..., 1., 1., 1.],\n",
       "         ...,\n",
       "         [1., 1., 1., ..., 1., 1., 1.],\n",
       "         [1., 1., 1., ..., 1., 1., 1.],\n",
       "         [1., 1., 1., ..., 1., 1., 1.]],\n",
       "\n",
       "        [[1., 1., 1., ..., 1., 1., 1.],\n",
       "         [1., 1., 1., ..., 1., 1., 1.],\n",
       "         [1., 1., 1., ..., 1., 1., 1.],\n",
       "         ...,\n",
       "         [1., 1., 1., ..., 1., 1., 1.],\n",
       "         [1., 1., 1., ..., 1., 1., 1.],\n",
       "         [1., 1., 1., ..., 1., 1., 1.]]],\n",
       "\n",
       "\n",
       "       [[[1., 1., 1., ..., 1., 1., 1.],\n",
       "         [1., 1., 1., ..., 1., 1., 1.],\n",
       "         [1., 1., 1., ..., 1., 1., 1.],\n",
       "         ...,\n",
       "         [1., 1., 1., ..., 1., 1., 1.],\n",
       "         [1., 1., 1., ..., 1., 1., 1.],\n",
       "         [1., 1., 1., ..., 1., 1., 1.]],\n",
       "\n",
       "        [[1., 1., 1., ..., 1., 1., 1.],\n",
       "         [1., 1., 1., ..., 1., 1., 1.],\n",
       "         [1., 1., 1., ..., 1., 1., 1.],\n",
       "         ...,\n",
       "         [1., 1., 1., ..., 1., 1., 1.],\n",
       "         [1., 1., 1., ..., 1., 1., 1.],\n",
       "         [1., 1., 1., ..., 1., 1., 1.]],\n",
       "\n",
       "        [[1., 1., 1., ..., 1., 1., 1.],\n",
       "         [1., 1., 1., ..., 1., 1., 1.],\n",
       "         [1., 1., 1., ..., 1., 1., 1.],\n",
       "         ...,\n",
       "         [1., 1., 1., ..., 1., 1., 1.],\n",
       "         [1., 1., 1., ..., 1., 1., 1.],\n",
       "         [1., 1., 1., ..., 1., 1., 1.]],\n",
       "\n",
       "        [[1., 1., 1., ..., 1., 1., 1.],\n",
       "         [1., 1., 1., ..., 1., 1., 1.],\n",
       "         [1., 1., 1., ..., 1., 1., 1.],\n",
       "         ...,\n",
       "         [1., 1., 1., ..., 1., 1., 1.],\n",
       "         [1., 1., 1., ..., 1., 1., 1.],\n",
       "         [1., 1., 1., ..., 1., 1., 1.]]],\n",
       "\n",
       "\n",
       "       [[[1., 1., 1., ..., 1., 1., 1.],\n",
       "         [1., 1., 1., ..., 1., 1., 1.],\n",
       "         [1., 1., 1., ..., 1., 1., 1.],\n",
       "         ...,\n",
       "         [1., 1., 1., ..., 1., 1., 1.],\n",
       "         [1., 1., 1., ..., 1., 1., 1.],\n",
       "         [1., 1., 1., ..., 1., 1., 1.]],\n",
       "\n",
       "        [[1., 1., 1., ..., 1., 1., 1.],\n",
       "         [1., 1., 1., ..., 1., 1., 1.],\n",
       "         [1., 1., 1., ..., 1., 1., 1.],\n",
       "         ...,\n",
       "         [1., 1., 1., ..., 1., 1., 1.],\n",
       "         [1., 1., 1., ..., 1., 1., 1.],\n",
       "         [1., 1., 1., ..., 1., 1., 1.]],\n",
       "\n",
       "        [[1., 1., 1., ..., 1., 1., 1.],\n",
       "         [1., 1., 1., ..., 1., 1., 1.],\n",
       "         [1., 1., 1., ..., 1., 1., 1.],\n",
       "         ...,\n",
       "         [1., 1., 1., ..., 1., 1., 1.],\n",
       "         [1., 1., 1., ..., 1., 1., 1.],\n",
       "         [1., 1., 1., ..., 1., 1., 1.]],\n",
       "\n",
       "        [[1., 1., 1., ..., 1., 1., 1.],\n",
       "         [1., 1., 1., ..., 1., 1., 1.],\n",
       "         [1., 1., 1., ..., 1., 1., 1.],\n",
       "         ...,\n",
       "         [1., 1., 1., ..., 1., 1., 1.],\n",
       "         [1., 1., 1., ..., 1., 1., 1.],\n",
       "         [1., 1., 1., ..., 1., 1., 1.]]],\n",
       "\n",
       "\n",
       "       ...,\n",
       "\n",
       "\n",
       "       [[[1., 1., 1., ..., 1., 1., 1.],\n",
       "         [1., 1., 1., ..., 1., 1., 1.],\n",
       "         [1., 1., 1., ..., 1., 1., 1.],\n",
       "         ...,\n",
       "         [1., 1., 1., ..., 1., 1., 1.],\n",
       "         [1., 1., 1., ..., 1., 1., 1.],\n",
       "         [1., 1., 1., ..., 1., 1., 1.]],\n",
       "\n",
       "        [[1., 1., 1., ..., 1., 1., 1.],\n",
       "         [1., 1., 1., ..., 1., 1., 1.],\n",
       "         [1., 1., 1., ..., 1., 1., 1.],\n",
       "         ...,\n",
       "         [1., 1., 1., ..., 1., 1., 1.],\n",
       "         [1., 1., 1., ..., 1., 1., 1.],\n",
       "         [1., 1., 1., ..., 1., 1., 1.]],\n",
       "\n",
       "        [[1., 1., 1., ..., 1., 1., 1.],\n",
       "         [1., 1., 1., ..., 1., 1., 1.],\n",
       "         [1., 1., 1., ..., 1., 1., 1.],\n",
       "         ...,\n",
       "         [1., 1., 1., ..., 1., 1., 1.],\n",
       "         [1., 1., 1., ..., 1., 1., 1.],\n",
       "         [1., 1., 1., ..., 1., 1., 1.]],\n",
       "\n",
       "        [[1., 1., 1., ..., 1., 1., 1.],\n",
       "         [1., 1., 1., ..., 1., 1., 1.],\n",
       "         [1., 1., 1., ..., 1., 1., 1.],\n",
       "         ...,\n",
       "         [1., 1., 1., ..., 1., 1., 1.],\n",
       "         [1., 1., 1., ..., 1., 1., 1.],\n",
       "         [1., 1., 1., ..., 1., 1., 1.]]],\n",
       "\n",
       "\n",
       "       [[[1., 1., 1., ..., 1., 1., 1.],\n",
       "         [1., 1., 1., ..., 1., 1., 1.],\n",
       "         [1., 1., 1., ..., 1., 1., 1.],\n",
       "         ...,\n",
       "         [1., 1., 1., ..., 1., 1., 1.],\n",
       "         [1., 1., 1., ..., 1., 1., 1.],\n",
       "         [1., 1., 1., ..., 1., 1., 1.]],\n",
       "\n",
       "        [[1., 1., 1., ..., 1., 1., 1.],\n",
       "         [1., 1., 1., ..., 1., 1., 1.],\n",
       "         [1., 1., 1., ..., 1., 1., 1.],\n",
       "         ...,\n",
       "         [1., 1., 1., ..., 1., 1., 1.],\n",
       "         [1., 1., 1., ..., 1., 1., 1.],\n",
       "         [1., 1., 1., ..., 1., 1., 1.]],\n",
       "\n",
       "        [[1., 1., 1., ..., 1., 1., 1.],\n",
       "         [1., 1., 1., ..., 1., 1., 1.],\n",
       "         [1., 1., 1., ..., 1., 1., 1.],\n",
       "         ...,\n",
       "         [1., 1., 1., ..., 1., 1., 1.],\n",
       "         [1., 1., 1., ..., 1., 1., 1.],\n",
       "         [1., 1., 1., ..., 1., 1., 1.]],\n",
       "\n",
       "        [[1., 1., 1., ..., 1., 1., 1.],\n",
       "         [1., 1., 1., ..., 1., 1., 1.],\n",
       "         [1., 1., 1., ..., 1., 1., 1.],\n",
       "         ...,\n",
       "         [1., 1., 1., ..., 1., 1., 1.],\n",
       "         [1., 1., 1., ..., 1., 1., 1.],\n",
       "         [1., 1., 1., ..., 1., 1., 1.]]],\n",
       "\n",
       "\n",
       "       [[[1., 1., 1., ..., 1., 1., 1.],\n",
       "         [1., 1., 1., ..., 1., 1., 1.],\n",
       "         [1., 1., 1., ..., 1., 1., 1.],\n",
       "         ...,\n",
       "         [1., 1., 1., ..., 1., 1., 1.],\n",
       "         [1., 1., 1., ..., 1., 1., 1.],\n",
       "         [1., 1., 1., ..., 1., 1., 1.]],\n",
       "\n",
       "        [[1., 1., 1., ..., 1., 1., 1.],\n",
       "         [1., 1., 1., ..., 1., 1., 1.],\n",
       "         [1., 1., 1., ..., 1., 1., 1.],\n",
       "         ...,\n",
       "         [1., 1., 1., ..., 1., 1., 1.],\n",
       "         [1., 1., 1., ..., 1., 1., 1.],\n",
       "         [1., 1., 1., ..., 1., 1., 1.]],\n",
       "\n",
       "        [[1., 1., 1., ..., 1., 1., 1.],\n",
       "         [1., 1., 1., ..., 1., 1., 1.],\n",
       "         [1., 1., 1., ..., 1., 1., 1.],\n",
       "         ...,\n",
       "         [1., 1., 1., ..., 1., 1., 1.],\n",
       "         [1., 1., 1., ..., 1., 1., 1.],\n",
       "         [1., 1., 1., ..., 1., 1., 1.]],\n",
       "\n",
       "        [[1., 1., 1., ..., 1., 1., 1.],\n",
       "         [1., 1., 1., ..., 1., 1., 1.],\n",
       "         [1., 1., 1., ..., 1., 1., 1.],\n",
       "         ...,\n",
       "         [1., 1., 1., ..., 1., 1., 1.],\n",
       "         [1., 1., 1., ..., 1., 1., 1.],\n",
       "         [1., 1., 1., ..., 1., 1., 1.]]]], dtype=float32)>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.ones((32, 4, 128, 128))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "fbc2ca83",
   "metadata": {},
   "outputs": [],
   "source": [
    "def eigenRank(tensor):\n",
    "    batch_shape = tf.shape(tensor)[:-2]\n",
    "    matrix_shape = tf.shape(tensor)[-2:]\n",
    "    l = len(batch_shape)\n",
    "    print(tensor.shape)\n",
    "    if matrix_shape[0]>matrix_shape[1]: tensor = tf.transpose(tensor, tuple(i for i in range(l)) + (l+1, l))\n",
    "    M = tf.matmul(tensor, tensor, transpose_b = True)\n",
    "    print(tensor.shape, M.shape)\n",
    "    trace = tf.linalg.trace(M)\n",
    "    M_squared = tf.matmul(M, M)\n",
    "    print(M_squared.shape)\n",
    "    trace_squared = tf.linalg.trace(M_squared)\n",
    "    return (trace**2)/trace_squared"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "35a5c5b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "att = attention[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "880f8bd9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4, 8, 128, 128)\n",
      "(4, 8, 128, 128) (4, 8, 128, 128)\n",
      "(4, 8, 128, 128)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(4, 8), dtype=float32, numpy=\n",
       "array([[1.7550379, 1.7803738, 1.75285  , 1.7513034, 1.7525351, 1.7638059,\n",
       "        1.7347128, 1.7705356],\n",
       "       [1.7289912, 1.7548829, 1.7417741, 1.7558697, 1.7845999, 1.7643174,\n",
       "        1.756217 , 1.7740963],\n",
       "       [1.7501621, 1.7563052, 1.7588693, 1.7585539, 1.7645165, 1.745992 ,\n",
       "        1.7515677, 1.7681904],\n",
       "       [1.7503204, 1.7486261, 1.7505194, 1.763513 , 1.7547823, 1.742856 ,\n",
       "        1.7614138, 1.7686299]], dtype=float32)>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eigenRank(tf.random.uniform(\n",
    "            (4,8, 128, 128), minval=0, maxval=1, dtype=tf.dtypes.float32, seed=420, name=None))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "32453501",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'Net' object has no attribute 'mha_layers'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_7089/379923011.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mvs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0matt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mmha\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msl\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmha_layers\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msl_layers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m     \u001b[0mv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ma\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmha\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'Net' object has no attribute 'mha_layers'"
     ]
    }
   ],
   "source": [
    "mask = tf.cast(tf.math.equal(x[:1], 0), tf.float32)[:, tf.newaxis, :, tf.newaxis]\n",
    "        \n",
    "v = model.enc_embed(x)[:]#, model.encoder.variable#tf.tile(model.encoder.variable, (32, 1, 1))\n",
    "vs = [v]\n",
    "att = []\n",
    "for mha, sl in zip(model.mha_layers, model.sl_layers):\n",
    "    v, a = mha(v, v, v, mask)\n",
    "    v = sl(v)\n",
    "    vs.append(v)\n",
    "    att.append(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5ef2256",
   "metadata": {},
   "outputs": [],
   "source": [
    "z = vs[-1][:8, :1, :16]\n",
    "z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "057ab246",
   "metadata": {},
   "outputs": [],
   "source": [
    "z = z - z[:, :1, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "282b3fbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reduce_sum(tf.cast(z>0.001, tf.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d177c501",
   "metadata": {},
   "outputs": [],
   "source": [
    "att[0][:1, :1, :16, :16]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae4dd682",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow_probability as tfp\n",
    "\n",
    "normal = tfp.distributions.Normal(tf.zeros((32)),  tf.ones((32)))\n",
    "x = tf.cast(tf.math.softmax(normal.sample(24)*tf.constant([[(i+1)*0.4] for i in range(24)]), axis=-1)>0.1, tf.int32)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b423b84d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
