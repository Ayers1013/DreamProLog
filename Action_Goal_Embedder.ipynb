{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ebf2bf77",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-12-21 17:03:57.385173: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1\n"
     ]
    }
   ],
   "source": [
    "from main import init_config\n",
    "from controller import Controller\n",
    "from dataset.process import TokenParser\n",
    "\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dffc85fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running the DreamProlog algorithm.\n",
      "There was a problem with the provided arguments. The program will run in the default setting:\n",
      "--configs prolog --logdir logdir\n",
      "Namespace(act='elu', action_gnn_hidden_act=64, action_gnn_hidden_val=200, action_gnn_layers=6, action_gnn_next_shape=(32, 64, 32), action_gnn_start_shape=(4, 1, 4), action_repeat=1, actor_disc=5, actor_dist='normal', actor_entropy='1e-4', actor_grad_clip=100, actor_init_std=1.0, actor_layers=4, actor_lr=0.001, actor_min_std=0.1, actor_outscale=0.0, actor_state_entropy=0.0, actor_temp=0.1, atari_grayscale=False, behavior_stop_grad=True, clip_rewards='identity', collect_dyn_sample=True, dataset_size=100000, debug=False, disag_layers=1, disag_log=True, disag_models=3, disag_offset=0, disag_target='embed', disag_units=200, discount=0.95, discount_lambda=0.8, discount_layers=2, discount_scale=1.0, dyn_cell='gru', dyn_deter=512, dyn_discrete=32, dyn_hidden=512, dyn_input_layers=5, dyn_mean_act='none', dyn_min_std=0.1, dyn_output_layers=5, dyn_shared=False, dyn_std_act='sigmoid2', dyn_stoch=192, envs=1, eval_every=500, eval_noise=0.0, eval_state_mean=False, evaldir=None, expl_amount=0.0, expl_behavior='greedy', expl_extr_scale=0.0, expl_gifs=False, expl_intr_scale=1.0, expl_until=10000000.0, free_heads=('image', 'reward', 'discount'), future_entropy=False, gnn_hidden_act=128, gnn_hidden_val=384, gnn_layers=14, gnn_next_shape=(32, 64, 32), gnn_start_shape=(4, 1, 4), gpu_growth=True, grad_clip=200, grad_heads=('image', 'reward', 'discount', 'action_mask'), imag_gradient='reinforce', imag_gradient_mix='0.1', imag_horizon=3, imag_sample=True, kl_balance='0.8', kl_free='0.5', kl_scale='1.0', log_every=10, model_lr=0.0009, offline_evaldir='', offline_traindir='', opt='adam', opt_eps=0.0008, oversample_ends=False, precision=32, pred_discount=True, prefill=40000, pretrain=5, reset_every=0, reward_layers=2, reward_scale=1.0, seed=0, share_gnn=True, slow_actor_target=False, slow_target_fraction=1, slow_target_update=100, slow_value_target=False, steps=1000000, task='prolog_void', time_limit=1000, train_every=25, train_steps=10, traindir=None, units=192, value_decay=0.0, value_grad_clip=100, value_head='normal', value_layers=3, value_lr=0.001, weight_decay=0.0)\n",
      "Logdir logdir\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "usage: ipykernel_launcher.py [-h] --configs CONFIGS [CONFIGS ...] --logdir\n",
      "                             LOGDIR\n",
      "ipykernel_launcher.py: error: the following arguments are required: --configs, --logdir\n",
      "2021-12-21 17:03:59.398499: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set\n",
      "2021-12-21 17:03:59.399323: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcuda.so.1\n",
      "2021-12-21 17:03:59.430036: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: \n",
      "pciBusID: 0000:05:00.0 name: TITAN V computeCapability: 7.0\n",
      "coreClock: 1.455GHz coreCount: 80 deviceMemorySize: 11.78GiB deviceMemoryBandwidth: 607.97GiB/s\n",
      "2021-12-21 17:03:59.436911: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 1 with properties: \n",
      "pciBusID: 0000:09:00.0 name: TITAN V computeCapability: 7.0\n",
      "coreClock: 1.455GHz coreCount: 80 deviceMemorySize: 11.78GiB deviceMemoryBandwidth: 607.97GiB/s\n",
      "2021-12-21 17:03:59.436945: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1\n",
      "2021-12-21 17:03:59.438606: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10\n",
      "2021-12-21 17:03:59.438644: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.10\n",
      "2021-12-21 17:03:59.440236: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10\n",
      "2021-12-21 17:03:59.440477: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10\n",
      "2021-12-21 17:03:59.442091: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10\n",
      "2021-12-21 17:03:59.442905: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.10\n",
      "2021-12-21 17:03:59.446357: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7\n",
      "2021-12-21 17:03:59.449222: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0, 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Suite: prolog\n",
      "Found 131 problem files.\n",
      "Query:\n",
      "    init_python(\"leancop/theorems/m2n140/t68_enumset1.p\",[conj, nodef, eager_reduction(1)],GnnInput, SimpleFeatures, TextFeatures, TextActions, ActionsMask, Result) \n",
      "\n",
      "Suite: prolog\n",
      "Found 131 problem files.\n",
      "Query:\n",
      "    init_python(\"leancop/theorems/m2n140/t80_enumset1.p\",[conj, nodef, eager_reduction(1)],GnnInput, SimpleFeatures, TextFeatures, TextActions, ActionsMask, Result) \n",
      "\n",
      "Prefill dataset (0 steps).\n",
      "Loaded problem: m2n140__t48_orders_2\n",
      "Found 131 problem files.\n",
      "Query:\n",
      "    init_python(\"leancop/theorems/m2n140/t52_relat_1.p\",[conj, nodef, eager_reduction(1)],GnnInput, SimpleFeatures, TextFeatures, TextActions, ActionsMask, Result) \n",
      "\n",
      "Eval episode has 8 steps and return -0.200.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kristsz/DreamProLog/envs/wrappers.py:57: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  value = np.array(value)\n"
     ]
    }
   ],
   "source": [
    "ctrl = Controller(*init_config())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9c2f2738",
   "metadata": {},
   "outputs": [],
   "source": [
    "meta = ctrl.datasetManager._train_eps._meta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b651f343",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = []\n",
    "for v in meta.values():\n",
    "    ds.extend([str(s)[1:] for s in v['action_space_text']])\n",
    "    \n",
    "parser = TokenParser()\n",
    "\n",
    "def pad(narr):\n",
    "    size = narr.size\n",
    "    return np.pad(narr, [0, 128-size])\n",
    "\n",
    "parsed_ds = []\n",
    "for dp in ds:\n",
    "    parsed_ds.append(pad(np.array(parser.parse(dp), dtype = np.int32)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a9423678",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# EOP NEG r1_tarski 2 skolem_3 0 skolem_5 0 EOP\n",
      "[2 3 4 5 6 7 8 9 8 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\n",
      "NEG r1_tarski 2 skolem_3 0 skolem_5 0 EOP # EOP\n",
      "[4 5 6 7 8 9 8 3 2 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\n",
      "# EOP NEG = 2 skolem_4 0 k6_subset_1 2 skolem_5 0 skolem_3 0 EOP\n",
      "[ 2  3  4 10  6 11  8 12  6  9  8  7  8  3  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(3):\n",
    "    print(ds[i], parsed_ds[i], sep='\\n', end='\\n\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "248d81a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-12-21 17:04:25.785848: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2021-12-21 17:04:26.025857: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: \n",
      "pciBusID: 0000:05:00.0 name: TITAN V computeCapability: 7.0\n",
      "coreClock: 1.455GHz coreCount: 80 deviceMemorySize: 11.78GiB deviceMemoryBandwidth: 607.97GiB/s\n",
      "2021-12-21 17:04:26.026725: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 1 with properties: \n",
      "pciBusID: 0000:09:00.0 name: TITAN V computeCapability: 7.0\n",
      "coreClock: 1.455GHz coreCount: 80 deviceMemorySize: 11.78GiB deviceMemoryBandwidth: 607.97GiB/s\n",
      "2021-12-21 17:04:26.026757: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1\n",
      "2021-12-21 17:04:26.026785: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10\n",
      "2021-12-21 17:04:26.026801: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.10\n",
      "2021-12-21 17:04:26.026815: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10\n",
      "2021-12-21 17:04:26.026830: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10\n",
      "2021-12-21 17:04:26.026845: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10\n",
      "2021-12-21 17:04:26.026860: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.10\n",
      "2021-12-21 17:04:26.026875: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7\n",
      "2021-12-21 17:04:26.030132: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0, 1\n",
      "2021-12-21 17:04:26.030173: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1\n",
      "2021-12-21 17:04:26.738609: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1261] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
      "2021-12-21 17:04:26.738640: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1267]      0 1 \n",
      "2021-12-21 17:04:26.738646: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1280] 0:   N Y \n",
      "2021-12-21 17:04:26.738649: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1280] 1:   Y N \n",
      "2021-12-21 17:04:26.741094: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1406] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10484 MB memory) -> physical GPU (device: 0, name: TITAN V, pci bus id: 0000:05:00.0, compute capability: 7.0)\n",
      "2021-12-21 17:04:26.742573: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1406] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:1 with 10487 MB memory) -> physical GPU (device: 1, name: TITAN V, pci bus id: 0000:09:00.0, compute capability: 7.0)\n",
      "2021-12-21 17:04:26.742823: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "BATCH_SIZE = 32\n",
    "def generator():\n",
    "    while True:\n",
    "        x = tf.constant([parsed_ds[np.random.randint(len(parsed_ds))] for i in range(BATCH_SIZE)])\n",
    "        yield x, x\n",
    "sgn = tf.TensorSpec((BATCH_SIZE, 128), dtype=tf.int32)\n",
    "tf_ds = tf.data.Dataset.from_generator(generator, output_signature = (sgn, sgn))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "aac11b90",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "BATCH_SIZE = 32\n",
    "def generator():\n",
    "    for data in parsed_ds:\n",
    "        x = tf.constant(data)\n",
    "        yield x, x\n",
    "sgn = tf.TensorSpec((128), dtype=tf.int32)\n",
    "tf_ds = tf.data.Dataset.from_generator(generator, output_signature = (sgn, sgn))\n",
    "tf_ds = tf_ds.shuffle(300*BATCH_SIZE).batch(BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ca04efb5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "128 11961\n"
     ]
    }
   ],
   "source": [
    "m=0\n",
    "for p in parsed_ds:\n",
    "    m = max(m, len(p))\n",
    "print(m, len(ds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4e75e981",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-12-21 17:06:09.725205: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:116] None of the MLIR optimization passes are enabled (registered 2)\n",
      "2021-12-21 17:06:09.745625: I tensorflow/core/platform/profile_utils/cpu_utils.cc:112] CPU Frequency: 3598190000 Hz\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor: shape=(32, 128), dtype=int32, numpy=\n",
       " array([[178,   6,  13, ...,   0,   0,   0],\n",
       "        [  4,  43,  21, ...,   0,   0,   0],\n",
       "        [  4,  10,   6, ...,   0,   0,   0],\n",
       "        ...,\n",
       "        [ 15,   6,  13, ...,   0,   0,   0],\n",
       "        [110,  21,  13, ...,   0,   0,   0],\n",
       "        [ 10,   6,  13, ...,   0,   0,   0]], dtype=int32)>,\n",
       " <tf.Tensor: shape=(32, 128), dtype=int32, numpy=\n",
       " array([[178,   6,  13, ...,   0,   0,   0],\n",
       "        [  4,  43,  21, ...,   0,   0,   0],\n",
       "        [  4,  10,   6, ...,   0,   0,   0],\n",
       "        ...,\n",
       "        [ 15,   6,  13, ...,   0,   0,   0],\n",
       "        [110,  21,  13, ...,   0,   0,   0],\n",
       "        [ 10,   6,  13, ...,   0,   0,   0]], dtype=int32)>)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds_it = iter(tf_ds)\n",
    "next(ds_it)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f742c6de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU available:  [PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU'), PhysicalDevice(name='/physical_device:GPU:1', device_type='GPU')]\n"
     ]
    }
   ],
   "source": [
    "from transformer import EncoderLayer, DecoderLayer, MultiHeadAttention\n",
    "\n",
    "def scaled_dot_product_attention2(q, k, v, mask):\n",
    "    matmul_qk = tf.matmul(q, k, transpose_b=True)  # (..., seq_len_q, seq_len_k)\n",
    "\n",
    "    # scale matmul_qk\n",
    "    dk = tf.cast(tf.shape(k)[-1], tf.float32)\n",
    "    scaled_attention_logits = matmul_qk / tf.math.sqrt(dk)\n",
    "\n",
    "    # add the mask to the scaled tensor.\n",
    "    if mask is not None:\n",
    "        scaled_attention_logits += (mask * -1e9)\n",
    "\n",
    "    # softmax is normalized on the last axis (seq_len_k) so that the scores\n",
    "    # add up to 1.\n",
    "    attention_weights = tf.nn.softmax(scaled_attention_logits, axis=-1)  # (..., seq_len_q, seq_len_k)\n",
    "\n",
    "    output = tf.matmul(attention_weights, v) # (..., seq_len_q, depth_v)\n",
    "    tf.print(output.shape)\n",
    "\n",
    "    return output, attention_weights\n",
    "\n",
    "class Encoder(tf.keras.layers.Layer):\n",
    "    def __init__(self, d_model, num_heads, dff, querry,rate):\n",
    "        super().__init__()\n",
    "        self.layers = [EncoderLayer(d_model, num_heads, dff, rate) for i in range(5)]\n",
    "        \n",
    "        self.mha = MultiHeadAttention(d_model, num_heads)\n",
    "        \n",
    "        shape=(querry, d_model)\n",
    "        self.variable = tf.Variable(tf.random.uniform(\n",
    "            shape, minval=0, maxval=1, dtype=tf.dtypes.float32, seed=69, name=None))\n",
    "        \n",
    "        self.num_heads = num_heads\n",
    "        self.d_model = d_model\n",
    "\n",
    "        assert d_model % self.num_heads == 0\n",
    "\n",
    "        self.depth = d_model // self.num_heads\n",
    "\n",
    "        self.wq = tf.keras.layers.Dense(d_model)\n",
    "        self.wk = tf.keras.layers.Dense(d_model)\n",
    "        self.wv = tf.keras.layers.Dense(d_model)\n",
    "\n",
    "        self.dense = tf.keras.layers.Dense(d_model)\n",
    "        \n",
    "    def split_heads(self, x, batch_size):\n",
    "        \"\"\"Split the last dimension into (num_heads, depth).\n",
    "        Transpose the result such that the shape is (batch_size, num_heads, seq_len, depth)\n",
    "        \"\"\"\n",
    "        x = tf.reshape(x, (batch_size, -1, self.num_heads, self.depth))\n",
    "        return tf.transpose(x, perm=[0, 2, 1, 3])\n",
    "                                    \n",
    "    def mha(self, x):\n",
    "        q, k = x, x\n",
    "        batch_size = tf.shape(q)[0]\n",
    "\n",
    "        q = self.wq(q)  # (batch_size, seq_len, d_model)\n",
    "        k = self.wk(k)  # (batch_size, seq_len, d_model)\n",
    "        #v = self.wv(v)  # (batch_size, seq_len, d_model)\n",
    "\n",
    "        q = self.split_heads(q, batch_size)  # (batch_size, num_heads, seq_len_q, depth)\n",
    "        k = self.split_heads(k, batch_size)  # (batch_size, num_heads, seq_len_k, depth)\n",
    "        #v = self.split_heads(v, batch_size)  # (batch_size, num_heads, seq_len_v, depth)\n",
    "        v = tf.reshape(self.variable, (1, -1, self.num_heads, self.depth))\n",
    "        v = tf.transpose(v, perm=[0, 2, 1, 3])\n",
    "\n",
    "        # scaled_attention.shape == (batch_size, num_heads, seq_len_q, depth)\n",
    "        # attention_weights.shape == (batch_size, num_heads, seq_len_q, seq_len_k)\n",
    "        scaled_attention, attention_weights = scaled_dot_product_attention2(\n",
    "            q, k, v, None)\n",
    "        \n",
    "        print(scaled_attention.shape)\n",
    "\n",
    "        scaled_attention = tf.transpose(scaled_attention, perm=[0, 2, 1, 3])  # (batch_size, seq_len_q, num_heads, depth)\n",
    "\n",
    "        concat_attention = tf.reshape(scaled_attention,\n",
    "                                      (batch_size, -1, self.d_model))  # (batch_size, seq_len_q, d_model)\n",
    "\n",
    "        output = self.dense(concat_attention)  # (batch_size, seq_len_q, d_model)\n",
    "\n",
    "        return output\n",
    "        \n",
    "        \n",
    "    def call(self, x, training):\n",
    "        for layer in self.layers:\n",
    "            x = layer(x,training, None)\n",
    "        \n",
    "        print('2', x.shape)\n",
    "            \n",
    "        x = self.mha(x,x, self.variable, None)\n",
    "        \n",
    "        return x\n",
    "    \n",
    "class Decoder(tf.keras.layers.Layer):\n",
    "    def __init__(self, d_model, num_heads, dff, output_length, rate):\n",
    "        super().__init__()\n",
    "        self.layers = [DecoderLayer(d_model, num_heads, dff, rate) for i in range(5)]\n",
    "        \n",
    "        shape=(BATCH_SIZE, output_length, d_model)\n",
    "        self.variable = tf.Variable(tf.random.uniform(\n",
    "            shape, minval=0, maxval=1, dtype=tf.dtypes.float32, seed=69, name=None))\n",
    "        \n",
    "        \n",
    "    def call(self, x, training):\n",
    "        y = self.variable\n",
    "        for layer in self.layers:\n",
    "            y, _, _ = layer(y, x, training, None, None)\n",
    "            \n",
    "        return y\n",
    "        \n",
    "class Net(tf.keras.Model):\n",
    "    def __init__(self, d_model, num_heads, dff):\n",
    "        super().__init__()\n",
    "        self.encoder = Encoder(d_model, num_heads, dff, 8, 0.04)  \n",
    "        self.enc_embed = tf.keras.layers.Embedding(300, d_model)\n",
    "        self.decoder = Decoder(d_model, num_heads, dff, 128, 0.04)\n",
    "        \n",
    "        self.dropout = tf.keras.layers.Dropout(0.08)\n",
    "        \n",
    "        self.dense = tf.keras.layers.Dense(300, activation='relu', use_bias=False)\n",
    "        \n",
    "    def call(self, x, training):\n",
    "        x = self.enc_embed(x)\n",
    "        x = self.encoder(x, training)\n",
    "        print(x[0].shape)\n",
    "        x = self.dropout(x)\n",
    "        x = self.decoder(x, training)\n",
    "        \n",
    "        x = self.dense(x)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7f56d9b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Loss(tf.keras.losses.Loss):\n",
    "    def __init__(self, omega=0.1):\n",
    "        super().__init__()\n",
    "        self.omega = omega\n",
    "        \n",
    "    def call(self, y_true, y_pred):\n",
    "        y = tf.nn.softmax(y_pred, axis=-1)\n",
    "        y_probs = tf.gather(y, y_true, axis=-1, batch_dims=2)\n",
    "        y_log_probs = tf.math.log(y_probs+0.001)\n",
    "        #loss = self.omega*y_log_probs + (1-self.omega)*tf.math.cumsum(y_log_probs, axis=-1)\n",
    "        loss = y_log_probs*tf.math.cumprod(0.97*tf.ones((32,128)), axis=-1)\n",
    "        loss = -tf.math.reduce_sum(loss)/(128*32)\n",
    "        return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e8954c0e",
   "metadata": {},
   "outputs": [
    {
     "ename": "InvalidArgumentError",
     "evalue": "Input to reshape is a tensor with 4096 values, but the requested shape requires a multiple of 8192",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_27366/367064309.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_true\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mds_it\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mencoder\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mEncoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m256\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m8\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m512\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m8\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.04\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mk\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mq\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/tf2/lib/python3.7/site-packages/tensorflow/python/data/ops/iterator_ops.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    745\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m__next__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    746\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 747\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_internal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    748\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOutOfRangeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    749\u001b[0m       \u001b[0;32mraise\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/tf2/lib/python3.7/site-packages/tensorflow/python/data/ops/iterator_ops.py\u001b[0m in \u001b[0;36m_next_internal\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    727\u001b[0m     \u001b[0;31m# TODO(b/77291417): This runs in sync mode as iterators use an error status\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    728\u001b[0m     \u001b[0;31m# to communicate that there is no more data to iterate over.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 729\u001b[0;31m     \u001b[0;32mwith\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecution_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSYNC\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    730\u001b[0m       ret = gen_dataset_ops.iterator_get_next(\n\u001b[1;32m    731\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterator_resource\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/tf2/lib/python3.7/contextlib.py\u001b[0m in \u001b[0;36m__enter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    110\u001b[0m         \u001b[0;32mdel\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    111\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 112\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgen\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    113\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    114\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"generator didn't yield\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/tf2/lib/python3.7/site-packages/tensorflow/python/eager/context.py\u001b[0m in \u001b[0;36mexecution_mode\u001b[0;34m(mode)\u001b[0m\n\u001b[1;32m   2109\u001b[0m     \u001b[0mexecutor_old\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecutor\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2110\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2111\u001b[0;31m       \u001b[0mexecutor_old\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2112\u001b[0m       \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecutor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mexecutor_new\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2113\u001b[0m       \u001b[0;32myield\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/tf2/lib/python3.7/site-packages/tensorflow/python/eager/executor.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     67\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m     \u001b[0;34m\"\"\"Waits for ops dispatched in this executor to finish.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 69\u001b[0;31m     \u001b[0mpywrap_tfe\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTFE_ExecutorWaitForAllPendingNodes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     70\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mclear_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m: Input to reshape is a tensor with 4096 values, but the requested shape requires a multiple of 8192"
     ]
    }
   ],
   "source": [
    "x, y_true = next(ds_it)\n",
    "encoder = Encoder(256, 8, 512, 8, 0.04)\n",
    "q, k = x, x\n",
    "batch_size = tf.shape(q)[0]\n",
    "print(q.shape)\n",
    "\n",
    "q = encoder.split_heads(q, batch_size)  # (batch_size, num_heads, seq_len_q, depth)\n",
    "k = encoder.split_heads(k, batch_size)  # (batch_size, num_heads, seq_len_k, depth)\n",
    "#v = self.split_heads(v, batch_size)  # (batch_size, num_heads, seq_len_v, depth)\n",
    "v = tf.reshape(encoder.variable, (1, -1, self.num_heads, self.depth))\n",
    "v = tf.transpose(v, perm=[0, 2, 1, 3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ef2acc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Net(256, 8, 512)\n",
    "x, y_true = next(ds_it)\n",
    "y_pred = model(x, False)\n",
    "loss1 = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
    "loss2 = Loss()\n",
    "print(loss2(y_true, y_pred))\n",
    "model.compile(optimizer=tf.keras.optimizers.SGD(learning_rate=0.01), loss=Loss(), metrics=[])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1a0ee1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(tf_ds, epochs = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b98c67be",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.decoder.variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b35ce6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "x, y_true = next(ds_it)\n",
    "y_pred = model(x, False)\n",
    "y_pred = tf.nn.softmax(y_pred, axis=-1)\n",
    "y_probs = tf.gather(y_pred, y_true, axis=-1, batch_dims=2)\n",
    "y_pred = tf.math.argmax(y_pred, axis=-1)\n",
    "print(x[:4], y_pred[:4], tf.cast(100*y_probs[:4], dtype=tf.int32), sep='\\n\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32c5fdae",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.Tensor(\n",
    "[[10  6 13 14  3  4 73 24 14  3 73 24 13  3  0  0  0  0  0  0  0  0  0  0\n",
    "   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
    "   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
    "   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
    "   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
    "   0  0  0  0  0  0  0  0]\n",
    " [22  6 13 39 24 14  3 38 24 14  3 46 24 14  3 37 24 14  3  4 34 24 14  3\n",
    "  22  6 17 39 24 14  3 22  6 19 39 24 14  3  4 10  6 19 49 21 14 17 13  3\n",
    "  48 21 14 19 17  3 48 21 14 19 13  3  4 48 21 14 16 33 19 13 17 14 13  3\n",
    "   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
    "   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
    "   0  0  0  0  0  0  0  0]\n",
    " [ 4 34 24 13  3  2  3  4 96 24  7  8  3  4 22  6  9 24 13 39 24  7  8  3\n",
    "  15  6 13 99 24  7  8  3 36 24 13  3 97 24 13  3 98  6 13  7  8  3  0  0\n",
    "   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
    "   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
    "   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
    "   0  0  0  0  0  0  0  0]\n",
    " [29 24 13  3 10  6 13 26  6 14 17  3  4 15  6 58  6 19 44 13  3 15  6 58\n",
    "   6 19 45 14  3 15  6 58  6 45 44 17  3  0  0  0  0  0  0  0  0  0  0  0\n",
    "   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
    "   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
    "   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
    "   0  0  0  0  0  0  0  0]], shape=(4, 128), dtype=int32)\n",
    "\n",
    "tf.Tensor(\n",
    "[[10  6 13 14  3 10 73 24  3  3 73 24 14  3  0  0  0  0  0  0  0  0  0  0\n",
    "   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
    "   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
    "   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
    "   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
    "   0  0  0  0  0  0  0  0]\n",
    " [22  6 13 39 24 14  3 38 24 14  3 46 24 14  3 37 24 14  3  4 34 24 14  3\n",
    "  22  6 17 39  6 14  3 22  6 19 39 24 14  3  4 10  6 19 49 21 14 14  6  3\n",
    "  48 21 14 19 17  3 48 21 14 14 13  3  4 48 21 16 16 13  0  0 14 14 14  0\n",
    "   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
    "   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
    "   0  0  0  0  0  0  0  0]\n",
    " [ 4  6 13  7  8  3  8  3  4  3  7  7  8 24  3  3  7  8  8  3  3  8  8 24\n",
    "  24  8  3 24 24 24 24 24 24  8 24  3 24 24 24  3  3  3  7  7  3  0  0  0\n",
    "   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
    "   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
    "   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
    "   0  0  0  0  0  0  0  0]\n",
    " [10  6 13  3  6 14 13  3 29 24 17  3  4  6  6 58  6 19 44 13  4 15  6 58\n",
    "   6  6 45 14  3 15  6 58 14 45  6 19 17  0  0  0  0  0  0  0  0  0  0  0\n",
    "   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
    "   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
    "   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
    "   0  0  0  0  0  0  0  0]], shape=(4, 128), dtype=int64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10af2dbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = tf.constant([[[2,2],[1,0]],[[1,1],[4,8]]])\n",
    "b = tf.constant([[[1],[10]]])\n",
    "tf.matmul(a,b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e68a5779",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
