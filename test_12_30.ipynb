{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "136ab73b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-09 18:09:04.494688: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running the DreamProlog algorithm.\n",
      "There was a problem with the provided arguments. The program will run in the default setting:\n",
      "--configs prolog --logdir logdir\n",
      "Namespace(act='elu', action_gnn_hidden_act=64, action_gnn_hidden_val=200, action_gnn_layers=6, action_gnn_next_shape=(32, 64, 32), action_gnn_start_shape=(4, 1, 4), action_repeat=1, actor_disc=5, actor_dist='normal', actor_entropy='1e-4', actor_grad_clip=100, actor_init_std=1.0, actor_layers=4, actor_lr=0.001, actor_min_std=0.1, actor_outscale=0.0, actor_state_entropy=0.0, actor_temp=0.1, atari_grayscale=False, behavior_stop_grad=True, clip_rewards='identity', collect_dyn_sample=True, dataset_size=100000, debug=False, disag_layers=1, disag_log=True, disag_models=3, disag_offset=0, disag_target='embed', disag_units=200, discount=0.95, discount_lambda=0.8, discount_layers=2, discount_scale=1.0, dyn_cell='gru', dyn_deter=512, dyn_discrete=32, dyn_hidden=512, dyn_input_layers=5, dyn_mean_act='none', dyn_min_std=0.1, dyn_output_layers=5, dyn_shared=False, dyn_std_act='sigmoid2', dyn_stoch=192, envs=1, eval_every=500, eval_noise=0.0, eval_state_mean=False, evaldir=None, expl_amount=0.0, expl_behavior='greedy', expl_extr_scale=0.0, expl_gifs=False, expl_intr_scale=1.0, expl_until=10000000.0, free_heads=('image', 'reward', 'discount'), future_entropy=False, gnn_hidden_act=128, gnn_hidden_val=384, gnn_layers=14, gnn_next_shape=(32, 64, 32), gnn_start_shape=(4, 1, 4), gpu_growth=True, grad_clip=200, grad_heads=('image', 'reward', 'discount', 'action_mask'), imag_gradient='reinforce', imag_gradient_mix='0.1', imag_horizon=3, imag_sample=True, kl_balance='0.8', kl_free='0.5', kl_scale='1.0', log_every=10, model_lr=0.0009, offline_evaldir='', offline_traindir='', opt='adam', opt_eps=0.0008, oversample_ends=False, precision=32, pred_discount=True, prefill=40000, pretrain=5, reset_every=0, reward_layers=2, reward_scale=1.0, seed=0, share_gnn=True, slow_actor_target=False, slow_target_fraction=1, slow_target_update=100, slow_value_target=False, steps=1000000, task='prolog_void', time_limit=1000, train_every=25, train_steps=10, traindir=None, units=192, value_decay=0.0, value_grad_clip=100, value_head='normal', value_layers=3, value_lr=0.001, weight_decay=0.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "usage: ipykernel_launcher.py [-h] --configs CONFIGS [CONFIGS ...] --logdir\n",
      "                             LOGDIR\n",
      "ipykernel_launcher.py: error: the following arguments are required: --configs, --logdir\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logdir logdir\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-09 18:09:05.901674: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set\n",
      "2022-01-09 18:09:05.902345: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcuda.so.1\n",
      "2022-01-09 18:09:07.217588: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: \n",
      "pciBusID: 0000:05:00.0 name: TITAN V computeCapability: 7.0\n",
      "coreClock: 1.455GHz coreCount: 80 deviceMemorySize: 11.78GiB deviceMemoryBandwidth: 607.97GiB/s\n",
      "2022-01-09 18:09:07.217620: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1\n",
      "2022-01-09 18:09:07.219046: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10\n",
      "2022-01-09 18:09:07.219077: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.10\n",
      "2022-01-09 18:09:07.220308: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10\n",
      "2022-01-09 18:09:07.220506: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10\n",
      "2022-01-09 18:09:07.221953: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10\n",
      "2022-01-09 18:09:07.222686: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.10\n",
      "2022-01-09 18:09:07.225696: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7\n",
      "2022-01-09 18:09:07.226908: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Suite: prolog\n",
      "Found 131 problem files.\n",
      "Query:\n",
      "    init_python(\"leancop/theorems/m2n140/l18_zfmisc_1.p\",[conj, nodef, eager_reduction(1)],GnnInput, SimpleFeatures, TextFeatures, TextActions, ActionsMask, Result) \n",
      "\n",
      "Suite: prolog\n",
      "Found 131 problem files.\n",
      "Query:\n",
      "    init_python(\"leancop/theorems/m2n140/t40_funct_1.p\",[conj, nodef, eager_reduction(1)],GnnInput, SimpleFeatures, TextFeatures, TextActions, ActionsMask, Result) \n",
      "\n",
      "Prefill dataset (0 steps).\n",
      "Loaded problem: m2n140__t58_partfun1\n",
      "Eval episode has 7 steps and return -0.200.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kristsz/DreamProLog/envs/wrappers.py:57: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  value = np.array(value)\n"
     ]
    }
   ],
   "source": [
    "#import os\n",
    "#os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3' \n",
    "\n",
    "from main import init_config\n",
    "from controller import Controller\n",
    "from dataset.process import TokenParser\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "ctrl = Controller(*init_config())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "32ca6252",
   "metadata": {},
   "outputs": [],
   "source": [
    "meta = ctrl.datasetManager._train_eps._meta\n",
    "ds = []\n",
    "for v in meta.values():\n",
    "    ds.extend([str(s)[1:] for s in v['action_space_text']])\n",
    "    \n",
    "parser = TokenParser()\n",
    "\n",
    "def pad(narr):\n",
    "    size = narr.size\n",
    "    return np.pad(narr, [1, 128-size], constant_values= [(299, 0)])\n",
    "\n",
    "parsed_ds = []\n",
    "for dp in ds:\n",
    "    parsed_ds.append(pad(np.array(parser.parse(dp), dtype = np.int32)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c43cc0b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-09 18:09:18.289218: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-01-09 18:09:18.292047: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: \n",
      "pciBusID: 0000:05:00.0 name: TITAN V computeCapability: 7.0\n",
      "coreClock: 1.455GHz coreCount: 80 deviceMemorySize: 11.78GiB deviceMemoryBandwidth: 607.97GiB/s\n",
      "2022-01-09 18:09:18.292101: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1\n",
      "2022-01-09 18:09:18.292144: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10\n",
      "2022-01-09 18:09:18.292171: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.10\n",
      "2022-01-09 18:09:18.292197: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10\n",
      "2022-01-09 18:09:18.292223: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10\n",
      "2022-01-09 18:09:18.292250: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10\n",
      "2022-01-09 18:09:18.292276: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.10\n",
      "2022-01-09 18:09:18.292302: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7\n",
      "2022-01-09 18:09:18.295472: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0\n",
      "2022-01-09 18:09:18.295538: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1\n",
      "2022-01-09 18:09:18.761084: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1261] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
      "2022-01-09 18:09:18.761113: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1267]      0 \n",
      "2022-01-09 18:09:18.761118: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1280] 0:   N \n",
      "2022-01-09 18:09:18.762841: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1406] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10910 MB memory) -> physical GPU (device: 0, name: TITAN V, pci bus id: 0000:05:00.0, compute capability: 7.0)\n",
      "2022-01-09 18:09:18.763143: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "BATCH_SIZE = 32\n",
    "def generator():\n",
    "    for i in range(1000):\n",
    "        x = tf.constant([parsed_ds[np.random.randint(len(parsed_ds))] for i in range(BATCH_SIZE)])\n",
    "        yield x[:, :-1], x[:, 1:]\n",
    "sgn = tf.TensorSpec((BATCH_SIZE, 128), dtype=tf.int32)\n",
    "tf_ds = tf.data.Dataset.from_generator(generator, output_signature = (sgn, sgn))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1071ea33",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU available:  [PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n"
     ]
    }
   ],
   "source": [
    "from unorganized.parts5 import Net\n",
    "from unorganized.loss import loss_function\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cedf289f",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_layers = 3\n",
    "d_model = 128\n",
    "dff = 512\n",
    "num_heads = 8\n",
    "dropout_rate = 0.1\n",
    "\n",
    "model = Net(num_layers, 16, 128, d_model, num_heads, dff, dropout_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "991d4338",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Loss(tf.keras.losses.Loss):\n",
    "    def __init__(self, omega=0.0):\n",
    "        super().__init__()\n",
    "        self.omega = omega\n",
    "        self.loss_objective = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True, reduction='none')\n",
    "        \n",
    "    def call(self, y_true, y_pred):\n",
    "        loss = self.loss_objective(y_true, y_pred)\n",
    "        mask = 1-tf.cast(tf.math.equal(y_true, 0), tf.float32)\n",
    "        \n",
    "        loss *= mask\n",
    "        return loss\n",
    "    \n",
    "class CustomSchedule(tf.keras.optimizers.schedules.LearningRateSchedule):\n",
    "    def __init__(self, d_model, warmup_steps=6000):\n",
    "        super(CustomSchedule, self).__init__()\n",
    "\n",
    "        self.d_model = d_model\n",
    "        self.d_model = tf.cast(self.d_model, tf.float32)\n",
    "\n",
    "        self.warmup_steps = warmup_steps\n",
    "\n",
    "    def __call__(self, step):\n",
    "        arg1 = tf.math.rsqrt(step)\n",
    "        arg2 = step * (self.warmup_steps ** -1.5)\n",
    "\n",
    "        return tf.math.rsqrt(self.d_model) * tf.math.minimum(arg1, arg2)\n",
    "    \n",
    "def accuracy_function(real, pred):\n",
    "    accuracies = tf.equal(real, tf.cast(tf.math.argmax(pred, axis=-1), dtype=tf.int32))\n",
    "\n",
    "    mask = tf.math.logical_not(tf.math.equal(real, 0))\n",
    "    accuracies = tf.math.logical_and(mask, accuracies)\n",
    "\n",
    "    accuracies = tf.cast(accuracies, dtype=tf.float32)\n",
    "    mask = tf.cast(mask, dtype=tf.float32)\n",
    "    return tf.reduce_sum(accuracies)/tf.reduce_sum(mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "24e14031",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-09 18:09:19.105122: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:116] None of the MLIR optimization passes are enabled (registered 2)\n",
      "2022-01-09 18:09:19.125599: I tensorflow/core/platform/profile_utils/cpu_utils.cc:112] CPU Frequency: 3598190000 Hz\n",
      "2022-01-09 18:09:19.157462: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7\n",
      "2022-01-09 18:09:19.875184: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=float32, numpy=0.0>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss = Loss()\n",
    "x, x = next(iter(tf_ds))\n",
    "y_pred = model(x, False)\n",
    "loss(x, y_pred)\n",
    "accuracy_function(x, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "58466e77",
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = CustomSchedule(d_model)\n",
    "optimizer=tf.keras.optimizers.Adam(learning_rate, beta_1=0.9, beta_2=0.98, epsilon=1e-9)\n",
    "model.compile(optimizer = optimizer, loss=Loss(), metrics=[])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7837801c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "WARNING: AutoGraph could not transform <bound method Net.call of <unorganized.parts5.Net object at 0x7f347075bb10>> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Index'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <bound method Encoder.call of <unorganized.parts5.Encoder object at 0x7f34753c2fd0>> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Index'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <bound method MultiHeadAttention.call of <unorganized.parts5.MultiHeadAttention object at 0x7f3470762dd0>> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Index'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <bound method Decoder.call of <unorganized.parts5.Decoder object at 0x7f3476ee25d0>> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Index'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "1000/1000 [==============================] - 33s 26ms/step - loss: 0.9150\n",
      "Epoch 2/50\n",
      "1000/1000 [==============================] - 27s 27ms/step - loss: 0.5580\n",
      "Epoch 3/50\n",
      "1000/1000 [==============================] - 27s 26ms/step - loss: 0.4005\n",
      "Epoch 4/50\n",
      "1000/1000 [==============================] - 27s 27ms/step - loss: 0.2831\n",
      "Epoch 5/50\n",
      "1000/1000 [==============================] - 27s 26ms/step - loss: 0.2061\n",
      "Epoch 6/50\n",
      "1000/1000 [==============================] - 27s 27ms/step - loss: 0.1601\n",
      "Epoch 7/50\n",
      "1000/1000 [==============================] - 27s 27ms/step - loss: 0.1289\n",
      "Epoch 8/50\n",
      "1000/1000 [==============================] - 27s 27ms/step - loss: 0.0991\n",
      "Epoch 9/50\n",
      "1000/1000 [==============================] - 27s 27ms/step - loss: 0.0765\n",
      "Epoch 10/50\n",
      "1000/1000 [==============================] - 27s 27ms/step - loss: 0.0638\n",
      "Epoch 11/50\n",
      "1000/1000 [==============================] - 27s 27ms/step - loss: 0.0528\n",
      "Epoch 12/50\n",
      "1000/1000 [==============================] - 27s 27ms/step - loss: 0.0455\n",
      "Epoch 13/50\n",
      "1000/1000 [==============================] - 27s 27ms/step - loss: 0.0407\n",
      "Epoch 14/50\n",
      "1000/1000 [==============================] - 27s 27ms/step - loss: 0.0341\n",
      "Epoch 15/50\n",
      "1000/1000 [==============================] - 27s 27ms/step - loss: 0.0319\n",
      "Epoch 16/50\n",
      "1000/1000 [==============================] - 27s 27ms/step - loss: 0.0276\n",
      "Epoch 17/50\n",
      "1000/1000 [==============================] - 27s 27ms/step - loss: 0.0255\n",
      "Epoch 18/50\n",
      "1000/1000 [==============================] - 27s 27ms/step - loss: 0.0228\n",
      "Epoch 19/50\n",
      "1000/1000 [==============================] - 27s 27ms/step - loss: 0.0203\n",
      "Epoch 20/50\n",
      "1000/1000 [==============================] - 27s 27ms/step - loss: 0.0193\n",
      "Epoch 21/50\n",
      "1000/1000 [==============================] - 27s 27ms/step - loss: 0.0175\n",
      "Epoch 22/50\n",
      "1000/1000 [==============================] - 27s 27ms/step - loss: 0.0155\n",
      "Epoch 23/50\n",
      "1000/1000 [==============================] - 27s 27ms/step - loss: 0.0147\n",
      "Epoch 24/50\n",
      "1000/1000 [==============================] - 27s 27ms/step - loss: 0.0134\n",
      "Epoch 25/50\n",
      "1000/1000 [==============================] - 27s 26ms/step - loss: 0.0126\n",
      "Epoch 26/50\n",
      "1000/1000 [==============================] - 27s 27ms/step - loss: 0.0118\n",
      "Epoch 27/50\n",
      " 243/1000 [======>.......................] - ETA: 20s - loss: 0.0115"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_1205/2708861432.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf_ds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m50\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/miniconda3/envs/tf2/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1098\u001b[0m                 _r=1):\n\u001b[1;32m   1099\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1100\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1101\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1102\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/tf2/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    826\u001b[0m     \u001b[0mtracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    827\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtrace\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtm\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 828\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    829\u001b[0m       \u001b[0mcompiler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"xla\"\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_experimental_compile\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"nonXla\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    830\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/tf2/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    853\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    854\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 855\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    856\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    857\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/tf2/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2941\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[1;32m   2942\u001b[0m     return graph_function._call_flat(\n\u001b[0;32m-> 2943\u001b[0;31m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m   2944\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2945\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/tf2/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1917\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1918\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1919\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1920\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1921\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/tf2/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    558\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    559\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 560\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    561\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    562\u001b[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001b[0;32m~/miniconda3/envs/tf2/lib/python3.7/site-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 60\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model.fit(tf_ds, epochs = 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "005c83f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[299   3 158  23  12   2  37  23  12   2   3  33  23  12   2 157  23  12\n",
      "    2   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0]\n",
      " [299   9   5  12  13   2   9   5  16  49  23  13   2   3  14   5  12  16\n",
      "    2   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0]\n",
      " [299   9   5  12  13   2   3   9   5  55  23  12  55  23  13   2   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0]\n",
      " [299 109  20  12  38  23  13  38  23  16   2  72  23  13   2  90  23  13\n",
      "    2   3  33  23  13   2  72  23  16   2  90  23  16   2   3  33  23  16\n",
      "    2  21   5  12  22  23  24   5  38  23  13  38  23  16   2  27  23  12\n",
      "    2  21   5  18  22  23  38  23  13   2   3 123   5 113  32  38  23  13\n",
      "   38  23  16  12  18  16   2 110  20  12  13  16   2 123   5  18  13   2\n",
      "    0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0]], shape=(4, 128), dtype=int32)\n",
      "\n",
      "tf.Tensor(\n",
      "[[  3 158  23  12   2  37  23  12   2   3  33  23  12   2 157  23  12   2\n",
      "    3  23  12   2  35  12  12  12  12  12  12  12   2   5  16  12  12   2\n",
      "   35  23  12  12   2  96  23  12   2   2   2  16   2   2  35  23  12   2\n",
      "   21  20  12   2  13  12   2  21 218  15  23  12  12   2   2  12   2  12\n",
      "    2   2   2  12   2   2  12  12  12  12  12   2  12  12  18  12   2  12\n",
      "    2   2   2  15  12  12  12   2   2  12  12   2 115  12  12   2  23  12\n",
      "   12  12  16   2   2   2   3  20  12  43  18  18   2   2  12  12  12  12\n",
      "   12   2]\n",
      " [  9   5  12  13   2   9   5  16  49  23  13   2   3  14   5  12  16   2\n",
      "    3  14   5  49  18   2  18  16  16  13  16  18   2  57   5  43  13   2\n",
      "    9   5  18  32   5  23  18  18   2  14   5  18   2   2  12  18  12   2\n",
      "    2  14  12  18   5  16  18  18   2  14   5  13  13  18  13  16   2  20\n",
      "   18  18  18  18   2   9   5  12  57  18  23  16  12  18  18  12   9   5\n",
      "    5  13   2  43  15  43  12  38  12  12  18   2   5  18  43   2   2  24\n",
      "    5  16  43  43   2   3   3   5  12  43  18   2   2   2   5  18  43  18\n",
      "   18   2]\n",
      " [  9   5  12  13   2   3   9   5  55  23  12  55  23  13   2  37   2  55\n",
      "   13  13   2  23 187   2  12  23  55  13  23  23   2   5   5  55  23   2\n",
      "    2  55  23  13   7   2   2 186   2   5   5  12   2   2  13  13   2   2\n",
      "   12  12   2   2   2   2   2  12 218   4   5  12   2   2  12  13  13   2\n",
      "    2  13  12  13   2   5  13  12  55  23  23  13  13  23  12  12  16  13\n",
      "    2   2   2  12  43  43  12 119  23  23  12  13  13  18  43  12  23  13\n",
      "    5  13  16  43  43  12   2   5  12  43  12  13   2   2   5  43  43  23\n",
      "   23  23]\n",
      " [109  20  12  38  23  13  38  23  16   2  72  23  13   2  90  23  13   2\n",
      "    3  33  23  13   2  72  23  16   2  90  23  16   2   3  33  23  16   2\n",
      "   21   5  12  22  23  24   5  38  23  13  38  23  16   2  27  23  12   2\n",
      "   21   5  18  22  23  38  23  13   2   3 123   5 113  32  38  23  13  38\n",
      "   23  16  12  18  16   2 110  20  12  13  16   2 123   5  18  13   2   2\n",
      "    2   2   5  18  18  12  23  38  23  16  16  13   5  16  38  23  23  13\n",
      "   13  16  18  18   2   2   2  20  16  13  18  18   2  38  23  13  38  38\n",
      "   13  13]], shape=(4, 128), dtype=int64)\n",
      "\n",
      "tf.Tensor(\n",
      "[[100  99  99  99 100  99 100 100 100  99  99  96  99  99  99  99 100 100\n",
      "    0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0]\n",
      " [100 100 100 100  99 100  99  99  99  99  99  99  99  99  99 100  99  99\n",
      "    0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0]\n",
      " [100  99 100 100 100  99 100  99  99  99  99  99 100  99 100   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0]\n",
      " [ 99  99  99  99 100  99  99  99  99 100  99 100  99  99  99  99  99 100\n",
      "   99  99 100  76 100  99  99  99 100  99  99  97  99  99  99  99  92  99\n",
      "   99  99  98  99  99  99  99  99  99  99  99  99  99  99  99  99  99  99\n",
      "   99  99  99  99  99  99  99  99  99  99  96  99  99  99  99  99  99  99\n",
      "   99  87  95  99  97  99  99  99  98  88  99  99  99  99  99  99  99   0\n",
      "    0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0]], shape=(4, 128), dtype=int32)\n",
      "\n",
      "tf.Tensor(\n",
      "[[100  99  99  99 100  99 100 100 100  99  99  96  99  99  99  99 100 100\n",
      "   79  98  99  86  35  97  91  96  34  83  99  99  98  74  76  54  99  99\n",
      "   38  90  95  99  99  53  90  99  99  98  97  42  73  89  99  97  72  99\n",
      "   51  84  69  69  66  57  99  98  45  89  99  91  72  96  80  48  88  94\n",
      "   99  99  60  50  99  44  96  42  40  99  99  86  35  76  96  93  56  80\n",
      "   78  66  93  96  68  98  99  96  99  94  99  55  69  56  99  47  70  99\n",
      "   98  78  65  89  99  99  99  92  98  74  88  54  99  59  99  99  92  61\n",
      "   48  90]\n",
      " [100 100 100 100  99 100  99  99  99  99  99  99  99  99  99 100  99  99\n",
      "   88  78  51  57  72  56  96  87  85  68  73  61  99  91  99  49  47  99\n",
      "   96  91  84  76  70  88  73  79  99  98  96  44  98  95  91  76  95  99\n",
      "   90  92  76  86  99  96  94  99  82  92  99  50  59  81  62  62  98  95\n",
      "   40  90  81  91  99  78  44  55  51  99  81  99  65  70  98  39  62  98\n",
      "   84  56  99  27  81  62  49  66  81  69  42  32  91  75  68  99  99  63\n",
      "   80  96  53  80  99  60  98  94  91  97  97  99  99  56  48  69  92  83\n",
      "   97  94]\n",
      " [100  99 100 100 100  99 100  99  99  99  99  99 100  99 100  82  79  91\n",
      "   36  40  53  76  98  78  23  97  50  73  53  49  72  98  88  97  53  99\n",
      "   91  72  62  98  49  33  45  97  99  89  99  37  99  97  70  98  93  98\n",
      "   93  31  70  94  79  92  70  93  78  41  93  81  52  64  51  80  89  81\n",
      "   98  72  38  52  93  65  50  39  50  88  91  70  60  64  68  97  33  97\n",
      "   98  99  99  80  50  84  95  82  93  78  76  67  90  73  57  82  85  73\n",
      "   96  93  47  60  89  39  29  64  88  51  56  92  89  99  86  61  67  44\n",
      "   93  88]\n",
      " [ 99  99  99  99 100  99  99  99  99 100  99 100  99  99  99  99  99 100\n",
      "   99  99 100  76 100  99  99  99 100  99  99  97  99  99  99  99  92  99\n",
      "   99  99  98  99  99  99  99  99  99  99  99  99  99  99  99  99  99  99\n",
      "   99  99  99  99  99  99  99  99  99  99  96  99  99  99  99  99  99  99\n",
      "   99  87  95  99  97  99  99  99  98  88  99  99  99  99  99  99  99  84\n",
      "   99  90  86  61  72  33  77  95  97  67  82  46  95  68  76  88  99  93\n",
      "   94  45  29  88  96  88  39  97  42  83  76  97  99  88  99  56  99  80\n",
      "   72  47]], shape=(4, 128), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "#To visualize performance\n",
    "x, y_true = next(iter(tf_ds))\n",
    "_y_pred = model(x, False)\n",
    "_y_pred = tf.nn.softmax(_y_pred, axis=-1)\n",
    "y_probs = tf.gather(_y_pred, y_true, axis=-1, batch_dims=2)\n",
    "y_pred = tf.math.argmax(_y_pred, axis=-1)\n",
    "print(x[:4], y_pred[:4], tf.cast(100*y_probs[:4], dtype=tf.int32), tf.cast(100*tf.reduce_max(_y_pred[:4], axis = -1), dtype = tf.int32), sep='\\n\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e3a9f2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = tf.cast(tf.math.equal(x[:], 0), tf.float32)[:, tf.newaxis, :, tf.newaxis]\n",
    "        \n",
    "v = model.enc_embed(x)[:]#, model.encoder.variable#tf.tile(model.encoder.variable, (32, 1, 1))\n",
    "vs = [v]\n",
    "att = []\n",
    "for layer in model.encoder.layers:\n",
    "    _v, a = mha(v, v, v, mask)\n",
    "    v = v + _v\n",
    "    v = sl(v) \n",
    "    vs.append(v)\n",
    "    att.append(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7537d5d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = tf.cast(tf.math.equal(x[:], 0), tf.float32)[:, tf.newaxis, :, tf.newaxis]\n",
    "v = model.enc_embed(x)[:]\n",
    "embed, att = model.encoder(v, mask, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fbfef4e2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(32, 1, 8), dtype=float32, numpy=\n",
       "array([[[ 0.0361836 , -0.10256108,  0.4023145 , -0.24285649,\n",
       "         -0.17512053,  0.23289916, -0.36779302,  0.44178143]],\n",
       "\n",
       "       [[-0.31037804,  0.32174262, -0.18416238, -0.3617726 ,\n",
       "          0.5733119 ,  0.01409043, -0.10353428, -0.22446443]],\n",
       "\n",
       "       [[ 0.00805724, -0.0114899 ,  0.15925747, -0.29105526,\n",
       "          0.31619775, -0.17798011,  0.2296477 , -0.01207742]],\n",
       "\n",
       "       [[-0.05382052,  0.10841717,  0.692728  ,  0.11222706,\n",
       "         -0.21121293,  0.8914639 ,  0.03716245,  0.18558213]],\n",
       "\n",
       "       [[-0.13097747,  0.7052641 , -0.7361518 , -0.15868004,\n",
       "          0.10542033, -0.15197513, -0.17474407,  0.65583575]],\n",
       "\n",
       "       [[-0.4998785 ,  0.6584555 ,  0.27690056,  0.26485413,\n",
       "          0.03289813, -0.0220038 , -0.19893831,  0.0268001 ]],\n",
       "\n",
       "       [[-0.03642412, -0.06805982, -0.3231477 , -0.03467386,\n",
       "          0.10892622,  0.85996616,  0.7717775 ,  0.54800034]],\n",
       "\n",
       "       [[-0.40738094,  0.58111465,  0.7478768 ,  0.15178776,\n",
       "          0.4908527 , -0.35010162, -0.03459343,  0.11496533]],\n",
       "\n",
       "       [[ 0.27322295, -0.28644994, -0.6989214 , -0.02703543,\n",
       "          0.08498386, -0.08010112, -0.03525269,  0.31453544]],\n",
       "\n",
       "       [[ 0.10036883,  0.13381605,  0.35069907,  0.08304495,\n",
       "         -0.33694333,  0.5225637 , -0.1012665 ,  0.13958368]],\n",
       "\n",
       "       [[-0.12871566,  0.06771966, -0.4898293 , -0.18185098,\n",
       "          0.11536291,  0.7168498 ,  0.60347134,  0.60378224]],\n",
       "\n",
       "       [[ 0.43428928,  0.06284383, -0.3671927 , -0.1666794 ,\n",
       "          0.41328827, -0.21090877, -1.1796026 , -0.06774594]],\n",
       "\n",
       "       [[-0.00478414, -0.0574898 , -0.04969928, -0.12442745,\n",
       "          0.30571786, -0.11187069,  0.0093798 ,  0.21172474]],\n",
       "\n",
       "       [[ 0.09982021,  0.57879245,  0.33914113,  0.32029647,\n",
       "         -0.18654475, -0.06683934, -0.86578834,  0.5736966 ]],\n",
       "\n",
       "       [[ 0.64014596,  0.313883  ,  0.03027879, -0.03857781,\n",
       "          0.13687736,  0.49659887,  0.37535995,  0.32933542]],\n",
       "\n",
       "       [[-0.0079072 ,  0.45199046, -0.8536345 ,  0.24978991,\n",
       "         -0.29399738, -0.22157645, -0.71918666,  0.2728461 ]],\n",
       "\n",
       "       [[-0.28528064,  0.06402564, -0.1469796 ,  0.3927225 ,\n",
       "         -0.1294094 , -0.03344996, -0.00639164,  0.91070366]],\n",
       "\n",
       "       [[-0.26081714,  0.26068226, -0.7014713 ,  0.07300854,\n",
       "         -0.02663935,  0.01078164,  0.28063616,  0.39965045]],\n",
       "\n",
       "       [[-0.61003274,  0.5919691 ,  0.26015708,  0.41298944,\n",
       "         -0.11500306, -0.10101585, -0.2183941 ,  0.02126448]],\n",
       "\n",
       "       [[ 0.06903676,  0.21903719, -0.6135414 ,  0.15960851,\n",
       "          0.00541971,  0.07092744,  0.02231885,  0.17910929]],\n",
       "\n",
       "       [[-0.28165334, -0.42078146, -0.05304098,  0.33575702,\n",
       "         -0.08202041,  0.1744053 , -0.7104456 ,  0.3437858 ]],\n",
       "\n",
       "       [[-0.03642412, -0.06805982, -0.3231477 , -0.03467386,\n",
       "          0.10892622,  0.85996616,  0.7717775 ,  0.54800034]],\n",
       "\n",
       "       [[-0.3088717 ,  0.22276168, -0.2742112 , -0.26186585,\n",
       "          0.6403694 , -0.04808205, -0.10943481, -0.23539369]],\n",
       "\n",
       "       [[-0.6547345 ,  0.27922514, -0.43865252,  0.46364278,\n",
       "          0.05272004, -0.15537766,  0.0137032 ,  0.31929892]],\n",
       "\n",
       "       [[-0.02676392, -0.14166994, -0.6195008 , -0.23489128,\n",
       "         -0.02696223,  0.36817136,  0.29973665,  0.43099886]],\n",
       "\n",
       "       [[ 0.35151154, -0.10974417,  0.86717737,  0.08864869,\n",
       "          0.03402899,  0.39448032, -0.42979217, -0.11857459]],\n",
       "\n",
       "       [[-0.1147749 ,  0.59279895, -0.2229338 ,  0.40458888,\n",
       "         -0.400021  ,  0.07842866, -0.41293657,  0.23623742]],\n",
       "\n",
       "       [[-0.21173203,  0.6152975 , -0.22593349,  0.60952854,\n",
       "         -0.16125126, -0.07584625,  0.0604572 ,  0.63538486]],\n",
       "\n",
       "       [[ 0.15973581,  0.43760112, -0.84981704,  0.30299973,\n",
       "         -0.12018427, -0.18145885, -0.6593992 ,  0.35208842]],\n",
       "\n",
       "       [[ 0.00864925, -0.18220612,  0.12109931, -0.13422032,\n",
       "         -0.07818735,  0.4968344 ,  0.6489584 ,  0.5765359 ]],\n",
       "\n",
       "       [[-0.12270034,  0.19860032,  0.5799179 ,  0.15210459,\n",
       "          0.09001658, -0.33531043, -0.25809425,  0.5175853 ]],\n",
       "\n",
       "       [[-0.01347822,  0.46848324, -0.35948658, -0.03498539,\n",
       "          0.32225496, -0.52314657,  0.52841705,  0.46848   ]]],\n",
       "      dtype=float32)>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embed[:, :1, :8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea5f1f08",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reduce_sum(tf.cast(att[0][1]>0.01, tf.int32))/(2**(5+3+7+4)) #32, 8, 128, 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36671caf",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.prod(att[0][0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cbb92bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def analyze_att(matrix):\n",
    "    print(matrix.shape)\n",
    "    entries = np.prod(matrix.shape)\n",
    "    x, y = [], []\n",
    "    for i in range(2, 100):\n",
    "        y.append(tf.reduce_sum(tf.cast(matrix>1/i, tf.float32)/entries))\n",
    "        x.append(i)\n",
    "    plt.plot(x, y)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b48288be",
   "metadata": {},
   "outputs": [],
   "source": [
    "analyze_att(att[2][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "747c9a07",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.math.argmax(embed, axis=-1), tf.reduce_max(embed, axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e381a56b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.encoder.variable\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a2ef1da",
   "metadata": {},
   "outputs": [],
   "source": [
    "vs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "055e3730",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = model.dense(vs[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0c6b928",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ae7054a8",
   "metadata": {},
   "source": [
    "#### "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5c7168c",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.math.argmax(pred[1, : , :], axis= -1 ), x[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25a0eacc",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.math.reduce_max(pred[1], axis=-1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
